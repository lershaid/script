        # Run migrations for each service
        kubectl create job user-migration-$(date +%Y%m%d%H%M%S) --from=cronjob/user-service-migration -n prism-production
        kubectl create job project-migration-$(date +%Y%m%d%H%M%S) --from=cronjob/project-service-migration -n prism-production
        
        # Wait for migrations to complete
        kubectl wait --for=condition=complete job -l app=migration -n prism-production --timeout=600s

  # Rollback capability
  rollback:
    runs-on: ubuntu-latest
    if: failure()
    environment: production
    
    steps:
    - name: Rollback deployment
      run: |
        # Emergency rollback procedure
        kubectl rollout undo deployment/api-gateway -n prism-production
        kubectl rollout undo deployment/user-service -n prism-production
        kubectl rollout undo deployment/project-service -n prism-production
    
    - name: Restore database backup
      run: |
        # Restore from latest backup if needed
        LATEST_BACKUP=$(kubectl get jobs -n prism-production -l app=postgres-backup --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1].metadata.name}')
        kubectl create job restore-$(date +%Y%m%d%H%M%S) --from=job/$LATEST_BACKUP -n prism-production

  # Post-deployment monitoring
  post-deploy-monitoring:
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: success()
    
    steps:
    - name: Enable enhanced monitoring
      run: |
        # Increase monitoring sensitivity for 1 hour after deployment
        curl -X POST "${{ secrets.PROMETHEUS_WEBHOOK }}" \
          -H "Content-Type: application/json" \
          -d '{"alert_level": "enhanced", "duration": "1h"}'
    
    - name: Update status page
      run: |
        # Update status page with deployment info
        curl -X POST "${{ secrets.STATUS_PAGE_API }}" \
          -H "Authorization: Bearer ${{ secrets.STATUS_PAGE_TOKEN }}" \
          -H "Content-Type: application/json" \
          -d '{
            "status": "operational",
            "message": "Deployment completed successfully",
            "version": "${{ github.ref_name }}"
          }'

  # Notifications
  notify-deployment:
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Notify team on success
      if: success()
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#prism-releases'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        message: |
          üöÄ **Deployment Successful!**
          
          **Environment:** ${{ github.event.inputs.environment || 'production' }}
          **Version:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}
          **Triggered by:** ${{ github.actor }}
          
          All services are healthy and running.
    
    - name: Notify team on failure
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        channel: '#prism-alerts'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        message: |
          üö® **Deployment Failed!**
          
          **Environment:** ${{ github.event.inputs.environment || 'production' }}
          **Version:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}
          **Failed Job:** ${{ github.job }}
          
          Immediate attention required!
    
    - name: Create GitHub release
      if: success() && startsWith(github.ref, 'refs/tags/v')
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref_name }}
        release_name: Release ${{ github.ref_name }}
        body: |
          ## Changes in this Release
          
          - Automated release from successful deployment
          - All services updated to version ${{ github.ref_name }}
          - Database migrations applied successfully
          - All health checks passed
          
          ## Deployment Details
          
          - **Staging Deployment:** ‚úÖ Successful
          - **Production Deployment:** ‚úÖ Successful
          - **Database Migrations:** ‚úÖ Applied
          - **Health Checks:** ‚úÖ Passed
          
          ## Service Versions
          
          - API Gateway: ${{ github.ref_name }}
          - User Service: ${{ github.ref_name }}
          - Project Service: ${{ github.ref_name }}
          - Registry Service: ${{ github.ref_name }}
          - Exchange Service: ${{ github.ref_name }}
        draft: false
        prerelease: false
'''

    def _get_security_workflow(self) -> str:
        return '''name: Security Scanning

on:
  schedule:
    - cron: '0 2 * * *'  # Run daily at 2 AM UTC
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  # Dependency Vulnerability Scanning
  dependency-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit semgrep
        pip install -r requirements.txt
    
    - name: Python dependency scan with Safety
      run: |
        safety check --json --output safety-report.json || true
    
    - name: Upload Safety report
      uses: actions/upload-artifact@v3
      with:
        name: safety-report
        path: safety-report.json
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install frontend dependencies
      working-directory: frontend/web-app
      run: npm ci
    
    - name: Node.js dependency scan with npm audit
      working-directory: frontend/web-app
      run: |
        npm audit --audit-level=moderate --json > npm-audit-report.json || true
    
    - name: Upload npm audit report
      uses: actions/upload-artifact@v3
      with:
        name: npm-audit-report
        path: frontend/web-app/npm-audit-report.json

  # Container Image Scanning
  container-scan:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        service: [
          api-gateway,
          user-service,
          project-service,
          registry-service
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Build Docker image
      run: |
        docker build -t prism/${{ matrix.service }}:latest ./services/${{ matrix.service }}
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'prism/${{ matrix.service }}:latest'
        format: 'sarif'
        output: 'trivy-${{ matrix.service }}-results.sarif'
    
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-${{ matrix.service }}-results.sarif'
    
    - name: Run Snyk container scan
      uses: snyk/actions/docker@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        image: 'prism/${{ matrix.service }}:latest'
        args: --severity-threshold=high

  # Static Code Analysis
  static-analysis:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install Bandit
      run: pip install bandit[toml]
    
    - name: Run Bandit security scan
      run: |
        bandit -r . -f json -o bandit-report.json -x tests/,venv/,.venv/ || true
    
    - name: Upload Bandit report
      uses: actions/upload-artifact@v3
      with:
        name: bandit-report
        path: bandit-report.json
    
    - name: Run Semgrep scan
      uses: returntocorp/semgrep-action@v1
      with:
        config: >-
          p/security-audit
          p/secrets
          p/owasp-top-ten
        generateSarif: "1"
    
    - name: Upload Semgrep results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: semgrep.sarif

  # Secrets Scanning
  secrets-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for better secret detection
    
    - name: Run TruffleHog
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD
        extra_args: --debug --only-verified

  # License Compliance
  license-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install pip-licenses
      run: pip install pip-licenses
    
    - name: Install dependencies
      run: pip install -r requirements.txt
    
    - name: Check Python package licenses
      run: |
        pip-licenses --format=json --output-file=python-licenses.json
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install license-checker
      run: npm install -g license-checker
    
    - name: Check Node.js package licenses
      working-directory: frontend/web-app
      run: |
        npm ci
        license-checker --json --out ../../node-licenses.json
    
    - name: Upload license reports
      uses: actions/upload-artifact@v3
      with:
        name: license-reports
        path: |
          python-licenses.json
          node-licenses.json

  # Infrastructure Security Scan
  infrastructure-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Run Checkov on Terraform
      uses: bridgecrewio/checkov-action@master
      with:
        directory: infrastructure/terraform
        framework: terraform
        output_format: sarif
        output_file_path: checkov-terraform.sarif
    
    - name: Upload Checkov scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: checkov-terraform.sarif
    
    - name: Run Checkov on Kubernetes manifests
      uses: bridgecrewio/checkov-action@master
      with:
        directory: infrastructure/kubernetes
        framework: kubernetes
        output_format: sarif
        output_file_path: checkov-k8s.sarif
    
    - name: Upload Kubernetes scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: checkov-k8s.sarif

  # Security Report Generation
  security-report:
    runs-on: ubuntu-latest
    needs: [dependency-scan, container-scan, static-analysis, secrets-scan, license-scan, infrastructure-scan]
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate security summary
      run: |
        echo "# Security Scan Summary" > security-summary.md
        echo "**Date:** $(date)" >> security-summary.md
        echo "**Commit:** ${{ github.sha }}" >> security-summary.md
        echo "" >> security-summary.md
        
        echo "## Scan Results" >> security-summary.md
        echo "- **Dependency Scan:** $([ -f safety-report/safety-report.json ] && echo '‚úÖ Completed' || echo '‚ùå Failed')" >> security-summary.md
        echo "- **Container Scan:** $([ -f trivy-*-results.sarif ] && echo '‚úÖ Completed' || echo '‚ùå Failed')" >> security-summary.md
        echo "- **Static Analysis:** $([ -f bandit-report/bandit-report.json ] && echo '‚úÖ Completed' || echo '‚ùå Failed')" >> security-summary.md
        echo "- **Secrets Scan:** $([ ${{ job.status }} == 'success' ] && echo '‚úÖ No secrets found' || echo '‚ö†Ô∏è Check required')" >> security-summary.md
        echo "- **License Scan:** $([ -f license-reports/python-licenses.json ] && echo '‚úÖ Completed' || echo '‚ùå Failed')" >> security-summary.md
        echo "- **Infrastructure Scan:** $([ -f checkov-*.sarif ] && echo '‚úÖ Completed' || echo '‚ùå Failed')" >> security-summary.md
    
    - name: Upload security summary
      uses: actions/upload-artifact@v3
      with:
        name: security-summary
        path: security-summary.md
    
    - name: Comment on PR with security summary
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('security-summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });

  # Notify security team
  notify-security:
    runs-on: ubuntu-latest
    needs: [dependency-scan, container-scan, static-analysis, secrets-scan]
    if: failure()
    
    steps:
    - name: Notify security team on critical findings
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        channel: '#security-alerts'
        webhook_url: ${{ secrets.SECURITY_SLACK_WEBHOOK }}
        message: |
          üö® **Critical Security Scan Failure**
          
          **Repository:** ${{ github.repository }}
          **Branch:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}
          **Workflow:** Security Scanning
          
          One or more security scans have detected critical issues.
          Please review the scan results immediately.
          
          **Failed Scans:**
          ${{ join(needs.*.result, ', ') }}
'''

    def _get_release_workflow(self) -> str:
        return '''name: Release

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Release version (e.g., v1.2.3)'
        required: true
        type: string
      release_type:
        description: 'Type of release'
        required: true
        type: choice
        options:
        - patch
        - minor
        - major
      prerelease:
        description: 'Mark as pre-release'
        required: false
        type: boolean
        default: false

jobs:
  # Validate release
  validate-release:
    runs-on: ubuntu-latest
    
    outputs:
      version: ${{ steps.validate.outputs.version }}
      tag: ${{ steps.validate.outputs.tag }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Validate version format
      id: validate
      run: |
        VERSION="${{ github.event.inputs.version }}"
        
        # Remove 'v' prefix if present
        if [[ $VERSION =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
          TAG=$VERSION
          VERSION=${VERSION#v}
        elif [[ $VERSION =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
          TAG=v$VERSION
        else
          echo "Invalid version format: $VERSION"
          exit 1
        fi
        
        # Check if tag already exists
        if git tag --list | grep -q "^$TAG$"; then
          echo "Tag $TAG already exists"
          exit 1
        fi
        
        echo "version=$VERSION" >> $GITHUB_OUTPUT
        echo "tag=$TAG" >> $GITHUB_OUTPUT
        
        echo "‚úÖ Version validation passed: $TAG"

  # Run full test suite
  test-suite:
    runs-on: ubuntu-latest
    needs: [validate-release]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Install Node.js dependencies
      working-directory: frontend/web-app
      run: npm ci
    
    - name: Run Python tests
      run: |
        pytest tests/ --cov=app --cov-report=term-missing
    
    - name: Run Node.js tests
      working-directory: frontend/web-app
      run: |
        npm test -- --coverage --watchAll=false
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
    
    - name: Run frontend linting
      working-directory: frontend/web-app
      run: |
        npm run lint

  # Build and tag release
  build-release:
    runs-on: ubuntu-latest
    needs: [validate-release, test-suite]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push release images
      run: |
        TAG="${{ needs.validate-release.outputs.tag }}"
        
        services=(api-gateway user-service project-service validation-service registry-service exchange-service)
        
        for service in "${services[@]}"; do
          echo "Building $service:$TAG"
          
          docker build -t ghcr.io/${{ github.repository }}-$service:$TAG \
                       -t ghcr.io/${{ github.repository }}-$service:latest \
                       ./services/$service
          
          docker push ghcr.io/${{ github.repository }}-$service:$TAG
          docker push ghcr.io/${{ github.repository }}-$service:latest
        done

  # Update version files
  update-version:
    runs-on: ubuntu-latest
    needs: [validate-release, test-suite]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Update version files
      run: |
        VERSION="${{ needs.validate-release.outputs.version }}"
        
        # Update package.json version
        cd frontend/web-app
        npm version $VERSION --no-git-tag-version
        cd ../..
        
        # Update Python package version (if applicable)
        if [ -f setup.py ]; then
          sed -i "s/version='[^']*'/version='$VERSION'/" setup.py
        fi
        
        # Update chart version (if applicable)
        if [ -f infrastructure/kubernetes/charts/prism-registry/Chart.yaml ]; then
          sed -i "s/version: .*/version: $VERSION/" infrastructure/kubernetes/charts/prism-registry/Chart.yaml
          sed -i "s/appVersion: .*/appVersion: $VERSION/" infrastructure/kubernetes/charts/prism-registry/Chart.yaml
        fi
    
    - name: Commit version updates
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add .
        git commit -m "chore: bump version to ${{ needs.validate-release.outputs.tag }}" || exit 0
        git push

  # Generate changelog
  generate-changelog:
    runs-on: ubuntu-latest
    needs: [validate-release]
    
    outputs:
      changelog: ${{ steps.changelog.outputs.changelog }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Generate changelog
      id: changelog
      run: |
        # Get the latest tag (previous release)
        PREVIOUS_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "")
        CURRENT_TAG="${{ needs.validate-release.outputs.tag }}"
        
        if [ -z "$PREVIOUS_TAG" ]; then
          # First release
          COMMITS=$(git log --pretty=format:"- %s (%an)" --reverse)
        else
          # Get commits since last tag
          COMMITS=$(git log $PREVIOUS_TAG..HEAD --pretty=format:"- %s (%an)" --reverse)
        fi
        
        # Generate changelog
        CHANGELOG="## Changes in $CURRENT_TAG\n\n"
        
        if [ -n "$COMMITS" ]; then
          # Categorize commits
          FEATURES=$(echo "$COMMITS" | grep -i "^- feat" || true)
          FIXES=$(echo "$COMMITS" | grep -i "^- fix" || true)
          OTHERS=$(echo "$COMMITS" | grep -v -i "^- feat\|^- fix" || true)
          
          if [ -n "$FEATURES" ]; then
            CHANGELOG+="\n### üöÄ Features\n$FEATURES\n"
          fi
          
          if [ -n "$FIXES" ]; then
            CHANGELOG+="\n### üêõ Bug Fixes\n$FIXES\n"
          fi
          
          if [ -n "$OTHERS" ]; then
            CHANGELOG+="\n### üîß Other Changes\n$OTHERS\n"
          fi
        else
          CHANGELOG+="\nNo changes since last release.\n"
        fi
        
        # Save changelog
        echo -e "$CHANGELOG" > CHANGELOG.tmp
        echo "changelog<<EOF" >> $GITHUB_OUTPUT
        cat CHANGELOG.tmp >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

  # Create GitHub release
  create-release:
    runs-on: ubuntu-latest
    needs: [validate-release, test-suite, build-release, update-version, generate-changelog]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        ref: main  # Get updated version files
    
    - name: Create Git tag
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git tag ${{ needs.validate-release.outputs.tag }}
        git push origin ${{ needs.validate-release.outputs.tag }}
    
    - name: Create GitHub Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ needs.validate-release.outputs.tag }}
        release_name: Release ${{ needs.validate-release.outputs.tag }}
        body: |
          # PRISM Carbon Registry ${{ needs.validate-release.outputs.tag }}
          
          ${{ needs.generate-changelog.outputs.changelog }}
          
          ## üì¶ Container Images
          
          All services have been published with tag `${{ needs.validate-release.outputs.tag }}`:
          
          - `ghcr.io/${{ github.repository }}-api-gateway:${{ needs.validate-release.outputs.tag }}`
          - `ghcr.io/${{ github.repository }}-user-service:${{ needs.validate-release.outputs.tag }}`
          - `ghcr.io/${{ github.repository }}-project-service:${{ needs.validate-release.outputs.tag }}`
          - `ghcr.io/${{ github.repository }}-validation-service:${{ needs.validate-release.outputs.tag }}`
          - `ghcr.io/${{ github.repository }}-registry-service:${{ needs.validate-release.outputs.tag }}`
          - `ghcr.io/${{ github.repository }}-exchange-service:${{ needs.validate-release.outputs.tag }}`
          
          ## üöÄ Deployment
          
          To deploy this version:
          
          ```bash
          # Update image tags in Kustomization
          cd infrastructure/kubernetes/overlays/production
          kustomize edit set image api-gateway=ghcr.io/${{ github.repository }}-api-gateway:${{ needs.validate-release.outputs.tag }}
          # ... repeat for other services
          
          # Apply to cluster
          kubectl apply -k infrastructure/kubernetes/overlays/production/
          ```
          
          ## üìã Verification
          
          - ‚úÖ All tests passed
          - ‚úÖ Security scans completed
          - ‚úÖ Container images built and pushed
          - ‚úÖ Documentation updated
        draft: false
        prerelease: ${{ github.event.inputs.prerelease }}

  # Deploy to staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [validate-release, create-release]
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure kubectl
      run: |
        echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > kubeconfig
        export KUBECONFIG=kubeconfig
    
    - name: Deploy to staging
      run: |
        export KUBECONFIG=kubeconfig
        TAG="${{ needs.validate-release.outputs.tag }}"
        
        # Update staging environment with new release
        cd infrastructure/kubernetes/overlays/staging
        kustomize edit set image api-gateway=ghcr.io/${{ github.repository }}-api-gateway:$TAG
        kustomize edit set image user-service=ghcr.io/${{ github.repository }}-user-service:$TAG
        kustomize edit set image project-service=ghcr.io/${{ github.repository }}-project-service:$TAG
        
        kubectl apply -k .
        
        # Wait for rollout
        kubectl rollout status deployment/api-gateway -n prism-staging --timeout=600s

  # Notifications
  notify:
    runs-on: ubuntu-latest
    needs: [validate-release, create-release, deploy-staging]
    if: always()
    
    steps:
    - name: Notify team on success
      if: success()
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#prism-releases'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        message: |
          üéâ **New Release Created!**
          
          **Version:** ${{ needs.validate-release.outputs.tag }}
          **Type:** ${{ github.event.inputs.release_type }}
          **Pre-release:** ${{ github.event.inputs.prerelease }}
          
          **Release URL:** https://github.com/${{ github.repository }}/releases/tag/${{ needs.validate-release.outputs.tag }}
          
          **Next Steps:**
          - Review staging deployment
          - Plan production deployment
          - Update documentation
    
    - name: Notify team on failure
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        channel: '#prism-alerts'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        message: |
          ‚ùå **Release Creation Failed!**
          
          **Version:** ${{ github.event.inputs.version }}
          **Failed Step:** ${{ github.job }}
          
          Please check the workflow logs and retry if necessary.
'''

    def _get_pr_template(self) -> str:
        return '''## Description

Brief description of the changes made in this pull request.

## Type of Change

Please delete options that are not relevant:

- [ ] üêõ Bug fix (non-breaking change which fixes an issue)
- [ ] ‚ú® New feature (non-breaking change which adds functionality)
- [ ] üí• Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] üìö Documentation update
- [ ] üé® Code style/formatting changes
- [ ] ‚ôªÔ∏è Code refactoring (no functional changes)
- [ ] ‚ö° Performance improvements
- [ ] üß™ Adding or updating tests
- [ ] üîß Maintenance/chore tasks

## What's Changed

- [ ] Item 1
- [ ] Item 2
- [ ] Item 3

## Testing

- [ ] Unit tests added/updated and passing
- [ ] Integration tests added/updated and passing
- [ ] Manual testing completed
- [ ] E2E tests passing (if applicable)

### Test Details

Describe the tests you ran to verify your changes:

1. Test case 1
2. Test case 2
3. Test case 3

## Screenshots (if applicable)

Add screenshots to help explain your changes (especially for UI changes).

## Database Changes

- [ ] No database changes
- [ ] Database migration included
- [ ] Database migration tested locally
- [ ] Backward compatible changes only

## Security Considerations

- [ ] No security implications
- [ ] Security review completed
- [ ] Input validation added/updated
- [ ] Authentication/authorization changes reviewed

## Performance Impact

- [ ] No performance impact
- [ ] Performance impact assessed and acceptable
- [ ] Performance improvements included

## Breaking Changes

If this includes breaking changes, please describe:

1. What breaks
2. Migration path for users
3. Documentation updates needed

## Deployment Notes

Special deployment considerations:

- [ ] No special deployment requirements
- [ ] Requires environment variable updates
- [ ] Requires infrastructure changes
- [ ] Requires data migration
- [ ] Requires feature flag changes

## Documentation

- [ ] Code is self-documenting
- [ ] Docstrings/comments added for complex logic
- [ ] README updated (if needed)
- [ ] API documentation updated (if needed)
- [ ] User documentation updated (if needed)

## Checklist

- [ ] Code follows the project's style guidelines
-                for _ in range(20):
                    start_time = time.time()
                    response = await client.get(f"{self.BASE_URL}/api/v1/projects", params=params)
                    end_time = time.time()
                    
                    assert response.status_code == 200
                    response_times.append((end_time - start_time) * 1000)
                
                avg_response_time = statistics.mean(response_times)
                assert avg_response_time < 500, f"Project list (size={params['size']}) avg response time {avg_response_time}ms exceeds 500ms"

@pytest.mark.performance
class TestConcurrentLoad:
    """Concurrent load tests"""
    
    BASE_URL = "http://localhost:8000"
    
    async def test_concurrent_user_registration(self):
        """Test concurrent user registrations"""
        
        async def register_user(user_id: int):
            async with httpx.AsyncClient() as client:
                user_data = {
                    "email": f"concurrent_user_{user_id}@example.com",
                    "password": "SecurePassword123!",
                    "full_name": f"Concurrent User {user_id}"
                }
                
                start_time = time.time()
                response = await client.post(f"{self.BASE_URL}/api/v1/auth/register", json=user_data)
                end_time = time.time()
                
                return {
                    "status_code": response.status_code,
                    "response_time": (end_time - start_time) * 1000,
                    "user_id": user_id
                }
        
        # Test with 50 concurrent registrations
        tasks = [register_user(i) for i in range(50)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Analyze results
        successful_registrations = [r for r in results if isinstance(r, dict) and r["status_code"] == 201]
        failed_registrations = [r for r in results if not isinstance(r, dict) or r["status_code"] != 201]
        
        success_rate = len(successful_registrations) / len(results)
        avg_response_time = statistics.mean([r["response_time"] for r in successful_registrations])
        
        assert success_rate >= 0.95, f"Success rate {success_rate} is below 95%"
        assert avg_response_time < 1000, f"Average response time {avg_response_time}ms exceeds 1 second"
        assert len(failed_registrations) < 3, f"Too many failed registrations: {len(failed_registrations)}"
    
    async def test_concurrent_project_creation(self):
        """Test concurrent project creation"""
        
        # First, create a user for authentication
        user_data = {
            "email": "project_creator@example.com",
            "password": "SecurePassword123!",
            "full_name": "Project Creator"
        }
        
        async with httpx.AsyncClient() as client:
            await client.post(f"{self.BASE_URL}/api/v1/auth/register", json=user_data)
            login_response = await client.post(f"{self.BASE_URL}/api/v1/auth/login", json={
                "email": user_data["email"],
                "password": user_data["password"]
            })
            token = login_response.json()["access_token"]
        
        async def create_project(project_id: int):
            async with httpx.AsyncClient() as client:
                headers = {"Authorization": f"Bearer {token}"}
                project_data = {
                    "name": f"Concurrent Project {project_id}",
                    "description": f"Project created during concurrent load test {project_id}",
                    "project_type": "forestry",
                    "country": "Brazil",
                    "estimated_annual_reduction": 1000 + project_id
                }
                
                start_time = time.time()
                response = await client.post(
                    f"{self.BASE_URL}/api/v1/projects", 
                    json=project_data, 
                    headers=headers
                )
                end_time = time.time()
                
                return {
                    "status_code": response.status_code,
                    "response_time": (end_time - start_time) * 1000,
                    "project_id": project_id
                }
        
        # Test with 25 concurrent project creations
        tasks = [create_project(i) for i in range(25)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        successful_creations = [r for r in results if isinstance(r, dict) and r["status_code"] == 201]
        success_rate = len(successful_creations) / len(results)
        
        assert success_rate >= 0.90, f"Project creation success rate {success_rate} is below 90%"

@pytest.mark.performance
class TestDatabasePerformance:
    """Database performance tests"""
    
    async def test_large_dataset_query_performance(self):
        """Test query performance with large datasets"""
        # This test would require a database with substantial test data
        pass
    
    async def test_database_connection_pooling(self):
        """Test database connection pool performance"""
        pass

@pytest.mark.performance  
class TestMemoryAndResourceUsage:
    """Memory and resource usage tests"""
    
    async def test_memory_usage_under_load(self):
        """Test memory usage during high load"""
        pass
    
    async def test_cpu_usage_patterns(self):
        """Test CPU usage patterns during various operations"""
        pass

# Test fixtures and sample data
@pytest.fixture
def sample_test_data():
    """Generate sample test data for performance tests"""
    return {
        "users": [
            {
                "email": f"user_{i}@example.com",
                "password": "TestPassword123!",
                "full_name": f"Test User {i}",
                "organization": f"Test Org {i}"
            }
            for i in range(100)
        ],
        "projects": [
            {
                "name": f"Performance Test Project {i}",
                "description": f"Project {i} for performance testing",
                "project_type": "forestry",
                "country": "Brazil",
                "estimated_annual_reduction": 1000 + (i * 10)
            }
            for i in range(50)
        ]
    }
'''

    def _get_test_fixtures(self) -> str:
        return '''{
  "users": [
    {
      "id": "user-1",
      "email": "admin@prism-registry.org",
      "full_name": "System Administrator",
      "organization": "PRISM Registry",
      "role": "admin",
      "status": "active",
      "is_verified": true
    },
    {
      "id": "user-2", 
      "email": "developer@example.com",
      "full_name": "Project Developer",
      "organization": "Green Energy Corp",
      "role": "project_developer",
      "status": "active",
      "is_verified": true
    },
    {
      "id": "user-3",
      "email": "validator@certify.org",
      "full_name": "Carbon Validator",
      "organization": "Certification Authority",
      "role": "validator", 
      "status": "active",
      "is_verified": true
    }
  ],
  "projects": [
    {
      "id": "project-1",
      "project_id": "PRISM-TEST-001",
      "name": "Amazon Rainforest Conservation",
      "description": "Large-scale forest conservation project in the Brazilian Amazon",
      "project_type": "forestry",
      "methodology": "VCS-001",
      "country": "Brazil",
      "region": "Amazonas",
      "area_hectares": 50000.0,
      "estimated_annual_reduction": 25000,
      "total_estimated_reduction": 500000,
      "crediting_period_start": "2024-01-01",
      "crediting_period_end": "2034-12-31",
      "status": "registered",
      "owner_id": "user-2"
    },
    {
      "id": "project-2",
      "project_id": "PRISM-TEST-002", 
      "name": "Solar Farm Development",
      "description": "100MW solar photovoltaic farm in rural area",
      "project_type": "renewable_energy",
      "methodology": "CDM-AMS-001",
      "country": "India",
      "region": "Rajasthan",
      "area_hectares": 200.0,
      "estimated_annual_reduction": 15000,
      "total_estimated_reduction": 150000,
      "crediting_period_start": "2024-03-01",
      "crediting_period_end": "2034-02-28",
      "status": "under_validation",
      "owner_id": "user-2",
      "validator_id": "user-3"
    },
    {
      "id": "project-3",
      "project_id": "PRISM-TEST-003",
      "name": "Methane Capture Facility",
      "description": "Landfill methane capture and utilization project",
      "project_type": "methane_capture", 
      "methodology": "CDM-AMS-003",
      "country": "United States",
      "region": "California",
      "area_hectares": 50.0,
      "estimated_annual_reduction": 8000,
      "total_estimated_reduction": 80000,
      "crediting_period_start": "2024-06-01",
      "crediting_period_end": "2034-05-31",
      "status": "draft",
      "owner_id": "user-2"
    }
  ],
  "documents": [
    {
      "id": "doc-1",
      "project_id": "project-1",
      "title": "Project Design Document - Amazon Conservation",
      "document_type": "pdd",
      "file_path": "/storage/docs/pdd_amazon_conservation.pdf",
      "file_size": 2048576,
      "file_extension": "pdf",
      "uploaded_by": "user-2",
      "is_public": true
    },
    {
      "id": "doc-2",
      "project_id": "project-1", 
      "title": "Satellite Imagery - Baseline Assessment",
      "document_type": "satellite_image",
      "file_path": "/storage/docs/satellite_baseline_amazon.tif",
      "file_size": 10485760,
      "file_extension": "tif",
      "uploaded_by": "user-2",
      "is_public": false
    },
    {
      "id": "doc-3",
      "project_id": "project-2",
      "title": "Environmental Impact Assessment",
      "document_type": "legal_document",
      "file_path": "/storage/docs/eia_solar_farm.pdf", 
      "file_size": 1572864,
      "file_extension": "pdf",
      "uploaded_by": "user-2",
      "is_public": true
    }
  ],
  "carbon_credits": [
    {
      "id": "credit-1",
      "project_id": "project-1",
      "batch_id": "PRISM-BATCH-001",
      "amount": 10000,
      "status": "issued",
      "issued_to": "user-2", 
      "vintage_year": 2024,
      "blockchain_tx_hash": "0x1234567890abcdef...",
      "metadata_uri": "ipfs://QmXxxxxx..."
    },
    {
      "id": "credit-2",
      "project_id": "project-1",
      "batch_id": "PRISM-BATCH-002", 
      "amount": 5000,
      "status": "available",
      "issued_to": "user-2",
      "vintage_year": 2024,
      "blockchain_tx_hash": "0xabcdef1234567890...",
      "metadata_uri": "ipfs://QmYyyyyy..."
    }
  ],
  "test_scenarios": {
    "user_registration": {
      "valid_user": {
        "email": "newuser@example.com",
        "password": "SecurePassword123!",
        "full_name": "New Test User",
        "organization": "Test Company",
        "country": "US"
      },
      "invalid_user": {
        "email": "invalid-email",
        "password": "weak",
        "full_name": ""
      }
    },
    "project_creation": {
      "valid_project": {
        "name": "Test Wind Farm Project",
        "description": "Small wind energy generation project",
        "project_type": "renewable_energy",
        "country": "Germany",
        "estimated_annual_reduction": 5000
      },
      "invalid_project": {
        "name": "",
        "project_type": "invalid_type",
        "country": ""
      }
    },
    "api_responses": {
      "success_201": {
        "status_code": 201,
        "message": "Resource created successfully"
      },
      "error_400": {
        "error_code": "VALIDATION_ERROR",
        "message": "Validation failed",
        "details": {
          "field_errors": [
            {
              "field": "email",
              "message": "Invalid email format"
            }
          ]
        }
      },
      "error_401": {
        "error_code": "UNAUTHORIZED", 
        "message": "Authentication required",
        "details": {}
      },
      "error_404": {
        "error_code": "NOT_FOUND",
        "message": "Resource not found",
        "details": {}
      }
    }
  }
}
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Code Quality Checks
  quality:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 mypy bandit
        pip install -r requirements.txt
    
    - name: Code formatting check
      run: black --check .
    
    - name: Linting
      run: flake8 .
    
    - name: Type checking
      run: mypy .
    
    - name: Security scan
      run: bandit -r . -f json -o bandit-report.json
    
    - name: Upload security scan results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: bandit-report
        path: bandit-report.json

  # Backend Tests
  backend-tests:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgis/postgis:15-3.3-alpine
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio
    
    - name: Run unit tests
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        JWT_SECRET: test-secret-key
      run: |
        pytest tests/unit/ --cov=app --cov-report=xml --cov-report=term-missing
    
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        JWT_SECRET: test-secret-key
      run: |
        pytest tests/integration/ -v
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: backend
        name: backend-coverage

  # Frontend Tests
  frontend-tests:
    runs-on: ubuntu-latest
    
    defaults:
      run:
        working-directory: frontend/web-app
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/web-app/package-lock.json
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run linting
      run: npm run lint
    
    - name: Run type checking
      run: npm run type-check
    
    - name: Run unit tests
      run: npm test -- --coverage --watchAll=false
    
    - name: Run build
      run: npm run build
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./frontend/web-app/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  # Build Docker Images
  build:
    runs-on: ubuntu-latest
    needs: [quality, backend-tests, frontend-tests]
    
    strategy:
      matrix:
        service: [
          api-gateway,
          user-service, 
          project-service,
          validation-service,
          registry-service,
          exchange-service
        ]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./services/${{ matrix.service }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # End-to-End Tests
  e2e-tests:
    runs-on: ubuntu-latest
    needs: [build]
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Compose
      run: |
        docker-compose -f docker-compose.test.yml up -d
        sleep 30  # Wait for services to be ready
    
    - name: Set up Node.js for E2E tests
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/web-app/package-lock.json
    
    - name: Install Playwright
      working-directory: frontend/web-app
      run: |
        npm ci
        npx playwright install --with-deps
    
    - name: Run E2E tests
      working-directory: frontend/web-app
      run: npx playwright test
    
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: frontend/web-app/test-results/
    
    - name: Cleanup
      if: always()
      run: docker-compose -f docker-compose.test.yml down -v

  # Security Scanning
  security:
    runs-on: ubuntu-latest
    needs: [build]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'
    
    - name: Run Snyk security scan
      uses: snyk/actions/node@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: --file=frontend/web-app/package.json

  # Deployment (only on main branch)
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [quality, backend-tests, frontend-tests, build]
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure kubectl
      run: |
        echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > kubeconfig
        export KUBECONFIG=kubeconfig
    
    - name: Deploy to staging
      run: |
        export KUBECONFIG=kubeconfig
        kubectl apply -k infrastructure/kubernetes/overlays/staging/
        kubectl rollout status deployment/api-gateway -n prism-staging
    
    - name: Run smoke tests
      run: |
        # Run basic smoke tests against staging environment
        curl -f https://staging-api.prism-registry.org/health

  # Notify on completion
  notify:
    runs-on: ubuntu-latest
    needs: [quality, backend-tests, frontend-tests, build]
    if: always()
    
    steps:
    - name: Notify Slack on success
      if: success()
      uses: 8398a7/action-slack@v3
      with:
        status: success
        channel: '#prism-dev'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        message: '‚úÖ CI Pipeline completed successfully for ${{ github.ref }}'
    
    - name: Notify Slack on failure  
      if: failure()
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        channel: '#prism-dev'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        message: '‚ùå CI Pipeline failed for ${{ github.ref }}. Check the logs!'
'''

    def _get_cd_workflow(self) -> str:
        return '''name: CD Pipeline

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Deploy to Staging
  deploy-staging:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'staging')
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2
    
    - name: Configure kubectl
      run: |
        aws eks update-kubeconfig --region us-west-2 --name prism-staging
    
    - name: Update image tags
      run: |
        # Update Kustomization with new image tags
        cd infrastructure/kubernetes/overlays/staging
        kustomize edit set image api-gateway=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api-gateway:${{ github.sha }}
        kustomize edit set image user-service=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-user-service:${{ github.sha }}
        kustomize edit set image project-service=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-project-service:${{ github.sha }}
    
    - name: Deploy to staging
      run: |
        kubectl apply -k infrastructure/kubernetes/overlays/staging/
        
        # Wait for rollout to complete
        kubectl rollout status deployment/api-gateway -n prism-staging --timeout=600s
        kubectl rollout status deployment/user-service -n prism-staging --timeout=600s
        kubectl rollout status deployment/project-service -n prism-staging --timeout=600s
    
    - name: Run health checks
      run: |
        # Wait for services to be ready
        sleep 30
        
        # Check service health
        kubectl get pods -n prism-staging
        
        # Test API endpoints
        STAGING_URL=$(kubectl get ingress prism-ingress -n prism-staging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        curl -f https://$STAGING_URL/health || exit 1
    
    - name: Run integration tests against staging
      run: |
        # Run integration tests against staging environment
        export TEST_BASE_URL="https://$(kubectl get ingress prism-ingress -n prism-staging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
        pytest tests/integration/ --base-url=$TEST_BASE_URL

  # Deploy to Production
  deploy-production:
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: startsWith(github.ref, 'refs/tags/v') || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production')
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}
        aws-region: us-west-2
    
    - name: Configure kubectl
      run: |
        aws eks update-kubeconfig --region us-west-2 --name prism-production
    
    - name: Create database backup
      run: |
        # Create backup before deployment
        kubectl create job --from=cronjob/postgres-backup manual-backup-$(date +%Y%m%d%H%M%S) -n prism-production
    
    - name: Update image tags for production
      run: |
        cd infrastructure/kubernetes/overlays/production
        
        # Use tag version for production deployments
        if [[ $GITHUB_REF == refs/tags/* ]]; then
          VERSION=${GITHUB_REF#refs/tags/}
        else
          VERSION=${{ github.sha }}
        fi
        
        kustomize edit set image api-gateway=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-api-gateway:$VERSION
        kustomize edit set image user-service=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-user-service:$VERSION
        kustomize edit set image project-service=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-project-service:$VERSION
    
    - name: Deploy to production with rolling update
      run: |
        # Deploy with zero-downtime rolling update
        kubectl apply -k infrastructure/kubernetes/overlays/production/
        
        # Monitor rollout
        kubectl rollout status deployment/api-gateway -n prism-production --timeout=900s
        kubectl rollout status deployment/user-service -n prism-production --timeout=900s
        kubectl rollout status deployment/project-service -n prism-production --timeout=900s
    
    - name: Run production health checks
      run: |
        sleep 60  # Wait for services to stabilize
        
        # Comprehensive health checks
        kubectl get pods -n prism-production
        
        # Test critical endpoints
        PROD_URL=$(kubectl get ingress prism-ingress -n prism-production -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
        
        # Health check
        curl -f https://$PROD_URL/health || exit 1
        
        # Database connectivity
        curl -f https://$PROD_URL/api/v1/health/database || exit 1
        
        # Authentication service
        curl -f https://$PROD_URL/api/v1/auth/health || exit 1
    
    - name: Run smoke tests
      run: |
        # Run critical path smoke tests
        export PROD_BASE_URL="https://$(kubectl get ingress prism-ingress -n prism-production -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')"
        pytest tests/smoke/ --base-url=$PROD_BASE_URL
    
    - name: Update monitoring alerts
      run: |
        # Update monitoring thresholds for new version
        kubectl apply -f infrastructure/monitoring/alerts-production.yaml

  # Database Migration
  migrate-database:
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Configure kubectl
      run: |
        echo "${{ secrets.KUBE_CONFIG_PROD }}" | base64 -d > kubeconfig
        export KUBECONFIG=kubeconfig
    
    - name: Run database migrations
      run: |
        export KUBECONFIG=kubeconfig
        
        # Run migrations for each service
        kubectl create job user-        owner_id:
          type: string
          format: uuid
        validator_id:
          type: string
          format: uuid
        issued_credits:
          type: integer
        available_credits:
          type: integer
        retired_credits:
          type: integer
        created_at:
          type: string
          format: date-time
        updated_at:
          type: string
          format: date-time

    ProjectCreate:
      type: object
      required:
        - name
        - project_type
        - country
      properties:
        name:
          type: string
        description:
          type: string
        project_type:
          $ref: '#/components/schemas/ProjectType'
        methodology:
          type: string
        country:
          type: string
        region:
          type: string
        area_hectares:
          type: number
          format: float
        estimated_annual_reduction:
          type: integer
        total_estimated_reduction:
          type: integer
        crediting_period_start:
          type: string
          format: date
        crediting_period_end:
          type: string
          format: date

    ProjectUpdate:
      type: object
      properties:
        name:
          type: string
        description:
          type: string
        methodology:
          type: string
        region:
          type: string
        area_hectares:
          type: number
          format: float
        estimated_annual_reduction:
          type: integer
        total_estimated_reduction:
          type: integer

    Document:
      type: object
      properties:
        id:
          type: string
          format: uuid
        project_id:
          type: string
          format: uuid
        title:
          type: string
        document_type:
          $ref: '#/components/schemas/DocumentType'
        file_path:
          type: string
        file_size:
          type: integer
        file_extension:
          type: string
        uploaded_by:
          type: string
          format: uuid
        is_public:
          type: boolean
        created_at:
          type: string
          format: date-time

    Error:
      type: object
      properties:
        error_code:
          type: string
        message:
          type: string
        details:
          type: object

    UserRole:
      type: string
      enum:
        - admin
        - project_developer
        - validator
        - auditor
        - registry_admin
        - trader
        - buyer

    UserStatus:
      type: string
      enum:
        - active
        - inactive
        - suspended
        - pending

    ProjectType:
      type: string
      enum:
        - forestry
        - renewable_energy
        - energy_efficiency
        - methane_capture
        - industrial
        - agriculture
        - waste_management
        - transport
        - blue_carbon
        - direct_air_capture

    ProjectStatus:
      type: string
      enum:
        - draft
        - submitted
        - under_validation
        - validated
        - rejected
        - registered
        - active
        - suspended
        - completed

    DocumentType:
      type: string
      enum:
        - pdd
        - monitoring_report
        - validation_report
        - verification_report
        - project_photo
        - satellite_image
        - legal_document
        - certificate
        - other

tags:
  - name: Authentication
    description: User authentication and authorization
  - name: Users
    description: User management operations
  - name: Projects
    description: Carbon project management
  - name: Validation
    description: Project validation and verification
  - name: Registry
    description: Carbon credit registry operations
  - name: Exchange
    description: Carbon credit trading
'''

    def _get_integration_test(self) -> str:
        return '''"""
Integration tests for user flow
"""

import pytest
import asyncio
from httpx import AsyncClient
from fastapi.testclient import TestClient
from app.main import app

@pytest.mark.integration
class TestUserFlow:
    """Test complete user workflows"""
    
    @pytest.fixture
    async def client(self):
        """Create test client"""
        async with AsyncClient(app=app, base_url="http://test") as ac:
            yield ac
    
    @pytest.fixture
    def sample_user_data(self):
        """Sample user data for testing"""
        return {
            "email": "integration_test@example.com",
            "password": "SecurePassword123!",
            "full_name": "Integration Test User",
            "organization": "Test Organization",
            "country": "US"
        }
    
    async def test_complete_user_registration_flow(self, client: AsyncClient, sample_user_data):
        """Test complete user registration and login flow"""
        
        # 1. Register new user
        response = await client.post("/api/v1/auth/register", json=sample_user_data)
        assert response.status_code == 201
        
        user_data = response.json()
        assert user_data["email"] == sample_user_data["email"]
        assert user_data["full_name"] == sample_user_data["full_name"]
        assert "id" in user_data
        
        # 2. Login with registered user
        login_data = {
            "email": sample_user_data["email"],
            "password": sample_user_data["password"]
        }
        response = await client.post("/api/v1/auth/login", json=login_data)
        assert response.status_code == 200
        
        token_data = response.json()
        assert "access_token" in token_data
        assert token_data["token_type"] == "bearer"
        
        # 3. Access protected endpoint with token
        headers = {"Authorization": f"Bearer {token_data['access_token']}"}
        response = await client.get("/api/v1/users/me", headers=headers)
        assert response.status_code == 200
        
        profile_data = response.json()
        assert profile_data["email"] == sample_user_data["email"]
    
    async def test_project_creation_flow(self, client: AsyncClient, sample_user_data):
        """Test project creation workflow"""
        
        # 1. Register and login user
        await client.post("/api/v1/auth/register", json=sample_user_data)
        login_response = await client.post("/api/v1/auth/login", json={
            "email": sample_user_data["email"],
            "password": sample_user_data["password"]
        })
        token = login_response.json()["access_token"]
        headers = {"Authorization": f"Bearer {token}"}
        
        # 2. Create project
        project_data = {
            "name": "Test Carbon Project",
            "description": "A test carbon reduction project",
            "project_type": "forestry",
            "country": "Brazil",
            "area_hectares": 1000.0,
            "estimated_annual_reduction": 5000,
            "methodology": "VCS-001"
        }
        
        response = await client.post("/api/v1/projects", json=project_data, headers=headers)
        assert response.status_code == 201
        
        project = response.json()
        assert project["name"] == project_data["name"]
        assert project["status"] == "draft"
        assert "id" in project
        
        # 3. Update project
        update_data = {
            "description": "Updated project description",
            "area_hectares": 1200.0
        }
        
        response = await client.put(
            f"/api/v1/projects/{project['id']}", 
            json=update_data, 
            headers=headers
        )
        assert response.status_code == 200
        
        updated_project = response.json()
        assert updated_project["description"] == update_data["description"]
        assert updated_project["area_hectares"] == update_data["area_hectares"]
        
        # 4. Get project details
        response = await client.get(f"/api/v1/projects/{project['id']}")
        assert response.status_code == 200
        
        retrieved_project = response.json()
        assert retrieved_project["id"] == project["id"]
    
    async def test_document_upload_flow(self, client: AsyncClient, sample_user_data):
        """Test document upload workflow"""
        
        # Setup: Create user and project
        await client.post("/api/v1/auth/register", json=sample_user_data)
        login_response = await client.post("/api/v1/auth/login", json={
            "email": sample_user_data["email"],
            "password": sample_user_data["password"]
        })
        token = login_response.json()["access_token"]
        headers = {"Authorization": f"Bearer {token}"}
        
        project_response = await client.post("/api/v1/projects", json={
            "name": "Document Test Project",
            "project_type": "forestry",
            "country": "Brazil"
        }, headers=headers)
        project_id = project_response.json()["id"]
        
        # 1. Upload document
        test_file_content = b"This is a test PDF document content"
        files = {
            "file": ("test_document.pdf", test_file_content, "application/pdf")
        }
        data = {
            "document_type": "pdd",
            "title": "Project Design Document",
            "is_public": "false"
        }
        
        response = await client.post(
            f"/api/v1/projects/{project_id}/documents",
            files=files,
            data=data,
            headers=headers
        )
        assert response.status_code == 201
        
        document = response.json()
        assert document["title"] == "Project Design Document"
        assert document["document_type"] == "pdd"
        assert document["project_id"] == project_id
        
        # 2. List project documents
        response = await client.get(f"/api/v1/projects/{project_id}/documents", headers=headers)
        assert response.status_code == 200
        
        documents = response.json()
        assert len(documents) == 1
        assert documents[0]["id"] == document["id"]
    
    async def test_error_handling_flow(self, client: AsyncClient):
        """Test error handling in various scenarios"""
        
        # 1. Test duplicate user registration
        user_data = {
            "email": "duplicate@example.com",
            "password": "SecurePassword123!",
            "full_name": "Duplicate User"
        }
        
        # First registration should succeed
        response = await client.post("/api/v1/auth/register", json=user_data)
        assert response.status_code == 201
        
        # Second registration should fail
        response = await client.post("/api/v1/auth/register", json=user_data)
        assert response.status_code == 409
        
        error = response.json()
        assert error["error_code"] == "USER_ALREADY_EXISTS"
        
        # 2. Test invalid login credentials
        response = await client.post("/api/v1/auth/login", json={
            "email": "duplicate@example.com",
            "password": "WrongPassword"
        })
        assert response.status_code == 401
        
        error = response.json()
        assert error["error_code"] == "INVALID_CREDENTIALS"
        
        # 3. Test unauthorized access
        response = await client.get("/api/v1/users/me")
        assert response.status_code == 401
        
        # 4. Test invalid project data
        response = await client.post("/api/v1/projects", json={
            "name": "",  # Invalid empty name
            "project_type": "invalid_type",  # Invalid type
        })
        assert response.status_code == 422
        
        error = response.json()
        assert error["error_code"] == "VALIDATION_ERROR"
        assert "validation_errors" in error["details"]
    
    async def test_pagination_flow(self, client: AsyncClient, sample_user_data):
        """Test pagination functionality"""
        
        # Setup: Create user and multiple projects
        await client.post("/api/v1/auth/register", json=sample_user_data)
        login_response = await client.post("/api/v1/auth/login", json={
            "email": sample_user_data["email"],
            "password": sample_user_data["password"]
        })
        token = login_response.json()["access_token"]
        headers = {"Authorization": f"Bearer {token}"}
        
        # Create multiple projects
        for i in range(25):
            await client.post("/api/v1/projects", json={
                "name": f"Test Project {i+1}",
                "project_type": "forestry",
                "country": "Brazil"
            }, headers=headers)
        
        # 1. Test default pagination
        response = await client.get("/api/v1/projects")
        assert response.status_code == 200
        
        data = response.json()
        assert len(data["items"]) == 20  # Default page size
        assert data["total"] >= 25
        assert data["page"] == 1
        assert data["pages"] >= 2
        
        # 2. Test custom page size
        response = await client.get("/api/v1/projects?size=10")
        assert response.status_code == 200
        
        data = response.json()
        assert len(data["items"]) == 10
        
        # 3. Test second page
        response = await client.get("/api/v1/projects?page=2&size=10")
        assert response.status_code == 200
        
        data = response.json()
        assert data["page"] == 2
        assert len(data["items"]) > 0

@pytest.mark.integration
class TestServiceIntegration:
    """Test integration between services"""
    
    async def test_user_project_integration(self, client: AsyncClient):
        """Test integration between user and project services"""
        
        # This test would verify that user permissions
        # are properly enforced across services
        pass
    
    async def test_project_validation_integration(self, client: AsyncClient):
        """Test integration between project and validation services"""
        
        # This test would verify that project submission
        # triggers validation workflow
        pass
    
    async def test_registry_blockchain_integration(self, client: AsyncClient):
        """Test integration between registry and blockchain"""
        
        # This test would verify that credit issuance
        # properly interacts with blockchain
        pass
'''

    def _get_e2e_test(self) -> str:
        return '''"""
End-to-end tests for project creation workflow
"""

import pytest
from playwright.async_api import async_playwright, Page, Browser
import asyncio

@pytest.mark.e2e
class TestProjectCreationE2E:
    """End-to-end tests for project creation workflow"""
    
    @pytest.fixture(scope="session")
    async def browser(self):
        """Create browser instance for testing"""
        playwright = await async_playwright().start()
        browser = await playwright.chromium.launch(headless=True)
        yield browser
        await browser.close()
        await playwright.stop()
    
    @pytest.fixture
    async def page(self, browser: Browser):
        """Create new page for each test"""
        page = await browser.new_page()
        yield page
        await page.close()
    
    async def test_complete_project_creation_flow(self, page: Page):
        """Test complete project creation workflow"""
        
        # 1. Navigate to application
        await page.goto("http://localhost:3000")
        
        # 2. Navigate to registration page
        await page.click("text=Sign Up")
        await page.wait_for_url("**/register")
        
        # 3. Register new user
        await page.fill('[data-testid="email-input"]', "e2e_test@example.com")
        await page.fill('[data-testid="password-input"]', "SecurePassword123!")
        await page.fill('[data-testid="full-name-input"]', "E2E Test User")
        await page.fill('[data-testid="organization-input"]', "Test Organization")
        await page.select_option('[data-testid="country-select"]', "US")
        
        await page.click('[data-testid="register-button"]')
        
        # 4. Verify registration success and automatic login
        await page.wait_for_url("**/dashboard")
        await page.wait_for_selector("text=Welcome back, E2E Test User!")
        
        # 5. Navigate to project creation
        await page.click("text=Create Project")
        await page.wait_for_url("**/projects/create")
        
        # 6. Fill project creation form
        await page.fill('[data-testid="project-name-input"]', "E2E Test Carbon Project")
        await page.fill(
            '[data-testid="project-description-input"]', 
            "This is an end-to-end test carbon reduction project"
        )
        await page.select_option('[data-testid="project-type-select"]', "forestry")
        await page.select_option('[data-testid="country-select"]', "Brazil")
        await page.fill('[data-testid="region-input"]', "Amazon Basin")
        await page.fill('[data-testid="area-input"]', "1000")
        await page.fill('[data-testid="annual-reduction-input"]', "5000")
        await page.fill('[data-testid="total-reduction-input"]', "100000")
        await page.select_option('[data-testid="methodology-select"]', "VCS-001")
        
        # 7. Upload project document
        await page.set_input_files(
            '[data-testid="file-upload-input"]',
            "tests/fixtures/sample_pdd.pdf"
        )
        await page.select_option('[data-testid="document-type-select"]', "pdd")
        await page.fill('[data-testid="document-title-input"]', "Project Design Document")
        
        # 8. Submit project
        await page.click('[data-testid="create-project-button"]')
        
        # 9. Verify project creation success
        await page.wait_for_selector("text=Project created successfully")
        await page.wait_for_url("**/projects/*")
        
        # 10. Verify project details page
        await page.wait_for_selector("text=E2E Test Carbon Project")
        await page.wait_for_selector("text=Amazon Basin")
        await page.wait_for_selector("text=Draft")
        await page.wait_for_selector("text=Project Design Document")
        
        # 11. Test project editing
        await page.click('[data-testid="edit-project-button"]')
        await page.wait_for_selector('[data-testid="project-edit-modal"]')
        
        # Update project description
        await page.fill(
            '[data-testid="edit-description-input"]',
            "Updated description for E2E test project"
        )
        await page.click('[data-testid="save-changes-button"]')
        
        # Verify update
        await page.wait_for_selector("text=Project updated successfully")
        await page.wait_for_selector("text=Updated description for E2E test project")
        
        # 12. Test project submission for validation
        await page.click('[data-testid="submit-for-validation-button"]')
        await page.wait_for_selector('[data-testid="confirm-submission-modal"]')
        await page.click('[data-testid="confirm-submit-button"]')
        
        # Verify submission
        await page.wait_for_selector("text=Project submitted for validation")
        await page.wait_for_selector("text=Submitted")
    
    async def test_project_list_and_filtering(self, page: Page):
        """Test project list page and filtering functionality"""
        
        # 1. Navigate to application and login
        await page.goto("http://localhost:3000/login")
        await page.fill('[data-testid="email-input"]', "existing_user@example.com")
        await page.fill('[data-testid="password-input"]', "password123")
        await page.click('[data-testid="login-button"]')
        
        # 2. Navigate to projects list
        await page.click("text=Projects")
        await page.wait_for_url("**/projects")
        
        # 3. Verify project list loads
        await page.wait_for_selector('[data-testid="projects-list"]')
        projects = await page.query_selector_all('[data-testid="project-card"]')
        assert len(projects) > 0
        
        # 4. Test status filtering
        await page.select_option('[data-testid="status-filter"]', "draft")
        await page.wait_for_selector('[data-testid="projects-list"]')
        
        # Verify only draft projects are shown
        status_badges = await page.query_selector_all('[data-testid="project-status"]:has-text("Draft")')
        assert len(status_badges) > 0
        
        # 5. Test project type filtering
        await page.select_option('[data-testid="type-filter"]', "forestry")
        await page.wait_for_selector('[data-testid="projects-list"]')
        
        # 6. Test search functionality
        await page.fill('[data-testid="search-input"]', "carbon")
        await page.press('[data-testid="search-input"]', "Enter")
        await page.wait_for_selector('[data-testid="projects-list"]')
        
        # 7. Test pagination
        if await page.query_selector('[data-testid="next-page-button"]'):
            await page.click('[data-testid="next-page-button"]')
            await page.wait_for_selector('[data-testid="projects-list"]')
            
            # Verify URL contains page parameter
            current_url = page.url
            assert "page=2" in current_url
    
    async def test_user_authentication_flow(self, page: Page):
        """Test user authentication and authorization"""
        
        # 1. Test accessing protected page without auth
        await page.goto("http://localhost:3000/dashboard")
        await page.wait_for_url("**/login")
        
        # 2. Test invalid login
        await page.fill('[data-testid="email-input"]', "invalid@example.com")
        await page.fill('[data-testid="password-input"]', "wrongpassword")
        await page.click('[data-testid="login-button"]')
        
        await page.wait_for_selector("text=Invalid credentials")
        
        # 3. Test valid login
        await page.fill('[data-testid="email-input"]', "valid_user@example.com")
        await page.fill('[data-testid="password-input"]', "correctpassword")
        await page.click('[data-testid="login-button"]')
        
        await page.wait_for_url("**/dashboard")
        
        # 4. Test logout
        await page.click('[data-testid="user-menu-button"]')
        await page.click("text=Logout")
        await page.wait_for_url("**/")
        
        # 5. Verify protected page redirects after logout
        await page.goto("http://localhost:3000/dashboard")
        await page.wait_for_url("**/login")
    
    async def test_responsive_design(self, page: Page):
        """Test responsive design on different screen sizes"""
        
        # Test mobile viewport
        await page.set_viewport_size({"width": 375, "height": 667})
        await page.goto("http://localhost:3000")
        
        # Verify mobile navigation
        await page.wait_for_selector('[data-testid="mobile-menu-button"]')
        await page.click('[data-testid="mobile-menu-button"]')
        await page.wait_for_selector('[data-testid="mobile-nav-menu"]')
        
        # Test tablet viewport
        await page.set_viewport_size({"width": 768, "height": 1024})
        await page.reload()
        
        # Verify layout adapts
        await page.wait_for_selector('[data-testid="main-content"]')
        
        # Test desktop viewport
        await page.set_viewport_size({"width": 1920, "height": 1080})
        await page.reload()
        
        # Verify desktop layout
        await page.wait_for_selector('[data-testid="desktop-nav"]')
    
    async def test_error_handling_ui(self, page: Page):
        """Test error handling in the user interface"""
        
        # 1. Test network error handling
        await page.route("**/api/v1/projects", lambda route: route.abort())
        await page.goto("http://localhost:3000/projects")
        
        await page.wait_for_selector("text=Unable to load projects")
        await page.wait_for_selector('[data-testid="retry-button"]')
        
        # 2. Test form validation errors
        await page.goto("http://localhost:3000/projects/create")
        await page.click('[data-testid="create-project-button"]')
        
        await page.wait_for_selector("text=Project name is required")
        await page.wait_for_selector("text=Project type is required")
        
        # 3. Test 404 page
        await page.goto("http://localhost:3000/non-existent-page")
        await page.wait_for_selector("text=Page Not Found")
        await page.wait_for_selector('[data-testid="back-to-home-button"]')
    
    async def test_accessibility(self, page: Page):
        """Test accessibility features"""
        
        await page.goto("http://localhost:3000")
        
        # 1. Test keyboard navigation
        await page.press("body", "Tab")
        focused_element = await page.evaluate("document.activeElement.tagName")
        assert focused_element in ["BUTTON", "A", "INPUT"]
        
        # 2. Test ARIA labels
        await page.goto("http://localhost:3000/login")
        email_input = await page.query_selector('[data-testid="email-input"]')
        aria_label = await email_input.get_attribute("aria-label")
        assert aria_label is not None
        
        # 3. Test heading structure
        headings = await page.query_selector_all("h1, h2, h3, h4, h5, h6")
        assert len(headings) > 0
        
        # 4. Test alt text for images
        images = await page.query_selector_all("img")
        for img in images:
            alt_text = await img.get_attribute("alt")
            assert alt_text is not None and alt_text.strip() != ""

@pytest.mark.e2e
class TestPerformanceE2E:
    """End-to-end performance tests"""
    
    async def test_page_load_performance(self, page: Page):
        """Test page load performance"""
        
        # Start performance monitoring
        await page.goto("about:blank")
        
        # Navigate to application
        start_time = await page.evaluate("performance.now()")
        await page.goto("http://localhost:3000")
        await page.wait_for_load_state("networkidle")
        end_time = await page.evaluate("performance.now()")
        
        load_time = end_time - start_time
        assert load_time < 3000  # Page should load in less than 3 seconds
        
        # Check for performance metrics
        metrics = await page.evaluate("""
            JSON.stringify({
                firstContentfulPaint: performance.getEntriesByName('first-contentful-paint')[0]?.startTime,
                largestContentfulPaint: performance.getEntriesByType('largest-contentful-paint')[0]?.startTime,
                totalBlockingTime: performance.getEntriesByType('measure').find(m => m.name === 'total-blocking-time')?.duration
            })
        """)
        
        performance_data = eval(metrics)
        
        # Assert performance thresholds
        if performance_data["firstContentfulPaint"]:
            assert performance_data["firstContentfulPaint"] < 1500  # FCP < 1.5s
        
        if performance_data["largestContentfulPaint"]:
            assert performance_data["largestContentfulPaint"] < 2500  # LCP < 2.5s
'''

    def _get_performance_test(self) -> str:
        return '''"""
Performance and load tests for PRISM Carbon Registry
"""

import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
import httpx
import statistics

@pytest.mark.performance
class TestAPIPerformance:
    """Performance tests for API endpoints"""
    
    BASE_URL = "http://localhost:8000"
    
    async def test_health_endpoint_performance(self):
        """Test health endpoint response time"""
        
        async with httpx.AsyncClient() as client:
            # Warm up
            await client.get(f"{self.BASE_URL}/health")
            
            # Measure response times
            response_times = []
            for _ in range(100):
                start_time = time.time()
                response = await client.get(f"{self.BASE_URL}/health")
                end_time = time.time()
                
                assert response.status_code == 200
                response_times.append((end_time - start_time) * 1000)  # Convert to ms
            
            # Assert performance metrics
            avg_response_time = statistics.mean(response_times)
            p95_response_time = statistics.quantiles(response_times, n=20)[18]  # 95th percentile
            
            assert avg_response_time < 50, f"Average response time {avg_response_time}ms exceeds 50ms"
            assert p95_response_time < 100, f"95th percentile response time {p95_response_time}ms exceeds 100ms"
            assert max(response_times) < 200, f"Max response time {max(response_times)}ms exceeds 200ms"
    
    async def test_user_authentication_performance(self):
        """Test user authentication endpoint performance"""
        
        user_data = {
            "email": "perf_test@example.com",
            "password": "SecurePassword123!",
            "full_name": "Performance Test User"
        }
        
        login_data = {
            "email": user_data["email"],
            "password": user_data["password"]
        }
        
        async with httpx.AsyncClient() as client:
            # Register user first
            await client.post(f"{self.BASE_URL}/api/v1/auth/register", json=user_data)
            
            # Test login performance
            response_times = []
            for _ in range(50):
                start_time = time.time()
                response = await client.post(f"{self.BASE_URL}/api/v1/auth/login", json=login_data)
                end_time = time.time()
                
                assert response.status_code == 200
                response_times.append((end_time - start_time) * 1000)
            
            avg_response_time = statistics.mean(response_times)
            assert avg_response_time < 200, f"Login average response time {avg_response_time}ms exceeds 200ms"
    
    async def test_project_list_performance(self):
        """Test project list endpoint performance under load"""
        
        async with httpx.AsyncClient() as client:
            # Test various page sizes
            test_cases = [
                {"page": 1, "size": 10},
                {"page": 1, "size": 20},
                {"page": 1, "size": 50},
                {"page": 2, "size": 20},
            ]
            
            for params in test_cases:
                response_times = []
                
                for _ in range(# Create new migration
alembic revision --autogenerate -m "Add new table"

# Rollback migration
alembic downgrade -1
```

#### MongoDB
```bash
# Connect to MongoDB
docker-compose exec mongodb mongo prism

# View collections
show collections

# Query data
db.projects.find().pretty()
```

## Development Workflow

### 1. Feature Development

```bash
# Create feature branch
git checkout -b feature/new-carbon-project-validation

# Make changes...

# Run tests
make test

# Format code
make format

# Commit changes
git add .
git commit -m "feat: add enhanced carbon project validation"

# Push branch
git push origin feature/new-carbon-project-validation

# Create pull request
```

### 2. Code Quality Checks

```bash
# Run all quality checks
make lint

# Individual checks
black --check .           # Code formatting
flake8 .                  # Style guide
mypy .                    # Type checking
pytest --cov=.           # Test coverage
bandit -r .              # Security scan
```

### 3. Testing Strategy

#### Unit Tests
```bash
# Run unit tests for a service
cd services/user-service
pytest tests/unit/

# With coverage
pytest --cov=app --cov-report=html tests/unit/
```

#### Integration Tests
```bash
# Start test environment
docker-compose -f docker-compose.test.yml up -d

# Run integration tests
pytest tests/integration/

# Cleanup
docker-compose -f docker-compose.test.yml down
```

#### End-to-End Tests
```bash
# Run E2E tests
cd frontend/web-app
npm run test:e2e
```

## Common Development Tasks

### Adding a New API Endpoint

1. **Define the route in FastAPI**:
```python
# services/user-service/app/presentation/api/v1/routes/users.py
@router.post("/", response_model=UserResponse)
async def create_user(user_data: UserCreate):
    # Implementation
    pass
```

2. **Add business logic**:
```python
# services/user-service/app/domain/services/user_service.py
async def create_user(self, user_data: dict) -> UserEntity:
    # Business logic
    pass
```

3. **Write tests**:
```python
# services/user-service/tests/unit/test_user_service.py
def test_create_user():
    # Test implementation
    pass
```

### Adding a New React Component

1. **Create component**:
```typescript
// frontend/web-app/src/components/UserProfile.tsx
import React from 'react';

interface UserProfileProps {
  user: User;
}

const UserProfile: React.FC<UserProfileProps> = ({ user }) => {
  return <div>{user.name}</div>;
};

export default UserProfile;
```

2. **Add tests**:
```typescript
// frontend/web-app/src/components/__tests__/UserProfile.test.tsx
import { render, screen } from '@testing-library/react';
import UserProfile from '../UserProfile';

test('renders user name', () => {
  // Test implementation
});
```

### Database Schema Changes

1. **Create migration**:
```bash
cd services/user-service
alembic revision --autogenerate -m "Add email verification field"
```

2. **Review generated migration**:
```python
# Check the generated migration file
# Edit if necessary
```

3. **Apply migration**:
```bash
alembic upgrade head
```

### Adding Environment Variables

1. **Add to .env.example**:
```bash
NEW_FEATURE_ENABLED=true
NEW_API_KEY=your-api-key
```

2. **Update settings**:
```python
# packages/common/config/settings.py
class Settings(BaseSettings):
    new_feature_enabled: bool = False
    new_api_key: Optional[str] = None
```

3. **Use in service**:
```python
from packages.common.config.settings import get_settings

settings = get_settings()
if settings.new_feature_enabled:
    # Feature logic
```

## Debugging

### Backend Services

```bash
# View service logs
docker-compose logs -f user-service

# Attach debugger
docker-compose exec user-service python -m debugpy --listen 0.0.0.0:5678 --wait-for-client -m uvicorn app.main:app

# Interactive debugging
docker-compose exec user-service python
>>> from app.domain.services.user_service import UserService
>>> # Debug interactively
```

### Frontend Debugging

```bash
# Browser DevTools
# Chrome/Firefox developer tools

# VSCode debugging
# Set breakpoints and use "Launch Chrome" configuration

# React Developer Tools
# Install browser extension for React debugging
```

### Database Debugging

```bash
# PostgreSQL query analysis
docker-compose exec postgres psql -U prism -d prism_core -c "EXPLAIN ANALYZE SELECT * FROM users;"

# Monitor database activity
docker-compose exec postgres psql -U prism -d prism_core -c "SELECT * FROM pg_stat_activity;"

# MongoDB profiling
docker-compose exec mongodb mongo prism --eval "db.setProfilingLevel(2)"
docker-compose exec mongodb mongo prism --eval "db.system.profile.find().pretty()"
```

## Performance Optimization

### Backend Performance

```python
# Use async/await properly
async def get_users():
    # Concurrent database queries
    users_task = get_users_from_db()
    projects_task = get_projects_from_db()
    
    users, projects = await asyncio.gather(users_task, projects_task)
    return combine_data(users, projects)

# Database query optimization
# Use select_related for foreign keys
# Add database indexes
# Use connection pooling
```

### Frontend Performance

```typescript
// Use React.memo for expensive components
const ExpensiveComponent = React.memo(({ data }) => {
  return <div>{/* Expensive rendering */}</div>;
});

// Use useMemo for expensive calculations
const expensiveValue = useMemo(() => {
  return expensiveCalculation(data);
}, [data]);

// Use useCallback for stable function references
const handleClick = useCallback(() => {
  // Handler logic
}, [dependency]);
```

## Security Best Practices

### Backend Security

```python
# Input validation
from pydantic import BaseModel, validator

class UserCreate(BaseModel):
    email: str
    password: str
    
    @validator('email')
    def validate_email(cls, v):
        # Email validation logic
        return v

# SQL injection prevention (using SQLAlchemy ORM)
# Always use parameterized queries
user = session.query(User).filter(User.id == user_id).first()

# Authentication
from packages.common.auth.middleware import get_current_user

@router.get("/protected")
async def protected_endpoint(current_user: User = Depends(get_current_user)):
    # Protected logic
    pass
```

### Frontend Security

```typescript
// XSS prevention
import DOMPurify from 'dompurify';

const sanitizedHtml = DOMPurify.sanitize(userInput);

// CSRF protection
// Use CSRF tokens for state-changing operations

// Secure API calls
const apiCall = async () => {
  const token = localStorage.getItem('token');
  const response = await fetch('/api/endpoint', {
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json',
    },
  });
};
```

## Monitoring and Logging

### Adding Metrics

```python
# Backend metrics
from prometheus_client import Counter, Histogram

REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')

@REQUEST_DURATION.time()
def process_request():
    REQUEST_COUNT.labels(method='GET', endpoint='/users').inc()
    # Request processing
```

### Logging Best Practices

```python
# Structured logging
import logging
import json

logger = logging.getLogger(__name__)

def create_user(user_data):
    logger.info(
        "Creating user",
        extra={
            "user_email": user_data.email,
            "user_role": user_data.role,
            "request_id": get_request_id(),
        }
    )
```

## Useful Commands

### Docker Commands
```bash
# Rebuild specific service
docker-compose build user-service

# View resource usage
docker stats

# Clean up
docker system prune -f
docker volume prune -f
```

### Git Commands
```bash
# Interactive rebase
git rebase -i HEAD~3

# Cherry pick commit
git cherry-pick <commit-hash>

# Reset branch to remote
git reset --hard origin/main
```

### Database Commands
```bash
# Backup database
docker-compose exec postgres pg_dump -U prism prism_core > backup.sql

# Restore database
docker-compose exec -T postgres psql -U prism prism_core < backup.sql
```

## Getting Help

### Documentation
- **Architecture**: See `/docs/architecture/`
- **API Docs**: http://localhost:8000/docs
- **Deployment**: See `/docs/deployment/`

### Team Communication
- **Slack**: #prism-dev-team
- **Email**: dev-team@prism-registry.org
- **Weekly Standup**: Mondays 9 AM UTC

### Code Review Process
1. Create feature branch
2. Make changes with tests
3. Create pull request
4. Address review feedback
5. Merge after approval

### Common Issues
- **Port conflicts**: Check `docker-compose ps` and stop conflicting services
- **Database connection errors**: Restart database with `docker-compose restart postgres`
- **Module import errors**: Check Python path and virtual environment

## Next Steps

1. **Read the Architecture Overview**: Understanding the system design
2. **Complete a Starter Task**: Pick up a "good first issue" from the backlog
3. **Join the Team**: Attend the next standup meeting
4. **Set up IDE**: Configure your development environment
5. **Review Code Standards**: Familiarize yourself with our coding conventions

Welcome to the team! üöÄ
'''

    def _get_contributing_guide(self) -> str:
        return '''# Contributing to PRISM Carbon Registry

We're excited that you're interested in contributing to the PRISM Carbon Registry Platform! This guide will help you get started.

## Code of Conduct

By participating in this project, you agree to abide by our Code of Conduct:

- **Be respectful**: Treat everyone with respect and kindness
- **Be inclusive**: Welcome people of all backgrounds and experience levels  
- **Be collaborative**: Work together to build the best platform possible
- **Be constructive**: Provide helpful feedback and suggestions

## Getting Started

### 1. Fork and Clone

```bash
# Fork the repository on GitHub
# Then clone your fork
git clone https://github.com/your-username/prism-carbon-registry.git
cd prism-carbon-registry

# Add upstream remote
git remote add upstream https://github.com/original-org/prism-carbon-registry.git
```

### 2. Set Up Development Environment

Follow the [Getting Started Guide](getting-started.md) to set up your development environment.

### 3. Find an Issue

Look for issues labeled:
- `good first issue` - Great for newcomers
- `help wanted` - Community contributions welcome
- `bug` - Bug fixes needed
- `enhancement` - Feature improvements

## Development Workflow

### 1. Create a Branch

```bash
# Update main branch
git checkout main
git pull upstream main

# Create feature branch
git checkout -b feature/your-feature-name

# Or for bug fixes
git checkout -b fix/bug-description
```

### 2. Make Changes

#### Code Standards

**Python (Backend)**:
```python
# Use type hints
def create_user(user_data: dict) -> User:
    """Create a new user with validation."""
    # Implementation

# Follow PEP 8 style guide
# Use descriptive variable names
# Add docstrings to functions and classes
class UserService:
    """Service for managing user operations."""
    
    async def create_user(self, user_data: UserCreate) -> UserEntity:
        """
        Create a new user.
        
        Args:
            user_data: User creation data
            
        Returns:
            Created user entity
            
        Raises:
            UserAlreadyExistsError: If user already exists
        """
```

**TypeScript (Frontend)**:
```typescript
// Use interfaces for type safety
interface User {
  id: string;
  email: string;
  name: string;
}

// Use descriptive function names
const createUserProfile = (user: User): JSX.Element => {
  return <div>{user.name}</div>;
};

// Add JSDoc comments for complex functions
/**
 * Validates user input and creates a new user
 * @param userData - The user data to validate
 * @returns Promise resolving to created user
 */
const createUser = async (userData: UserCreateInput): Promise<User> => {
  // Implementation
};
```

#### Commit Message Format

We use [Conventional Commits](https://www.conventionalcommits.org/):

```
type(scope): description

[optional body]

[optional footer]
```

**Types**:
- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, etc.)
- `refactor`: Code refactoring
- `test`: Adding or updating tests
- `chore`: Maintenance tasks

**Examples**:
```
feat(user-service): add email verification endpoint

Add endpoint for users to verify their email addresses
after registration. Includes validation logic and 
email template generation.

Closes #123

fix(frontend): resolve navigation menu overflow issue

The navigation menu was overflowing on mobile devices
due to fixed width constraints.

refactor(registry): improve carbon credit validation logic

Simplify validation rules and improve error messages
for better user experience.
```

### 3. Write Tests

#### Backend Tests
```python
# Unit tests
def test_create_user_success():
    """Test successful user creation."""
    user_service = UserService(mock_repository)
    user_data = {"email": "test@example.com", "name": "Test User"}
    
    result = await user_service.create_user(user_data)
    
    assert result.email == "test@example.com"
    assert result.name == "Test User"

def test_create_user_duplicate_email():
    """Test user creation with duplicate email."""
    user_service = UserService(mock_repository)
    
    with pytest.raises(UserAlreadyExistsError):
        await user_service.create_user({"email": "existing@example.com"})

# Integration tests
@pytest.mark.integration
async def test_user_registration_flow():
    """Test complete user registration flow."""
    async with TestClient(app) as client:
        response = await client.post("/api/v1/users", json={
            "email": "newuser@example.com",
            "password": "SecurePass123!",
            "name": "New User"
        })
        
        assert response.status_code == 201
        assert response.json()["email"] == "newuser@example.com"
```

#### Frontend Tests
```typescript
// Component tests
import { render, screen, fireEvent } from '@testing-library/react';
import UserProfile from '../UserProfile';

describe('UserProfile', () => {
  const mockUser = {
    id: '1',
    email: 'test@example.com',
    name: 'Test User',
  };

  test('renders user information', () => {
    render(<UserProfile user={mockUser} />);
    
    expect(screen.getByText('Test User')).toBeInTheDocument();
    expect(screen.getByText('test@example.com')).toBeInTheDocument();
  });

  test('handles edit button click', () => {
    const mockOnEdit = jest.fn();
    render(<UserProfile user={mockUser} onEdit={mockOnEdit} />);
    
    fireEvent.click(screen.getByRole('button', { name: /edit/i }));
    
    expect(mockOnEdit).toHaveBeenCalledWith(mockUser);
  });
});

// API integration tests
describe('User API', () => {
  test('creates user successfully', async () => {
    const userData = {
      email: 'newuser@example.com',
      name: 'New User',
      password: 'SecurePass123!',
    };

    const result = await apiClient.createUser(userData);

    expect(result.email).toBe(userData.email);
    expect(result.name).toBe(userData.name);
  });
});
```

### 4. Run Quality Checks

```bash
# Run all quality checks
make lint

# Fix formatting issues
make format

# Run tests
make test

# Check test coverage
make coverage
```

### 5. Update Documentation

- Update relevant documentation in `/docs/`
- Add JSDoc/docstrings for new functions
- Update API documentation if adding new endpoints
- Add examples for new features

## Pull Request Process

### 1. Submit Pull Request

```bash
# Push your branch
git push origin feature/your-feature-name

# Create pull request on GitHub
# Use the pull request template
```

### 2. Pull Request Template

When creating a PR, use this template:

```markdown
## Description
Brief description of changes made.

## Type of Change
- [ ] Bug fix (non-breaking change that fixes an issue)
- [ ] New feature (non-breaking change that adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Documentation update

## Testing
- [ ] Unit tests added/updated
- [ ] Integration tests added/updated
- [ ] Manual testing completed

## Screenshots (if applicable)
Add screenshots for UI changes.

## Checklist
- [ ] Code follows style guidelines
- [ ] Self-review completed
- [ ] Comments added for complex code
- [ ] Documentation updated
- [ ] Tests pass locally
- [ ] No new warnings introduced

## Related Issues
Closes #123
Related to #456
```

### 3. Code Review Process

1. **Automated Checks**: CI pipeline runs tests and quality checks
2. **Peer Review**: At least one team member reviews the code
3. **Address Feedback**: Make requested changes and respond to comments
4. **Final Approval**: Reviewer approves the changes
5. **Merge**: Maintainer merges the pull request

### 4. Review Guidelines

**For Authors**:
- Keep PRs focused and reasonably sized (< 500 lines of changes)
- Provide clear description and context
- Test your changes thoroughly
- Be responsive to feedback

**For Reviewers**:
- Review within 48 hours
- Be constructive and helpful
- Test the changes locally if needed
- Approve when satisfied with quality

## Release Process

### 1. Versioning

We use [Semantic Versioning](https://semver.org/):
- `MAJOR.MINOR.PATCH` (e.g., 1.2.3)
- Major: Breaking changes
- Minor: New features (backward compatible)
- Patch: Bug fixes (backward compatible)

### 2. Release Workflow

1. **Feature Freeze**: Stop adding new features
2. **Testing**: Comprehensive testing in staging
3. **Documentation**: Update changelog and docs
4. **Release**: Create release tag and deploy
5. **Monitoring**: Monitor production deployment

## Security

### Reporting Security Vulnerabilities

**DO NOT** create public issues for security vulnerabilities.

Instead:
1. Email: security@prism-registry.org
2. Include detailed description
3. Provide steps to reproduce
4. Include potential impact assessment

We will respond within 48 hours.

### Security Guidelines

- Never commit secrets or credentials
- Use environment variables for configuration
- Validate all user inputs
- Follow OWASP security guidelines
- Use secure coding practices

## Performance Guidelines

### Backend Performance
- Use async/await for I/O operations
- Implement database query optimization
- Add appropriate caching layers
- Monitor response times and memory usage

### Frontend Performance
- Optimize bundle size
- Use code splitting
- Implement lazy loading
- Minimize API calls
- Use React.memo and useMemo appropriately

## Documentation Standards

### Code Documentation
```python
def complex_calculation(data: List[Dict], threshold: float) -> Dict[str, Any]:
    """
    Perform complex calculation on project data.
    
    This function analyzes carbon project data to calculate
    emission reductions based on specified thresholds.
    
    Args:
        data: List of project data dictionaries
        threshold: Minimum threshold for inclusion
        
    Returns:
        Dictionary containing calculation results:
        - total_reduction: Total CO2 reduction in tonnes
        - project_count: Number of projects analyzed
        - average_reduction: Average reduction per project
        
    Raises:
        ValueError: If threshold is negative
        DataValidationError: If data format is invalid
        
    Example:
        >>> data = [{"reduction": 100}, {"reduction": 200}]
        >>> result = complex_calculation(data, 50)
        >>> result["total_reduction"]
        300
    """
```

### API Documentation
- Use OpenAPI/Swagger specifications
- Include request/response examples
- Document error responses
- Provide authentication requirements

## Community

### Getting Help

- **Documentation**: Check `/docs/` first
- **GitHub Issues**: Search existing issues
- **Discussions**: Use GitHub Discussions for questions
- **Slack**: Join our development Slack channel

### Communication Channels

- **GitHub Issues**: Bug reports and feature requests
- **GitHub Discussions**: General questions and ideas
- **Slack**: Real-time chat with the team
- **Email**: dev-team@prism-registry.org

### Recognition

Contributors are recognized in:
- CONTRIBUTORS.md file
- Release notes
- Annual contributor highlights
- Conference presentations

## Legal

### License

By contributing to this project, you agree that your contributions will be licensed under the same license as the project.

### Contributor License Agreement (CLA)

For significant contributions, you may need to sign a CLA. We'll guide you through this process if needed.

Thank you for contributing to the PRISM Carbon Registry Platform! Your efforts help build a more sustainable future. üå±
'''

    def _get_openapi_spec(self) -> str:
        return '''openapi: 3.0.3
info:
  title: PRISM Carbon Registry API
  description: |
    The PRISM Carbon Registry Platform API provides comprehensive access to carbon project management,
    validation, registry, and trading functionality.
    
    ## Authentication
    
    Most endpoints require authentication using JWT tokens. Include the token in the Authorization header:
    
    ```
    Authorization: Bearer <your-jwt-token>
    ```
    
    ## Rate Limiting
    
    API requests are rate limited to prevent abuse:
    - Authenticated users: 1000 requests per hour
    - Unauthenticated users: 100 requests per hour
    
    ## Error Handling
    
    The API uses standard HTTP status codes and returns error details in a consistent format:
    
    ```json
    {
      "error_code": "VALIDATION_ERROR",
      "message": "Validation failed",
      "details": {
        "field_errors": [...]
      }
    }
    ```
    
  version: 1.0.0
  contact:
    name: PRISM Development Team
    email: api-support@prism-registry.org
    url: https://docs.prism-registry.org
  license:
    name: MIT
    url: https://opensource.org/licenses/MIT

servers:
  - url: https://api.prism-registry.org/api/v1
    description: Production server
  - url: https://staging-api.prism-registry.org/api/v1
    description: Staging server
  - url: http://localhost:8000/api/v1
    description: Local development server

paths:
  # Authentication endpoints
  /auth/login:
    post:
      tags:
        - Authentication
      summary: User login
      description: Authenticate user and return JWT token
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - email
                - password
              properties:
                email:
                  type: string
                  format: email
                  example: "user@example.com"
                password:
                  type: string
                  format: password
                  example: "SecurePassword123!"
      responses:
        '200':
          description: Login successful
          content:
            application/json:
              schema:
                type: object
                properties:
                  access_token:
                    type: string
                    example: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
                  token_type:
                    type: string
                    example: "bearer"
                  expires_in:
                    type: integer
                    example: 86400
        '401':
          description: Invalid credentials
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'

  /auth/register:
    post:
      tags:
        - Authentication
      summary: User registration
      description: Register a new user account
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserCreate'
      responses:
        '201':
          description: User created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
        '409':
          description: User already exists
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'

  # User endpoints
  /users/me:
    get:
      tags:
        - Users
      summary: Get current user profile
      security:
        - BearerAuth: []
      responses:
        '200':
          description: User profile
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'

    put:
      tags:
        - Users
      summary: Update current user profile
      security:
        - BearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UserUpdate'
      responses:
        '200':
          description: User updated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/User'

  # Project endpoints
  /projects:
    get:
      tags:
        - Projects
      summary: List projects
      description: Get a list of carbon projects with optional filtering
      parameters:
        - name: status
          in: query
          description: Filter by project status
          schema:
            $ref: '#/components/schemas/ProjectStatus'
        - name: project_type
          in: query
          description: Filter by project type
          schema:
            $ref: '#/components/schemas/ProjectType'
        - name: country
          in: query
          description: Filter by country
          schema:
            type: string
        - name: page
          in: query
          description: Page number
          schema:
            type: integer
            minimum: 1
            default: 1
        - name: size
          in: query
          description: Page size
          schema:
            type: integer
            minimum: 1
            maximum: 100
            default: 20
      responses:
        '200':
          description: List of projects
          content:
            application/json:
              schema:
                type: object
                properties:
                  items:
                    type: array
                    items:
                      $ref: '#/components/schemas/Project'
                  total:
                    type: integer
                  page:
                    type: integer
                  size:
                    type: integer
                  pages:
                    type: integer

    post:
      tags:
        - Projects
      summary: Create new project
      security:
        - BearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectCreate'
      responses:
        '201':
          description: Project created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'

  /projects/{project_id}:
    get:
      tags:
        - Projects
      summary: Get project details
      parameters:
        - name: project_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Project details
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'
        '404':
          description: Project not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'

    put:
      tags:
        - Projects
      summary: Update project
      security:
        - BearerAuth: []
      parameters:
        - name: project_id
          in: path
          required: true
          schema:
            type: string
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ProjectUpdate'
      responses:
        '200':
          description: Project updated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Project'

  /projects/{project_id}/documents:
    post:
      tags:
        - Projects
      summary: Upload project document
      security:
        - BearerAuth: []
      parameters:
        - name: project_id
          in: path
          required: true
          schema:
            type: string
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                file:
                  type: string
                  format: binary
                document_type:
                  $ref: '#/components/schemas/DocumentType'
                title:
                  type: string
                is_public:
                  type: boolean
                  default: false
      responses:
        '201':
          description: Document uploaded successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Document'

components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT

  schemas:
    User:
      type: object
      properties:
        id:
          type: string
          format: uuid
        email:
          type: string
          format: email
        full_name:
          type: string
        organization:
          type: string
        role:
          $ref: '#/components/schemas/UserRole'
        status:
          $ref: '#/components/schemas/UserStatus'
        is_verified:
          type: boolean
        created_at:
          type: string
          format: date-time
        updated_at:
          type: string
          format: date-time

    UserCreate:
      type: object
      required:
        - email
        - password
        - full_name
      properties:
        email:
          type: string
          format: email
        password:
          type: string
          minLength: 8
        full_name:
          type: string
        organization:
          type: string
        country:
          type: string
        phone:
          type: string

    UserUpdate:
      type: object
      properties:
        full_name:
          type: string
        organization:
          type: string
        phone:
          type: string
        country:
          type: string

    Project:
      type: object
      properties:
        id:
          type: string
          format: uuid
        project_id:
          type: string
        name:
          type: string
        description:
          type: string
        project_type:
          $ref: '#/components/schemas/ProjectType'
        methodology:
          type: string
        country:
          type: string
        region:
          type: string
        area_hectares:
          type: number
          format: float
        estimated_annual_reduction:
          type: integer
        total_estimated_reduction:
          type: integer
        crediting_period_start:
          type: string
          format: date
        crediting_period_end:
          type: string
          format: date
        status:
          $ref: '#/components/schemas/ProjectStatus'
        owner_id:
          type: string
          format    def _get_getting_started(self) -> str:
        return '''# Getting Started - PRISM Carbon Registry Development

Welcome to the PRISM Carbon Registry Platform development team! This guide will help you get up and running quickly.

## Prerequisites

Make sure you have the following installed on your development machine:

### Required Software
- **Git** (version 2.30+)
- **Docker** (version 20.10+) 
- **Docker Compose** (version 2.0+)
- **Node.js** (version 18+)
- **Python** (version 3.11+)
- **VSCode** (recommended IDE)

### Recommended VSCode Extensions
- Python
- Docker
- Kubernetes
- GitLens
- Prettier
- ESLint
- Thunder Client (for API testing)

## Quick Setup

### 1. Clone the Repository

```bash
git clone <repository-url>
cd prism-carbon-registry
```

### 2. Initial Setup

```bash
# Run the setup script
./tools/scripts/setup.sh

# This will:
# - Create .env file from template
# - Start infrastructure services
# - Install dependencies
# - Run database migrations
```

### 3. Verify Installation

```bash
# Check all services are running
docker-compose ps

# Test API Gateway
curl http://localhost:8000/health

# Test frontend
open http://localhost:3000
```

## Development Environment

### Project Structure Overview

```
prism-carbon-registry/
‚îú‚îÄ‚îÄ services/           # Backend microservices
‚îÇ   ‚îú‚îÄ‚îÄ user-service/   # User management
‚îÇ   ‚îú‚îÄ‚îÄ project-service/# Project management
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ frontend/           # Frontend applications
‚îÇ   ‚îú‚îÄ‚îÄ web-app/        # React web app
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ packages/           # Shared libraries
‚îÇ   ‚îú‚îÄ‚îÄ common/         # Common utilities
‚îÇ   ‚îî‚îÄ‚îÄ blockchain/     # Blockchain integration
‚îú‚îÄ‚îÄ infrastructure/     # Deployment configs
‚îî‚îÄ‚îÄ tools/             # Development tools
```

### Working with Services

#### Backend Services (Python/FastAPI)

```bash
# Navigate to a service
cd services/user-service

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run service locally
uvicorn app.main:app --host 0.0.0.0 --port 8001 --reload

# Run tests
pytest

# Format code
black .
isort .

# Type checking
mypy .
```

#### Frontend Development (React/TypeScript)

```bash
# Navigate to frontend
cd frontend/web-app

# Install dependencies
npm install

# Start development server
npm start

# Run tests
npm test

# Build for production
npm run build

# Lint code
npm run lint

# Format code
npm run format
```

### Database Operations

#### PostgreSQL
```bash
# Connect to database
docker-compose exec postgres psql -U prism -d prism_core

# Run migrations
cd services/user-service
alembic upgrade head

# Create new    def _get_flake8_config(self) -> str:
        return '''[flake8]
max-line-length = 88
extend-ignore = E203, E266, E501, W503
max-complexity = 10
select = B,C,E,F,W,T4,B9
exclude = 
    .git,
    __pycache__,
    .venv,
    .eggs,
    *.egg,
    build,
    dist,
    .tox,
    migrations
'''

    def _get_pytest_config(self) -> str:
        return '''[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    -v
    --tb=short
    --strict-markers
    --cov=app
    --cov-report=term-missing
    --cov-report=html
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    e2e: marks tests as end-to-end tests
'''

    def _get_build_script(self) -> str:
        return '''#!/bin/bash

# Build script for PRISM Carbon Registry Platform

set -e

echo "üèóÔ∏è  Building PRISM Carbon Registry Platform..."

# Build all Docker images
echo "üì¶ Building Docker images..."
docker-compose build

# Build frontend
echo "üé® Building frontend..."
cd frontend/web-app
npm run build
cd ../..

# Run tests
echo "üß™ Running tests..."
make test

echo "‚úÖ Build completed successfully!"
'''

    def _get_deploy_script(self) -> str:
        return '''#!/bin/bash

# Deployment script for PRISM Carbon Registry Platform

set -e

ENVIRONMENT=${1:-development}

echo "üöÄ Deploying PRISM Carbon Registry Platform to $ENVIRONMENT..."

case $ENVIRONMENT in
  development)
    echo "üìù Deploying to development environment..."
    docker-compose -f docker-compose.yml up -d
    ;;
  
  staging)
    echo "üìù Deploying to staging environment..."
    kubectl apply -k infrastructure/kubernetes/overlays/staging
    ;;
  
  production)
    echo "üìù Deploying to production environment..."
    kubectl apply -k infrastructure/kubernetes/overlays/production
    ;;
  
  *)
    echo "‚ùå Unknown environment: $ENVIRONMENT"
    echo "Available environments: development, staging, production"
    exit 1
    ;;
esac

echo "‚úÖ Deployment to $ENVIRONMENT completed!"
'''

    def _get_test_script(self) -> str:
        return '''#!/bin/bash

# Test script for PRISM Carbon Registry Platform

set -e

echo "üß™ Running tests for PRISM Carbon Registry Platform..."

# Run Python tests
echo "üêç Running Python tests..."
pytest --cov=. --cov-report=xml --cov-report=term-missing

# Run frontend tests
echo "‚öõÔ∏è  Running frontend tests..."
cd frontend/web-app
npm test -- --coverage --watchAll=false
cd ../..

# Run linting
echo "üîç Running linting..."
black --check .
flake8 .
mypy .

# Run security checks
echo "üîí Running security checks..."
bandit -r . -x tests/

echo "‚úÖ All tests passed!"
'''

    def _get_migrate_script(self) -> str:
        return '''#!/bin/bash

# Database migration script for PRISM Carbon Registry Platform

set -e

echo "üìä Running database migrations..."

# Wait for database to be ready
echo "‚è≥ Waiting for database..."
until docker-compose exec -T postgres pg_isready -U prism; do
  echo "Database is unavailable - sleeping"
  sleep 1
done

echo "‚úÖ Database is ready!"

# Run migrations for each service
services=("user-service" "project-service" "validation-service" "registry-service" "exchange-service")

for service in "${services[@]}"; do
  echo "üîÑ Running migrations for $service..."
  docker-compose exec -T $service alembic upgrade head
done

echo "‚úÖ All migrations completed!"
'''

    def _get_docs_readme(self) -> str:
        return '''# PRISM Carbon Registry Documentation

This directory contains comprehensive documentation for the PRISM Carbon Registry Platform.

## Documentation Structure

### üìã [Architecture](architecture/)
- [System Overview](architecture/overview.md)
- [Service Architecture](architecture/services.md)
- [Database Design](architecture/database.md)
- [Security Architecture](architecture/security.md)

### üöÄ [Deployment](deployment/)
- [Local Development Setup](deployment/local.md)
- [Production Deployment](deployment/production.md)
- [Kubernetes Configuration](deployment/kubernetes.md)
- [Monitoring Setup](deployment/monitoring.md)

### üîß [Development](development/)
- [Getting Started](development/getting-started.md)
- [Contributing Guidelines](development/contributing.md)
- [Code Standards](development/standards.md)
- [Testing Guide](development/testing.md)

### üìö [API Documentation](api/)
- [OpenAPI Specification](api/openapi.yml)
- [Authentication](api/authentication.md)
- [Error Handling](api/errors.md)
- [Rate Limiting](api/rate-limiting.md)

### üë• [User Guides](user-guides/)
- [Project Developer Guide](user-guides/project-developer.md)
- [Validator Guide](user-guides/validator.md)
- [Trader Guide](user-guides/trader.md)
- [Administrator Guide](user-guides/administrator.md)

## Quick Navigation

- **New Developer?** Start with [Getting Started](development/getting-started.md)
- **Deploying?** Check [Production Deployment](deployment/production.md)
- **API Integration?** See [API Documentation](api/)
- **Need Help?** Contact the development team

## Contributing to Documentation

We welcome contributions to improve our documentation. Please:

1. Follow the [Contributing Guidelines](development/contributing.md)
2. Use clear, concise language
3. Include code examples where helpful
4. Update the table of contents when adding new sections

## License

This documentation is part of the PRISM Carbon Registry Platform and is licensed under [LICENSE].
'''

    def _get_architecture_overview(self) -> str:
        return '''# PRISM Carbon Registry - Architecture Overview

## System Architecture

The PRISM Carbon Registry Platform is built using a microservices architecture that provides scalability, maintainability, and flexibility for carbon credit management operations.

## High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Web App       ‚îÇ    ‚îÇ   Mobile App    ‚îÇ    ‚îÇ   Admin Panel   ‚îÇ
‚îÇ   (React)       ‚îÇ    ‚îÇ (React Native)  ‚îÇ    ‚îÇ   (React)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   API Gateway   ‚îÇ
                    ‚îÇ   (FastAPI)     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                       ‚îÇ                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User Service   ‚îÇ    ‚îÇ Project Service ‚îÇ    ‚îÇRegistry Service ‚îÇ
‚îÇ   (FastAPI)     ‚îÇ    ‚îÇ   (FastAPI)     ‚îÇ    ‚îÇ   (FastAPI)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Event Bus     ‚îÇ
                    ‚îÇ   (Redis)       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Core Principles

### 1. Domain-Driven Design (DDD)
- Clear domain boundaries between services
- Business logic encapsulated in domain entities
- Rich domain models with behavior

### 2. Clean Architecture
- Dependencies point inward toward the domain
- Infrastructure concerns separated from business logic
- Framework-agnostic core logic

### 3. Event-Driven Architecture
- Loose coupling between services
- Asynchronous processing where appropriate
- Event sourcing for audit trails

### 4. CQRS (Command Query Responsibility Segregation)
- Separate read and write models
- Optimized queries for different use cases
- Better scalability for read-heavy operations

## Service Boundaries

### Core Services
- **User Service**: Authentication, authorization, user management
- **Project Service**: Carbon project lifecycle management
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading and marketplace

### Supporting Services
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

### Infrastructure Services
- **API Gateway**: Request routing, authentication, rate limiting
- **Event Bus**: Inter-service communication
- **Monitoring**: Metrics, logging, alerting

## Data Architecture

### Database Strategy
- **Database per Service**: Each service owns its data
- **PostgreSQL**: Primary database for relational data
- **MongoDB**: Document storage for semi-structured data
- **Redis**: Caching and session storage

### Blockchain Integration
- **Hedera Hashgraph**: Primary blockchain for carbon credits
- **Smart Contracts**: ERC-1155 tokens for carbon assets
- **IPFS**: Decentralized metadata storage

## Security Architecture

### Authentication & Authorization
- **JWT Tokens**: Stateless authentication
- **Role-Based Access Control (RBAC)**: Fine-grained permissions
- **OAuth2**: External identity provider integration

### Data Protection
- **Encryption at Rest**: Database and file encryption
- **Encryption in Transit**: TLS for all communications
- **Secret Management**: HashiCorp Vault integration

## Scalability & Performance

### Horizontal Scaling
- **Stateless Services**: Easy to scale horizontally
- **Load Balancing**: Distribute traffic across instances
- **Auto-scaling**: Based on metrics and demand

### Caching Strategy
- **Redis**: Distributed caching
- **CDN**: Static asset delivery
- **Query Optimization**: Efficient database queries

## Monitoring & Observability

### Metrics
- **Prometheus**: Metrics collection
- **Grafana**: Visualization and dashboards
- **Custom Metrics**: Business-specific KPIs

### Logging
- **Structured Logging**: JSON format for better parsing
- **Centralized Logs**: ELK stack or similar
- **Correlation IDs**: Request tracing across services

### Tracing
- **Distributed Tracing    def _get_frontend_index_tsx(self) -> str:
        return '''import React from 'react';
import ReactDOM from 'react-dom/client';
import './index.css';
import App from './App';

const root = ReactDOM.createRoot(
  document.getElementById('root') as HTMLElement
);

root.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);
'''

    def _get_frontend_index_html(self) -> str:
        return '''<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta
      name="description"
      content="PRISM Carbon Registry Platform"
    />
    <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <title>PRISM Carbon Registry</title>
  </head>
  <body>
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root"></div>
  </body>
</html>
'''

    def _get_frontend_dockerfile(self) -> str:
        return '''# Build stage
FROM node:18-alpine as build

WORKDIR /app

# Copy package files
COPY package*.json ./
RUN npm ci --only=production

# Copy source code
COPY . .

# Build the app
RUN npm run build

# Production stage
FROM nginx:alpine

# Copy built app
COPY --from=build /app/build /usr/share/nginx/html

# Copy nginx config
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
'''

    def _get_button_component(self) -> str:
        return '''import React from 'react';
import { Button as MuiButton, ButtonProps } from '@mui/material';

interface CustomButtonProps extends ButtonProps {
  loading?: boolean;
}

const Button: React.FC<CustomButtonProps> = ({ 
  children, 
  loading = false, 
  disabled,
  ...props 
}) => {
  return (
    <MuiButton
      {...props}
      disabled={disabled || loading}
    >
      {loading ? 'Loading...' : children}
    </MuiButton>
  );
};

export default Button;
'''

    def _get_modal_component(self) -> str:
        return '''import React from 'react';
import {
  Dialog,
  DialogTitle,
  DialogContent,
  DialogActions,
  IconButton,
} from '@mui/material';
import CloseIcon from '@mui/icons-material/Close';

interface ModalProps {
  open: boolean;
  onClose: () => void;
  title?: string;
  children: React.ReactNode;
  actions?: React.ReactNode;
  maxWidth?: 'xs' | 'sm' | 'md' | 'lg' | 'xl';
}

const Modal: React.FC<ModalProps> = ({
  open,
  onClose,
  title,
  children,
  actions,
  maxWidth = 'md'
}) => {
  return (
    <Dialog
      open={open}
      onClose={onClose}
      maxWidth={maxWidth}
      fullWidth
    >
      {title && (
        <DialogTitle>
          {title}
          <IconButton
            aria-label="close"
            onClick={onClose}
            sx={{
              position: 'absolute',
              right: 8,
              top: 8,
            }}
          >
            <CloseIcon />
          </IconButton>
        </DialogTitle>
      )}
      <DialogContent>
        {children}
      </DialogContent>
      {actions && (
        <DialogActions>
          {actions}
        </DialogActions>
      )}
    </Dialog>
  );
};

export default Modal;
'''

    def _get_home_page(self) -> str:
        return '''import React from 'react';
import { Box, Container, Typography, Button, Grid, Card, CardContent } from '@mui/material';
import { useNavigate } from 'react-router-dom';

const HomePage: React.FC = () => {
  const navigate = useNavigate();

  const features = [
    {
      title: 'Project Origination',
      description: 'Create and manage carbon reduction projects with AI-powered assistance',
    },
    {
      title: 'Digital MRV',
      description: 'Automated monitoring, reporting, and verification using satellite data',
    },
    {
      title: 'Blockchain Registry',
      description: 'Secure, transparent carbon credit registry on Hedera Hashgraph',
    },
    {
      title: 'Credit Exchange',
      description: 'Trade carbon credits in a liquid, efficient marketplace',
    },
  ];

  return (
    <Box>
      {/* Hero Section */}
      <Box
        sx={{
          bgcolor: 'primary.main',
          color: 'white',
          py: 8,
        }}
      >
        <Container maxWidth="lg">
          <Typography variant="h2" component="h1" gutterBottom>
            PRISM Carbon Registry
          </Typography>
          <Typography variant="h5" component="p" sx={{ mb: 4 }}>
            The future of carbon credit management - transparent, efficient, and blockchain-powered
          </Typography>
          <Button
            variant="contained"
            color="secondary"
            size="large"
            onClick={() => navigate('/dashboard')}
          >
            Get Started
          </Button>
        </Container>
      </Box>

      {/* Features Section */}
      <Container maxWidth="lg" sx={{ py: 8 }}>
        <Typography variant="h3" component="h2" textAlign="center" gutterBottom>
          Platform Features
        </Typography>
        <Grid container spacing={4} sx={{ mt: 2 }}>
          {features.map((feature, index) => (
            <Grid item xs={12} md={6} key={index}>
              <Card sx={{ height: '100%' }}>
                <CardContent>
                  <Typography variant="h5" component="h3" gutterBottom>
                    {feature.title}
                  </Typography>
                  <Typography variant="body1">
                    {feature.description}
                  </Typography>
                </CardContent>
              </Card>
            </Grid>
          ))}
        </Grid>
      </Container>
    </Box>
  );
};

export default HomePage;
'''

    def _get_dashboard_page(self) -> str:
        return '''import React from 'react';
import { Box, Container, Typography, Grid, Card, CardContent, Paper } from '@mui/material';
import { useAuth } from '../hooks/useAuth';

const DashboardPage: React.FC = () => {
  const { user } = useAuth();

  const stats = [
    { label: 'Active Projects', value: '12', color: '#2e7d32' },
    { label: 'Credits Issued', value: '45,230', color: '#1976d2' },
    { label: 'Credits Traded', value: '23,450', color: '#ed6c02' },
    { label: 'Credits Retired', value: '8,760', color: '#d32f2f' },
  ];

  return (
    <Container maxWidth="lg" sx={{ py: 4 }}>
      <Typography variant="h4" component="h1" gutterBottom>
        Welcome back, {user?.full_name}!
      </Typography>
      
      {/* Stats Grid */}
      <Grid container spacing={3} sx={{ mb: 4 }}>
        {stats.map((stat, index) => (
          <Grid item xs={12} sm={6} md={3} key={index}>
            <Card>
              <CardContent>
                <Typography color="textSecondary" gutterBottom>
                  {stat.label}
                </Typography>
                <Typography variant="h5" component="div" sx={{ color: stat.color }}>
                  {stat.value}
                </Typography>
              </CardContent>
            </Card>
          </Grid>
        ))}
      </Grid>

      {/* Recent Activity */}
      <Paper sx={{ p: 3 }}>
        <Typography variant="h6" gutterBottom>
          Recent Activity
        </Typography>
        <Typography variant="body2" color="textSecondary">
          Recent project and transaction activity will be displayed here.
        </Typography>
      </Paper>
    </Container>
  );
};

export default DashboardPage;
'''

    def _get_use_auth_hook(self) -> str:
        return '''import { useContext } from 'react';
import { AuthContext } from '../context/AuthContext';

export const useAuth = () => {
  const context = useContext(AuthContext);
  
  if (context === undefined) {
    throw new Error('useAuth must be used within an AuthProvider');
  }
  
  return context;
};
'''

    def _get_auth_context(self) -> str:
        return '''import React, { createContext, useState, useEffect, ReactNode } from 'react';
import apiClient from '../services/api/client';

interface User {
  id: string;
  email: string;
  full_name: string;
  organization?: string;
  role: string;
}

interface AuthContextType {
  user: User | null;
  login: (email: string, password: string) => Promise<void>;
  logout: () => void;
  loading: boolean;
}

export const AuthContext = createContext<AuthContextType | undefined>(undefined);

interface AuthProviderProps {
  children: ReactNode;
}

export const AuthProvider: React.FC<AuthProviderProps> = ({ children }) => {
  const [user, setUser] = useState<User | null>(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    // Check if user is already logged in
    const token = localStorage.getItem('access_token');
    if (token) {
      // Verify token and get user info
      fetchUserProfile();
    } else {
      setLoading(false);
    }
  }, []);

  const fetchUserProfile = async () => {
    try {
      const userData = await apiClient.getProfile();
      setUser(userData);
    } catch (error) {
      localStorage.removeItem('access_token');
    } finally {
      setLoading(false);
    }
  };

  const login = async (email: string, password: string) => {
    try {
      const response = await apiClient.login(email, password);
      localStorage.setItem('access_token', response.access_token);
      await fetchUserProfile();
    } catch (error) {
      throw error;
    }
  };

  const logout = () => {
    localStorage.removeItem('access_token');
    setUser(null);
  };

  return (
    <AuthContext.Provider value={{ user, login, logout, loading }}>
      {children}
    </AuthContext.Provider>
  );
};
'''

    def _get_auth_service(self) -> str:
        return '''import apiClient from './client';

export interface LoginCredentials {
  email: string;
  password: string;
}

export interface RegisterData {
  email: string;
  password: string;
  full_name: string;
  organization?: string;
  country: string;
}

class AuthService {
  async login(credentials: LoginCredentials) {
    return await apiClient.login(credentials.email, credentials.password);
  }

  async register(userData: RegisterData) {
    return await apiClient.register(userData);
  }

  async refreshToken() {
    return await apiClient.refreshToken();
  }

  logout() {
    localStorage.removeItem('access_token');
  }

  getToken(): string | null {
    return localStorage.getItem('access_token');
  }

  isAuthenticated(): boolean {
    return !!this.getToken();
  }
}

export default new AuthService();
'''

export interface User {
  id: string;
  email: string;
  full_name: string;
  organization?: string;
  phone?: string;
  country?: string;
  role: UserRole;
  status: UserStatus;
  is_verified: boolean;
  created_at: string;
  updated_at: string;
}

export interface Project {
  id: string;
  project_id: string;
  name: string;
  description?: string;
  project_type: ProjectType;
  methodology?: string;
  country: string;
  region?: string;
  area_hectares?: number;
  estimated_annual_reduction?: number;
  total_estimated_reduction?: number;
  crediting_period_start?: string;
  crediting_period_end?: string;
  status: ProjectStatus;
  owner_id: string;
  validator_id?: string;
  issued_credits: number;
  available_credits: number;
  retired_credits: number;
  created_at: string;
  updated_at: string;
}

export interface Document {
  id: string;
  project_id: string;
  title: string;
  document_type: DocumentType;
  file_path: string;
  file_size: number;
  file_extension: string;
  uploaded_by: string;
  is_public: boolean;
  created_at: string;
}

export interface CarbonCredit {
  id: string;
  project_id: string;
  batch_id: string;
  amount: number;
  status: CreditStatus;
  issued_to: string;
  vintage_year: number;
  blockchain_tx_hash?: string;
  created_at: string;
}

export enum UserRole {
  ADMIN = 'admin',
  PROJECT_DEVELOPER = 'project_developer',
  VALIDATOR = 'validator',
  AUDITOR = 'auditor',
  REGISTRY_ADMIN = 'registry_admin',
  TRADER = 'trader',
  BUYER = 'buyer',
}

export enum UserStatus {
  ACTIVE = 'active',
  INACTIVE = 'inactive',
  SUSPENDED = 'suspended',
  PENDING = 'pending',
}

export enum ProjectType {
  FORESTRY = 'forestry',
  RENEWABLE_ENERGY = 'renewable_energy',
  ENERGY_EFFICIENCY = 'energy_efficiency',
  METHANE_CAPTURE = 'methane_capture',
  INDUSTRIAL = 'industrial',
  AGRICULTURE = 'agriculture',
  WASTE_MANAGEMENT = 'waste_management',
  TRANSPORT = 'transport',
  BLUE_CARBON = 'blue_carbon',
  DIRECT_AIR_CAPTURE = 'direct_air_capture',
}

export enum ProjectStatus {
  DRAFT = 'draft',
  SUBMITTED = 'submitted',
  UNDER_VALIDATION = 'under_validation',
  VALIDATED = 'validated',
  REJECTED = 'rejected',
  REGISTERED = 'registered',
  ACTIVE = 'active',
  SUSPENDED = 'suspended',
  COMPLETED = 'completed',
}

export enum DocumentType {
  PDD = 'pdd',
  MONITORING_REPORT = 'monitoring_report',
  VALIDATION_REPORT = 'validation_report',
  VERIFICATION_REPORT = 'verification_report',
  PROJECT_PHOTO = 'project_photo',
  SATELLITE_IMAGE = 'satellite_image',
  LEGAL_DOCUMENT = 'legal_document',
  CERTIFICATE = 'certificate',
  OTHER = 'other',
}

export enum CreditStatus {
  ISSUED = 'issued',
  AVAILABLE = 'available',
  RESERVED = 'reserved',
  TRANSFERRED = 'transferred',
  RETIRED = 'retired',
  CANCELLED = 'cancelled',
}

export interface ApiResponse<T> {
  data: T;
  message?: string;
  success: boolean;
}

export interface PaginatedResponse<T> {
  items: T[];
  total: number;
  page: number;
  size: number;
  pages: number;
}

export interface ErrorResponse {
  error_code: string;
  message: string;
  details: Record<string, any>;
}
'''

    def _get_frontend_constants(self) -> str:
        return '''// Constants for the frontend application

export const API_ENDPOINTS = {
  // Auth endpoints
  LOGIN: '/api/v1/auth/login',
  REGISTER: '/api/v1/auth/register',
  REFRESH: '/api/v1/auth/refresh',
  LOGOUT: '/api/v1/auth/logout',
  
  // User endpoints
  PROFILE: '/api/v1/users/me',
  USERS: '/api/v1/users',
  
  // Project endpoints
  PROJECTS: '/api/v1/projects',
  PROJECT_DOCUMENTS: '/api/v1/projects/{id}/documents',
  PROJECT_SUBMIT: '/api/v1/projects/{id}/submit',
  
  // Registry endpoints
  REGISTRY: '/api/v1/registry',
  CREDITS: '/api/v1/registry/credits',
  
  // Exchange endpoints
  ORDERS: '/api/v1/exchange/orders',
  TRADES: '/api/v1/exchange/trades',
};

export const FILE_UPLOAD = {
  MAX_SIZE: 50 * 1024 * 1024, // 50MB
  ALLOWED_TYPES: [
    'application/pdf',
    'application/msword',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'image/jpeg',
    'image/png',
    'image/gif',
    'application/vnd.ms-excel',
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    'application/zip',
  ],
  ALLOWED_EXTENSIONS: ['pdf', 'doc', 'docx', 'jpg', 'jpeg', 'png', 'gif', 'xls', 'xlsx', 'zip'],
};

export const PAGINATION = {
  DEFAULT_PAGE_SIZE: 20,
  MAX_PAGE_SIZE: 100,
};

export const ROUTES = {
  HOME: '/',
  LOGIN: '/login',
  REGISTER: '/register',
  DASHBOARD: '/dashboard',
  PROFILE: '/profile',
  PROJECTS: '/projects',
  PROJECT_DETAIL: '/projects/:id',
  CREATE_PROJECT: '/projects/create',
  REGISTRY: '/registry',
  EXCHANGE: '/exchange',
  ADMIN: '/admin',
};

export const STATUS_COLORS = {
  // Project status colors
  draft: '#gray',
  submitted: '#blue',
  under_validation: '#orange',
  validated: '#green',
  rejected: '#red',
  registered: '#purple',
  active: '#teal',
  suspended: '#yellow',
  completed: '#indigo',
  
  // Credit status colors
  issued: '#green',
  available: '#blue',
  reserved: '#orange',
  transferred: '#purple',
  retired: '#gray',
  cancelled: '#red',
};

export const DOCUMENT_ICONS = {
  pdd: 'description',
  monitoring_report: 'analytics',
  validation_report: 'verified',
  verification_report: 'shield',
  project_photo: 'photo_camera',
  satellite_image: 'satellite',
  legal_document: 'gavel',
  certificate: 'workspace_premium',
  other: 'insert_drive_file',
};

export const PROJECT_TYPE_LABELS = {
  forestry: 'Forestry & Land Use',
  renewable_energy: 'Renewable Energy',
  energy_efficiency: 'Energy Efficiency',
  methane_capture: 'Methane Capture',
  industrial: 'Industrial Processes',
  agriculture: 'Agriculture',
  waste_management: 'Waste Management',
  transport: 'Transportation',
  blue_carbon: 'Blue Carbon',
  direct_air_capture: 'Direct Air Capture',
};

export const USER_ROLE_LABELS = {
  admin: 'Administrator',
  project_developer: 'Project Developer',
  validator: 'Validator',
  auditor: 'Auditor',
  registry_admin: 'Registry Administrator',
  trader: 'Trader',
  buyer: 'Buyer',
};

export const VALIDATION_RULES = {
  EMAIL: /^[^\s@]+@[^\s@]+\.[^\s@]+$/,
  PHONE: /^\+?[\d\s\-\(\)]+$/,
  PROJECT_ID: /^[a-zA-Z0-9_-]+$/,
  PASSWORD_MIN_LENGTH: 8,
};

export const TOAST_DURATION = 5000;

export const CHART_COLORS = [
  '#2e7d32',
  '#1976d2',
  '#ed6c02',
  '#d32f2f',
  '#7b1fa2',
  '#00796b',
  '#f57c00',
  '#5d4037',
];
'''

    def _get_frontend_test_setup(self) -> str:
        return '''// Test setup for React application

import '@testing-library/jest-dom';
import { configure } from '@testing-library/react';

// Configure testing library
configure({
  testIdAttribute: 'data-testid',
});

// Mock localStorage
const localStorageMock = {
  getItem: jest.fn(),
  setItem: jest.fn(),
  removeItem: jest.fn(),
  clear: jest.fn(),
};

global.localStorage = localStorageMock;

// Mock window.matchMedia
Object.defineProperty(window, 'matchMedia', {
  writable: true,
  value: jest.fn().mockImplementation(query => ({
    matches: false,
    media: query,
    onchange: null,
    addListener: jest.fn(),
    removeListener: jest.fn(),
    addEventListener: jest.fn(),
    removeEventListener: jest.fn(),
    dispatchEvent: jest.fn(),
  })),
});

// Mock IntersectionObserver
global.IntersectionObserver = class IntersectionObserver {
  constructor() {}
  disconnect() {}
  observe() {}
  unobserve() {}
};

// Mock fetch
global.fetch = jest.fn();

// Setup test environment
beforeEach(() => {
  localStorage.clear();
  jest.clearAllMocks();
});
'''

    def _get_k8s_configmap(self) -> str:
        return '''apiVersion: v1
kind: ConfigMap
metadata:
  name: prism-config
  namespace: prism-carbon-registry
data:
  # Database configuration
  DATABASE_HOST: "postgres-service"
  DATABASE_PORT: "5432"
  DATABASE_NAME: "prism_core"
  
  # Redis configuration
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  
  # Application configuration
  LOG_LEVEL: "INFO"
  ENVIRONMENT: "production"
  
  # Service URLs
  USER_SERVICE_URL: "http://user-service:8000"
  PROJECT_SERVICE_URL: "http://project-service:8000"
  VALIDATION_SERVICE_URL: "http://validation-service:8000"
  REGISTRY_SERVICE_URL: "http://registry-service:8000"
  EXCHANGE_SERVICE_URL: "http://exchange-service:8000"
'''

    def _get_k8s_kustomization_dev(self) -> str:
        return '''apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: prism-carbon-registry

resources:
  - ../../base

patchesStrategicMerge:
  - deployment-patch.yaml
  - service-patch.yaml

configMapGenerator:
  - name: prism-config-dev
    literals:
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - DEBUG=true

images:
  - name: prism/api-gateway
    newTag: latest
  - name: prism/user-service
    newTag: latest
  - name: prism/project-service
    newTag: latest
'''

    def _get_terraform_variables(self) -> str:
        return '''variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-west-2"
}

variable "cluster_name" {
  description = "EKS cluster name"
  type        = string
  default     = "prism-carbon-registry"
}

variable "cluster_version" {
  description = "Kubernetes version"
  type        = string
  default     = "1.28"
}

variable "vpc_cidr" {
  description = "VPC CIDR block"
  type        = string
  default     = "10.0.0.0/16"
}

variable "availability_zones" {
  description = "Availability zones"
  type        = list(string)
  default     = ["us-west-2a", "us-west-2b", "us-west-2c"]
}

variable "node_groups" {
  description = "EKS node groups configuration"
  type = map(object({
    instance_types = list(string)
    capacity_type  = string
    min_size      = number
    max_size      = number
    desired_size  = number
  }))
  default = {
    general = {
      instance_types = ["t3.medium"]
      capacity_type  = "ON_DEMAND"
      min_size      = 1
      max_size      = 10
      desired_size  = 3
    }
  }
}

variable "db_allocated_storage" {
  description = "RDS allocated storage"
  type        = number
  default     = 100
}

variable "db_instance_class" {
  description = "RDS instance class"
  type        = string
  default     = "db.t3.micro"
}

variable "db_name" {
  description = "Database name"
  type        = string
  default     = "prism_core"
}

variable "db_username" {
  description = "Database username"
  type        = string
  default     = "prism"
}

variable "redis_node_type" {
  description = "Redis node type"
  type        = string
  default     = "cache.t3.micro"
}

variable "tags" {
  description = "Common tags"
  type        = map(string)
  default = {
    Project     = "PRISM Carbon Registry"
    Environment = "production"
    ManagedBy   = "Terraform"
  }
}
'''

    def _get_terraform_outputs(self) -> str:
        return '''output "cluster_endpoint" {
  description = "EKS cluster endpoint"
  value       = module.eks.cluster_endpoint
}

output "cluster_name" {
  description = "EKS cluster name"
  value       = module.eks.cluster_name
}

output "cluster_arn" {
  description = "EKS cluster ARN"
  value       = module.eks.cluster_arn
}

output "vpc_id" {
  description = "VPC ID"
  value       = module.vpc.vpc_id
}

output "private_subnets" {
  description = "Private subnet IDs"
  value       = module.vpc.private_subnets
}

output "database_endpoint" {
  description = "RDS database endpoint"
  value       = module.rds.endpoint
  sensitive   = true
}

output "redis_endpoint" {
  description = "Redis cluster endpoint"
  value       = module.redis.endpoint
}
'''

    def _get_grafana_dashboard(self) -> str:
        return '''{
  "dashboard": {
    "id": null,
    "title": "PRISM Carbon Registry Dashboard",
    "tags": ["prism", "carbon", "registry"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Service Health",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=~\".*-service\"}",
            "legendFormat": "{{job}}"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 0
        }
      },
      {
        "id": 2,
        "title": "API Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 0
        }
      },
      {
        "id": 3,
        "title": "Total Projects",
        "type": "stat",
        "targets": [
          {
            "expr": "prism_projects_total",
            "legendFormat": "Projects"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 6,
          "x": 0,
          "y": 8
        }
      },
      {
        "id": 4,
        "title": "Credits Issued",
        "type": "stat",
        "targets": [
          {
            "expr": "prism_credits_issued_total",
            "legendFormat": "Credits"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 6,
          "x": 6,
          "y": 8
        }
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s"
  }
}
'''

    def _get_pyproject_toml(self) -> str:
        return '''[tool.black]
line-length = 88
target-version = ['py311']
include = '\.pyi?def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item for sublist in nested_list for item in sublist]

def remove_duplicates(lst: List[Any]) -> List[Any]:
    """
    Remove duplicates from list while preserving order
    """
    seen = set()
    result = []
    for item in lst:
        if item not in seen:
            seen.add(item)
            result.append(item)
    return result

def is_valid_url(url: str) -> bool:
    """
    Check if string is a valid URL
    """
    import re
    url_pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)
        return '''"""
Validation utilities and helpers
"""

import re
from typing import Any, Dict, List, Optional, Tuple
from email_validator import validate_email, EmailNotValidError

def validate_email_address(email: str) -> Tuple[bool, Optional[str]]:
    """
    Validate email address
    Returns (is_valid, error_message)
    """
    try:
        valid = validate_email(email)
        return True, None
    except EmailNotValidError as e:
        return False, str(e)

def validate_phone_number(phone: str) -> Tuple[bool, Optional[str]]:
    """
    Validate phone number (basic validation)
    Returns (is_valid, error_message)
    """
    # Remove all non-digit characters
    digits_only = re.sub(r'\D', '', phone)
    
    if len(digits_only) < 10:
        return False, "Phone number must have at least 10 digits"
    
    if len(digits_only) > 15:
        return False, "Phone number cannot exceed 15 digits"
    
    return True, None

def validate_password_strength(password: str) -> Tuple[bool, List[str]]:
    """
    Validate password strength
    Returns (is_valid, list_of_issues)
    """
    issues = []
    
    if len(password) < 8:
        issues.append("Password must be at least 8 characters long")
    
    if not re.search(r'[A-Z]', password):
        issues.append("Password must contain at least one uppercase letter")
    
    if not re.search(r'[a-z]', password):
        issues.append("Password must contain at least one lowercase letter")
    
    if not re.search(r'\d', password):
        issues.append("Password must contain at least one digit")
    
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        issues.append("Password must contain at least one special character")
    
    return len(issues) == 0, issues

def validate_project_id(project_id: str) -> Tuple[bool, Optional[str]]:
    """
    Validate project ID format
    Returns (is_valid, error_message)
    """
    if not project_id:
        return False, "Project ID cannot be empty"
    
    if len(project_id) < 3:
        return False, "Project ID must be at least 3 characters long"
    
    if len(project_id) > 50:
        return False, "Project ID cannot exceed 50 characters"
    
    # Allow alphanumeric, hyphens, and underscores
    if not re.match(r'^[a-zA-Z0-9_-]+#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, project_id):
        return False, "Project ID can only contain letters, numbers, hyphens, and underscores"
    
    return True, None

def validate_coordinates(latitude: float, longitude: float) -> Tuple[bool, Optional[str]]:
    """
    Validate GPS coordinates
    Returns (is_valid, error_message)
    """
    if not (-90 <= latitude <= 90):
        return False, "Latitude must be between -90 and 90 degrees"
    
    if not (-180 <= longitude <= 180):
        return False, "Longitude must be between -180 and 180 degrees"
    
    return True, None

def validate_file_extension(filename: str, allowed_extensions: List[str]) -> Tuple[bool, Optional[str]]:
    """
    Validate file extension
    Returns (is_valid, error_message)
    """
    if not filename:
        return False, "Filename cannot be empty"
    
    extension = filename.lower().split('.')[-1] if '.' in filename else ''
    
    if extension not in [ext.lower() for ext in allowed_extensions]:
        return False, f"File extension '{extension}' not allowed. Allowed: {', '.join(allowed_extensions)}"
    
    return True, None

def sanitize_filename(filename: str) -> str:
    """
    Sanitize filename for safe storage
    """
    # Remove or replace unsafe characters
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # Remove leading/trailing spaces and dots
    filename = filename.strip(' .')
    
    # Ensure filename is not empty
    if not filename:
        filename = "unnamed_file"
    
    return filename

def validate_amount(amount: Any, min_value: float = 0, max_value: Optional[float] = None) -> Tuple[bool, Optional[str]]:
    """
    Validate numeric amount
    Returns (is_valid, error_message)
    """
    try:
        amount = float(amount)
    except (TypeError, ValueError):
        return False, "Amount must be a valid number"
    
    if amount < min_value:
        return False, f"Amount must be at least {min_value}"
    
    if max_value is not None and amount > max_value:
        return False, f"Amount cannot exceed {max_value}"
    
    return True, None
'''

    def _get_serialization_utils(self) -> str:
        return '''"""
Serialization utilities
"""

import json
from datetime import datetime, date
from decimal import Decimal
from typing import Any, Dict
from uuid import UUID

class CustomJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder to handle additional types"""
    
    def default(self, obj: Any) -> Any:
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, date):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, UUID):
            return str(obj)
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)

def serialize_to_json(data: Any) -> str:
    """
    Serialize data to JSON string
    """
    return json.dumps(data, cls=CustomJSONEncoder, ensure_ascii=False)

def deserialize_from_json(json_str: str) -> Any:
    """
    Deserialize JSON string to Python object
    """
    return json.loads(json_str)

def dict_to_model(data: Dict[str, Any], model_class):
    """
    Convert dictionary to Pydantic model instance
    """
    return model_class(**data)

def model_to_dict(model_instance) -> Dict[str, Any]:
    """
    Convert Pydantic model instance to dictionary
    """
    if hasattr(model_instance, 'dict'):
        return model_instance.dict()
    elif hasattr(model_instance, '__dict__'):
        return model_instance.__dict__
    else:
        raise ValueError("Object cannot be converted to dictionary")

def camel_to_snake(name: str) -> str:
    """
    Convert camelCase to snake_case
    """
    import re
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

def snake_to_camel(name: str) -> str:
    """
    Convert snake_case to camelCase
    """
    components = name.split('_')
    return components[0] + ''.join(word.capitalize() for word in components[1:])
'''

    def _get_helper_utils(self) -> str:
        return '''"""
General helper utilities
"""

import hashlib
import secrets
import string
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import uuid

def generate_uuid() -> str:
    """Generate a new UUID string"""
    return str(uuid.uuid4())

def generate_random_string(length: int = 32, use_letters: bool = True, use_digits: bool = True) -> str:
    """
    Generate a random string of specified length
    """
    characters = ""
    if use_letters:
        characters += string.ascii_letters
    if use_digits:
        characters += string.digits
    
    if not characters:
        raise ValueError("Must include at least letters or digits")
    
    return ''.join(secrets.choice(characters) for _ in range(length))

def generate_api_key() -> str:
    """Generate a secure API key"""
    return f"pk_{''.join(secrets.choice(string.ascii_letters + string.digits) for _ in range(32))}"

def hash_string(input_string: str, salt: str = "") -> str:
    """
    Generate SHA-256 hash of a string
    """
    return hashlib.sha256((input_string + salt).encode()).hexdigest()

def verify_hash(input_string: str, hash_value: str, salt: str = "") -> bool:
    """
    Verify if input string matches the hash
    """
    return hash_string(input_string, salt) == hash_value

def truncate_string(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Truncate string to specified length with suffix
    """
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_date_string(date_str: str) -> Optional[datetime]:
    """
    Parse date string in various formats
    """
    formats = [
        "%Y-%m-%d",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S.%fZ",
        "%d/%m/%Y",
        "%m/%d/%Y",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    return None

def format_file_size(size_bytes: int) -> str:
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def clean_dict(data: Dict[str, Any], remove_none: bool = True, remove_empty: bool = False) -> Dict[str, Any]:
    """
    Clean dictionary by removing None or empty values
    """
    cleaned = {}
    
    for key, value in data.items():
        if remove_none and value is None:
            continue
        
        if remove_empty and (value == "" or value == [] or value == {}):
            continue
        
        cleaned[key] = value
    
    return cleaned

def merge_dicts(*dicts: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge multiple dictionaries
    """
    result = {}
    for d in dicts:
        if d:
            result.update(d)
    return result

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """
    Split list into chunks of specified size
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, re.IGNORECASE)
    return url_pattern.match(url) is not None
'''

    def _get_hedera_utils(self) -> str:
        return '''"""
Hedera Hashgraph utility functions
"""

import hashlib
import json
from typing import Dict, Any, Optional

def generate_token_id(project_id: str, batch_number: int = 1) -> int:
    """
    Generate a deterministic token ID from project ID and batch number
    """
    # Create a hash of project_id + batch_number
    hash_input = f"{project_id}_{batch_number}"
    hash_bytes = hashlib.sha256(hash_input.encode()).digest()
    
    # Convert first 8 bytes to integer (to fit in uint256)
    return int.from_bytes(hash_bytes[:8], byteorder='big')

def format_hedera_amount(amount: int) -> str:
    """
    Format amount for Hedera transactions (in tinybars)
    """
    return str(amount * 100000000)  # Convert to tinybars

def validate_hedera_account_id(account_id: str) -> bool:
    """
    Validate Hedera account ID format (0.0.xxxxx)
    """
    import re
    pattern = r'^0\.0\.\d+
        return '''"""
Validation utilities and helpers
"""

import re
from typing import Any, Dict, List, Optional, Tuple
from email_validator import validate_email, EmailNotValidError

def validate_email_address(email: str) -> Tuple[bool, Optional[str]]:
    """
    Validate email address
    Returns (is_valid, error_message)
    """
    try:
        valid = validate_email(email)
        return True, None
    except EmailNotValidError as e:
        return False, str(e)

def validate_phone_number(phone: str) -> Tuple[bool, Optional[str]]:
    """
    Validate phone number (basic validation)
    Returns (is_valid, error_message)
    """
    # Remove all non-digit characters
    digits_only = re.sub(r'\D', '', phone)
    
    if len(digits_only) < 10:
        return False, "Phone number must have at least 10 digits"
    
    if len(digits_only) > 15:
        return False, "Phone number cannot exceed 15 digits"
    
    return True, None

def validate_password_strength(password: str) -> Tuple[bool, List[str]]:
    """
    Validate password strength
    Returns (is_valid, list_of_issues)
    """
    issues = []
    
    if len(password) < 8:
        issues.append("Password must be at least 8 characters long")
    
    if not re.search(r'[A-Z]', password):
        issues.append("Password must contain at least one uppercase letter")
    
    if not re.search(r'[a-z]', password):
        issues.append("Password must contain at least one lowercase letter")
    
    if not re.search(r'\d', password):
        issues.append("Password must contain at least one digit")
    
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        issues.append("Password must contain at least one special character")
    
    return len(issues) == 0, issues

def validate_project_id(project_id: str) -> Tuple[bool, Optional[str]]:
    """
    Validate project ID format
    Returns (is_valid, error_message)
    """
    if not project_id:
        return False, "Project ID cannot be empty"
    
    if len(project_id) < 3:
        return False, "Project ID must be at least 3 characters long"
    
    if len(project_id) > 50:
        return False, "Project ID cannot exceed 50 characters"
    
    # Allow alphanumeric, hyphens, and underscores
    if not re.match(r'^[a-zA-Z0-9_-]+#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, project_id):
        return False, "Project ID can only contain letters, numbers, hyphens, and underscores"
    
    return True, None

def validate_coordinates(latitude: float, longitude: float) -> Tuple[bool, Optional[str]]:
    """
    Validate GPS coordinates
    Returns (is_valid, error_message)
    """
    if not (-90 <= latitude <= 90):
        return False, "Latitude must be between -90 and 90 degrees"
    
    if not (-180 <= longitude <= 180):
        return False, "Longitude must be between -180 and 180 degrees"
    
    return True, None

def validate_file_extension(filename: str, allowed_extensions: List[str]) -> Tuple[bool, Optional[str]]:
    """
    Validate file extension
    Returns (is_valid, error_message)
    """
    if not filename:
        return False, "Filename cannot be empty"
    
    extension = filename.lower().split('.')[-1] if '.' in filename else ''
    
    if extension not in [ext.lower() for ext in allowed_extensions]:
        return False, f"File extension '{extension}' not allowed. Allowed: {', '.join(allowed_extensions)}"
    
    return True, None

def sanitize_filename(filename: str) -> str:
    """
    Sanitize filename for safe storage
    """
    # Remove or replace unsafe characters
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # Remove leading/trailing spaces and dots
    filename = filename.strip(' .')
    
    # Ensure filename is not empty
    if not filename:
        filename = "unnamed_file"
    
    return filename

def validate_amount(amount: Any, min_value: float = 0, max_value: Optional[float] = None) -> Tuple[bool, Optional[str]]:
    """
    Validate numeric amount
    Returns (is_valid, error_message)
    """
    try:
        amount = float(amount)
    except (TypeError, ValueError):
        return False, "Amount must be a valid number"
    
    if amount < min_value:
        return False, f"Amount must be at least {min_value}"
    
    if max_value is not None and amount > max_value:
        return False, f"Amount cannot exceed {max_value}"
    
    return True, None
'''

    def _get_serialization_utils(self) -> str:
        return '''"""
Serialization utilities
"""

import json
from datetime import datetime, date
from decimal import Decimal
from typing import Any, Dict
from uuid import UUID

class CustomJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder to handle additional types"""
    
    def default(self, obj: Any) -> Any:
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, date):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, UUID):
            return str(obj)
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)

def serialize_to_json(data: Any) -> str:
    """
    Serialize data to JSON string
    """
    return json.dumps(data, cls=CustomJSONEncoder, ensure_ascii=False)

def deserialize_from_json(json_str: str) -> Any:
    """
    Deserialize JSON string to Python object
    """
    return json.loads(json_str)

def dict_to_model(data: Dict[str, Any], model_class):
    """
    Convert dictionary to Pydantic model instance
    """
    return model_class(**data)

def model_to_dict(model_instance) -> Dict[str, Any]:
    """
    Convert Pydantic model instance to dictionary
    """
    if hasattr(model_instance, 'dict'):
        return model_instance.dict()
    elif hasattr(model_instance, '__dict__'):
        return model_instance.__dict__
    else:
        raise ValueError("Object cannot be converted to dictionary")

def camel_to_snake(name: str) -> str:
    """
    Convert camelCase to snake_case
    """
    import re
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

def snake_to_camel(name: str) -> str:
    """
    Convert snake_case to camelCase
    """
    components = name.split('_')
    return components[0] + ''.join(word.capitalize() for word in components[1:])
'''

    def _get_helper_utils(self) -> str:
        return '''"""
General helper utilities
"""

import hashlib
import secrets
import string
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import uuid

def generate_uuid() -> str:
    """Generate a new UUID string"""
    return str(uuid.uuid4())

def generate_random_string(length: int = 32, use_letters: bool = True, use_digits: bool = True) -> str:
    """
    Generate a random string of specified length
    """
    characters = ""
    if use_letters:
        characters += string.ascii_letters
    if use_digits:
        characters += string.digits
    
    if not characters:
        raise ValueError("Must include at least letters or digits")
    
    return ''.join(secrets.choice(characters) for _ in range(length))

def generate_api_key() -> str:
    """Generate a secure API key"""
    return f"pk_{''.join(secrets.choice(string.ascii_letters + string.digits) for _ in range(32))}"

def hash_string(input_string: str, salt: str = "") -> str:
    """
    Generate SHA-256 hash of a string
    """
    return hashlib.sha256((input_string + salt).encode()).hexdigest()

def verify_hash(input_string: str, hash_value: str, salt: str = "") -> bool:
    """
    Verify if input string matches the hash
    """
    return hash_string(input_string, salt) == hash_value

def truncate_string(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Truncate string to specified length with suffix
    """
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_date_string(date_str: str) -> Optional[datetime]:
    """
    Parse date string in various formats
    """
    formats = [
        "%Y-%m-%d",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S.%fZ",
        "%d/%m/%Y",
        "%m/%d/%Y",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    return None

def format_file_size(size_bytes: int) -> str:
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def clean_dict(data: Dict[str, Any], remove_none: bool = True, remove_empty: bool = False) -> Dict[str, Any]:
    """
    Clean dictionary by removing None or empty values
    """
    cleaned = {}
    
    for key, value in data.items():
        if remove_none and value is None:
            continue
        
        if remove_empty and (value == "" or value == [] or value == {}):
            continue
        
        cleaned[key] = value
    
    return cleaned

def merge_dicts(*dicts: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge multiple dictionaries
    """
    result = {}
    for d in dicts:
        if d:
            result.update(d)
    return result

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """
    Split list into chunks of specified size
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()

    return bool(re.match(pattern, account_id))

def create_metadata_json(project_data: Dict[str, Any]) -> str:
    """
    Create standardized metadata JSON for carbon tokens
    """
    metadata = {
        "name": project_data.get("name"),
        "description": project_data.get("description"),
        "image": project_data.get("image_url"),
        "attributes": [
            {
                "trait_type": "Project Type",
                "value": project_data.get("project_type")
            },
            {
                "trait_type": "Country",
                "value": project_data.get("country")
            },
            {
                "trait_type": "Methodology",
                "value": project_data.get("methodology")
            },
            {
                "trait_type": "Vintage Year",
                "value": project_data.get("vintage_year")
            }
        ],
        "external_url": project_data.get("external_url"),
        "carbon_credit_info": {
            "vintage_year": project_data.get("vintage_year"),
            "verification_standard": project_data.get("standard"),
            "additional_certifications": project_data.get("certifications", [])
        }
    }
    
    return json.dumps(metadata, ensure_ascii=False)
'''

    def _get_registry_interface(self) -> str:
        return '''"""
Registry interface for blockchain operations
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional

class IRegistryService(ABC):
    """Interface for registry service operations"""
    
    @abstractmethod
    async def register_project(self, project_id: str, metadata: Dict[str, Any]) -> str:
        """Register a new project and mint NFT"""
        pass
    
    @abstractmethod
    async def issue_credits(
        self, 
        project_id: str, 
        amount: int, 
        to_address: str,
        metadata: Dict[str, Any]
    ) -> str:
        """Issue carbon credits for a project"""
        pass
    
    @abstractmethod
    async def transfer_credits(
        self,
        from_address: str,
        to_address: str,
        token_id: int,
        amount: int
    ) -> str:
        """Transfer credits between addresses"""
        pass
    
    @abstractmethod
    async def retire_credits(
        self,
        owner_address: str,
        token_id: int,
        amount: int,
        retirement_reason: str
    ) -> str:
        """Retire (burn) carbon credits"""
        pass
    
    @abstractmethod
    async def get_credit_balance(self, address: str, token_id: int) -> int:
        """Get credit balance for an address"""
        pass
    
    @abstractmethod
    async def get_project_info(self, project_id: str) -> Optional[Dict[str, Any]]:
        """Get project information from blockchain"""
        pass
    
    @abstractmethod
    async def get_transaction_history(self, token_id: int) -> List[Dict[str, Any]]:
        """Get transaction history for a token"""
        pass

class IBlockchainClient(ABC):
    """Interface for blockchain client operations"""
    
    @abstractmethod
    async def deploy_contract(self, contract_code: str, constructor_args: List[Any]) -> str:
        """Deploy a smart contract"""
        pass
    
    @abstractmethod
    async def call_contract_function(
        self,
        contract_address: str,
        function_name: str,
        args: List[Any],
        sender_private_key: str
    ) -> str:
        """Call a contract function"""
        pass
    
    @abstractmethod
    async def get_transaction_receipt(self, tx_hash: str) -> Dict[str, Any]:
        """Get transaction receipt"""
        pass
    
    @abstractmethod
    async def get_block_number(self) -> int:
        """Get current block number"""
        pass
'''

    def _get_project_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/project.py": '''"""Project domain entity"""

from dataclasses import dataclass
from typing import Optional, List
from datetime import datetime
from packages.common.models.enums import ProjectType, ProjectStatus

@dataclass
class ProjectEntity:
    id: str
    project_id: str
    name: str
    description: Optional[str]
    project_type: ProjectType
    methodology: Optional[str]
    country: str
    region: Optional[str]
    area_hectares: Optional[float]
    estimated_annual_reduction: Optional[int]
    total_estimated_reduction: Optional[int]
    crediting_period_start: Optional[str]
    crediting_period_end: Optional[str]
    status: ProjectStatus
    owner_id: str
    validator_id: Optional[str]
    created_at: datetime
    updated_at: datetime
    
    def can_edit(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_submit(self) -> bool:
        return self.status == ProjectStatus.DRAFT
    
    def can_validate(self) -> bool:
        return self.status == ProjectStatus.SUBMITTED
''',
            "app/domain/entities/document.py": '''"""Document domain entity"""

from dataclasses import dataclass
from typing import Optional
from datetime import datetime
from packages.common.models.enums import DocumentType

@dataclass
class DocumentEntity:
    id: str
    project_id: str
    title: str
    document_type: DocumentType
    file_path: str
    file_size: int
    file_extension: str
    uploaded_by: str
    is_public: bool
    created_at: datetime
    
    @property
    def file_size_mb(self) -> float:
        return round(self.file_size / (1024 * 1024), 2)
    
    @property
    def is_image(self) -> bool:
        return self.file_extension.lower() in ['jpg', 'jpeg', 'png', 'gif']
''',
            "app/domain/services/project_service.py": '''"""Project domain service"""

from typing import List, Optional
from ..entities.project import ProjectEntity
from ..repositories.project_repository import IProjectRepository
from packages.common.exceptions.business import ProjectNotFoundError, InvalidProjectStatusError
from packages.common.models.enums import ProjectStatus

class ProjectService:
    def __init__(self, project_repository: IProjectRepository):
        self.project_repository = project_repository
    
    async def create_project(self, project_data: dict, owner_id: str) -> ProjectEntity:
        """Create a new project"""
        project_data['owner_id'] = owner_id
        project_data['status'] = ProjectStatus.DRAFT
        return await self.project_repository.create(project_data)
    
    async def get_project_by_id(self, project_id: str) -> Optional[ProjectEntity]:
        """Get project by ID"""
        return await self.project_repository.get_by_id(project_id)
    
    async def get_projects_by_owner(self, owner_id: str) -> List[ProjectEntity]:
        """Get all projects owned by a user"""
        return await self.project_repository.get_by_owner_id(owner_id)
    
    async def update_project(self, project_id: str, updates: dict) -> ProjectEntity:
        """Update project"""
        project = await self.project_repository.get_by_id(project_id)
        if not project:
            raise ProjectNotFoundError(project_id)
        
        if not project.can_edit():
            raise InvalidProjectStatusError(project.status.value, "edited")
        
        return await self.project_repository.update(project_id, updates)
    
    async def submit_for_validation(self, project_id: str) -> ProjectEntity:
        """Submit project for validation"""
        project = await self.project_repository.get_by_id(project_id)
        if not project:
            raise ProjectNotFoundError(project_id)
        
        if not project.can_submit():
            raise InvalidProjectStatusError(project.status.value, ProjectStatus.SUBMITTED.value)
        
        return await self.project_repository.update(
            project_id, 
            {"status": ProjectStatus.SUBMITTED}
        )
''',
        }

    def _get_api_gateway_files(self) -> Dict[str, str]:
        return {
            "app/main.py": '''"""
API Gateway Main Application
"""

from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import httpx
import os
from .middleware.auth import AuthMiddleware
from .middleware.rate_limit import RateLimitMiddleware
from .routing.router import setup_routes

app = FastAPI(
    title="PRISM API Gateway",
    description="API Gateway for PRISM Carbon Registry Platform",
    version="1.0.0",
)

# Add middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(AuthMiddleware)
app.add_middleware(RateLimitMiddleware)

# Setup routes
setup_routes(app)

# Service URLs
SERVICES = {
    "user": os.getenv("USER_SERVICE_URL", "http://user-service:8000"),
    "project": os.getenv("PROJECT_SERVICE_URL", "http://project-service:8000"),
    "validation": os.getenv("VALIDATION_SERVICE_URL", "http://validation-service:8000"),
    "registry": os.getenv("REGISTRY_SERVICE_URL", "http://registry-service:8000"),
    "exchange": os.getenv("EXCHANGE_SERVICE_URL", "http://exchange-service:8000"),
}

@app.get("/")
async def root():
    return {"message": "PRISM API Gateway", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    service_health = {}
    
    async with httpx.AsyncClient() as client:
        for service_name, service_url in SERVICES.items():
            try:
                response = await client.get(f"{service_url}/health", timeout=5.0)
                service_health[service_name] = {
                    "status": "healthy" if response.status_code == 200 else "unhealthy",
                    "response_time": response.elapsed.total_seconds()
                }
            except Exception as e:
                service_health[service_name] = {
                    "status": "unhealthy",
                    "error": str(e)
                }
    
    overall_status = "healthy" if all(
        s["status"] == "healthy" for s in service_health.values()
    ) else "degraded"
    
    return {
        "status": overall_status,
        "services": service_health
    }
''',
            "app/routing/router.py": '''"""
API Gateway routing setup
"""

from fastapi import FastAPI, Request, HTTPException
import httpx
from typing import Dict, Any

SERVICES = {
    "user": "http://user-service:8000",
    "project": "http://project-service:8000",
    "validation": "http://validation-service:8000",
    "registry": "http://registry-service:8000",
    "exchange": "http://exchange-service:8000",
}

def setup_routes(app: FastAPI):
    """Setup proxy routes for all services"""
    
    @app.api_route("/api/v1/users/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    @app.api_route("/api/v1/auth/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_user_service(request: Request, path: str):
        return await proxy_request(request, "user", f"/api/v1/{path}")
    
    @app.api_route("/api/v1/projects/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_project_service(request: Request, path: str):
        return await proxy_request(request, "project", f"/api/v1/{path}")
    
    @app.api_route("/api/v1/validation/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_validation_service(request: Request, path: str):
        return await proxy_request(request, "validation", f"/api/v1/{path}")
    
    @app.api_route("/api/v1/registry/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_registry_service(request: Request, path: str):
        return await proxy_request(request, "registry", f"/api/v1/{path}")

async def proxy_request(request: Request, service: str, path: str):
    """Proxy request to appropriate service"""
    
    service_url = SERVICES.get(service)
    if not service_url:
        raise HTTPException(status_code=404, detail="Service not found")
    
    url = f"{service_url}{path}"
    
    # Get request data
    headers = dict(request.headers)
    headers.pop("host", None)  # Remove host header
    
    body = await request.body()
    params = dict(request.query_params)
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.request(
                method=request.method,
                url=url,
                headers=headers,
                content=body,
                params=params,
                timeout=30.0
            )
            
            return JSONResponse(
                content=response.json() if response.content else None,
                status_code=response.status_code,
                headers=dict(response.headers)
            )
    
    except httpx.TimeoutException:
        raise HTTPException(status_code=504, detail="Service timeout")
    except Exception as e:
        raise HTTPException(status_code=502, detail=f"Service error: {str(e)}")
''',
        }

    def _get_test_conftest(self) -> str:
        return '''"""
Test configuration and fixtures
"""

import pytest
import asyncio
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from fastapi.testclient import TestClient
from packages.common.database.base import Base
from app.main import app

# Test database URL
TEST_DATABASE_URL = "postgresql://test:test@localhost:5432/test_db"

@pytest.fixture(scope="session")
def event_loop():
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def test_db():
    """Create test database"""
    engine = create_engine(TEST_DATABASE_URL)
    Base.metadata.create_all(bind=engine)
    
    TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    
    yield TestingSessionLocal
    
    Base.metadata.drop_all(bind=engine)

@pytest.fixture
def client(test_db):
    """Create test client"""
    with TestClient(app) as test_client:
        yield test_client

@pytest.fixture
def sample_user_data():
    """Sample user data for testing"""
    return {
        "email": "test@example.com",
        "password": "TestPassword123!",
        "full_name": "Test User",
        "organization": "Test Organization",
        "country": "US"
    }

@pytest.fixture
def sample_project_data():
    """Sample project data for testing"""
    return {
        "name": "Test Carbon Project",
        "description": "A test carbon reduction project",
        "project_type": "forestry",
        "country": "Brazil",
        "area_hectares": 1000.0,
        "estimated_annual_reduction": 5000,
        "methodology": "VCS-001"
    }
'''

    def _get_frontend_index_tsx(self) -> str:
        return '''"""
Validation utilities and helpers
"""

import re
from typing import Any, Dict, List, Optional, Tuple
from email_validator import validate_email, EmailNotValidError

def validate_email_address(email: str) -> Tuple[bool, Optional[str]]:
    """
    Validate email address
    Returns (is_valid, error_message)
    """
    try:
        valid = validate_email(email)
        return True, None
    except EmailNotValidError as e:
        return False, str(e)

def validate_phone_number(phone: str) -> Tuple[bool, Optional[str]]:
    """
    Validate phone number (basic validation)
    Returns (is_valid, error_message)
    """
    # Remove all non-digit characters
    digits_only = re.sub(r'\D', '', phone)
    
    if len(digits_only) < 10:
        return False, "Phone number must have at least 10 digits"
    
    if len(digits_only) > 15:
        return False, "Phone number cannot exceed 15 digits"
    
    return True, None

def validate_password_strength(password: str) -> Tuple[bool, List[str]]:
    """
    Validate password strength
    Returns (is_valid, list_of_issues)
    """
    issues = []
    
    if len(password) < 8:
        issues.append("Password must be at least 8 characters long")
    
    if not re.search(r'[A-Z]', password):
        issues.append("Password must contain at least one uppercase letter")
    
    if not re.search(r'[a-z]', password):
        issues.append("Password must contain at least one lowercase letter")
    
    if not re.search(r'\d', password):
        issues.append("Password must contain at least one digit")
    
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        issues.append("Password must contain at least one special character")
    
    return len(issues) == 0, issues

def validate_project_id(project_id: str) -> Tuple[bool, Optional[str]]:
    """
    Validate project ID format
    Returns (is_valid, error_message)
    """
    if not project_id:
        return False, "Project ID cannot be empty"
    
    if len(project_id) < 3:
        return False, "Project ID must be at least 3 characters long"
    
    if len(project_id) > 50:
        return False, "Project ID cannot exceed 50 characters"
    
    # Allow alphanumeric, hyphens, and underscores
    if not re.match(r'^[a-zA-Z0-9_-]+#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, project_id):
        return False, "Project ID can only contain letters, numbers, hyphens, and underscores"
    
    return True, None

def validate_coordinates(latitude: float, longitude: float) -> Tuple[bool, Optional[str]]:
    """
    Validate GPS coordinates
    Returns (is_valid, error_message)
    """
    if not (-90 <= latitude <= 90):
        return False, "Latitude must be between -90 and 90 degrees"
    
    if not (-180 <= longitude <= 180):
        return False, "Longitude must be between -180 and 180 degrees"
    
    return True, None

def validate_file_extension(filename: str, allowed_extensions: List[str]) -> Tuple[bool, Optional[str]]:
    """
    Validate file extension
    Returns (is_valid, error_message)
    """
    if not filename:
        return False, "Filename cannot be empty"
    
    extension = filename.lower().split('.')[-1] if '.' in filename else ''
    
    if extension not in [ext.lower() for ext in allowed_extensions]:
        return False, f"File extension '{extension}' not allowed. Allowed: {', '.join(allowed_extensions)}"
    
    return True, None

def sanitize_filename(filename: str) -> str:
    """
    Sanitize filename for safe storage
    """
    # Remove or replace unsafe characters
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # Remove leading/trailing spaces and dots
    filename = filename.strip(' .')
    
    # Ensure filename is not empty
    if not filename:
        filename = "unnamed_file"
    
    return filename

def validate_amount(amount: Any, min_value: float = 0, max_value: Optional[float] = None) -> Tuple[bool, Optional[str]]:
    """
    Validate numeric amount
    Returns (is_valid, error_message)
    """
    try:
        amount = float(amount)
    except (TypeError, ValueError):
        return False, "Amount must be a valid number"
    
    if amount < min_value:
        return False, f"Amount must be at least {min_value}"
    
    if max_value is not None and amount > max_value:
        return False, f"Amount cannot exceed {max_value}"
    
    return True, None
'''

    def _get_serialization_utils(self) -> str:
        return '''"""
Serialization utilities
"""

import json
from datetime import datetime, date
from decimal import Decimal
from typing import Any, Dict
from uuid import UUID

class CustomJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder to handle additional types"""
    
    def default(self, obj: Any) -> Any:
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, date):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, UUID):
            return str(obj)
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)

def serialize_to_json(data: Any) -> str:
    """
    Serialize data to JSON string
    """
    return json.dumps(data, cls=CustomJSONEncoder, ensure_ascii=False)

def deserialize_from_json(json_str: str) -> Any:
    """
    Deserialize JSON string to Python object
    """
    return json.loads(json_str)

def dict_to_model(data: Dict[str, Any], model_class):
    """
    Convert dictionary to Pydantic model instance
    """
    return model_class(**data)

def model_to_dict(model_instance) -> Dict[str, Any]:
    """
    Convert Pydantic model instance to dictionary
    """
    if hasattr(model_instance, 'dict'):
        return model_instance.dict()
    elif hasattr(model_instance, '__dict__'):
        return model_instance.__dict__
    else:
        raise ValueError("Object cannot be converted to dictionary")

def camel_to_snake(name: str) -> str:
    """
    Convert camelCase to snake_case
    """
    import re
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

def snake_to_camel(name: str) -> str:
    """
    Convert snake_case to camelCase
    """
    components = name.split('_')
    return components[0] + ''.join(word.capitalize() for word in components[1:])
'''

    def _get_helper_utils(self) -> str:
        return '''"""
General helper utilities
"""

import hashlib
import secrets
import string
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import uuid

def generate_uuid() -> str:
    """Generate a new UUID string"""
    return str(uuid.uuid4())

def generate_random_string(length: int = 32, use_letters: bool = True, use_digits: bool = True) -> str:
    """
    Generate a random string of specified length
    """
    characters = ""
    if use_letters:
        characters += string.ascii_letters
    if use_digits:
        characters += string.digits
    
    if not characters:
        raise ValueError("Must include at least letters or digits")
    
    return ''.join(secrets.choice(characters) for _ in range(length))

def generate_api_key() -> str:
    """Generate a secure API key"""
    return f"pk_{''.join(secrets.choice(string.ascii_letters + string.digits) for _ in range(32))}"

def hash_string(input_string: str, salt: str = "") -> str:
    """
    Generate SHA-256 hash of a string
    """
    return hashlib.sha256((input_string + salt).encode()).hexdigest()

def verify_hash(input_string: str, hash_value: str, salt: str = "") -> bool:
    """
    Verify if input string matches the hash
    """
    return hash_string(input_string, salt) == hash_value

def truncate_string(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Truncate string to specified length with suffix
    """
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_date_string(date_str: str) -> Optional[datetime]:
    """
    Parse date string in various formats
    """
    formats = [
        "%Y-%m-%d",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S.%fZ",
        "%d/%m/%Y",
        "%m/%d/%Y",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    return None

def format_file_size(size_bytes: int) -> str:
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def clean_dict(data: Dict[str, Any], remove_none: bool = True, remove_empty: bool = False) -> Dict[str, Any]:
    """
    Clean dictionary by removing None or empty values
    """
    cleaned = {}
    
    for key, value in data.items():
        if remove_none and value is None:
            continue
        
        if remove_empty and (value == "" or value == [] or value == {}):
            continue
        
        cleaned[key] = value
    
    return cleaned

def merge_dicts(*dicts: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge multiple dictionaries
    """
    result = {}
    for d in dicts:
        if d:
            result.update(d)
    return result

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """
    Split list into chunks of specified size
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()

extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
line_length = 88

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true

[[tool.mypy.overrides]]
module = [
    "uvicorn.*",
    "fastapi.*",
    "sqlalchemy.*",
    "alembic.*",
]
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --tb=short --strict-markers"
markers = [
    "slow: marks tests as slow",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
]
'''

# Add all the remaining missing methods that are referenced but not defined

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item for sublist in nested_list for item in sublist]

def remove_duplicates(lst: List[Any]) -> List[Any]:
    """
    Remove duplicates from list while preserving order
    """
    seen = set()
    result = []
    for item in lst:
        if item not in seen:
            seen.add(item)
            result.append(item)
    return result

def is_valid_url(url: str) -> bool:
    """
    Check if string is a valid URL
    """
    import re
    url_pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)
        return '''"""
Validation utilities and helpers
"""

import re
from typing import Any, Dict, List, Optional, Tuple
from email_validator import validate_email, EmailNotValidError

def validate_email_address(email: str) -> Tuple[bool, Optional[str]]:
    """
    Validate email address
    Returns (is_valid, error_message)
    """
    try:
        valid = validate_email(email)
        return True, None
    except EmailNotValidError as e:
        return False, str(e)

def validate_phone_number(phone: str) -> Tuple[bool, Optional[str]]:
    """
    Validate phone number (basic validation)
    Returns (is_valid, error_message)
    """
    # Remove all non-digit characters
    digits_only = re.sub(r'\D', '', phone)
    
    if len(digits_only) < 10:
        return False, "Phone number must have at least 10 digits"
    
    if len(digits_only) > 15:
        return False, "Phone number cannot exceed 15 digits"
    
    return True, None

def validate_password_strength(password: str) -> Tuple[bool, List[str]]:
    """
    Validate password strength
    Returns (is_valid, list_of_issues)
    """
    issues = []
    
    if len(password) < 8:
        issues.append("Password must be at least 8 characters long")
    
    if not re.search(r'[A-Z]', password):
        issues.append("Password must contain at least one uppercase letter")
    
    if not re.search(r'[a-z]', password):
        issues.append("Password must contain at least one lowercase letter")
    
    if not re.search(r'\d', password):
        issues.append("Password must contain at least one digit")
    
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        issues.append("Password must contain at least one special character")
    
    return len(issues) == 0, issues

def validate_project_id(project_id: str) -> Tuple[bool, Optional[str]]:
    """
    Validate project ID format
    Returns (is_valid, error_message)
    """
    if not project_id:
        return False, "Project ID cannot be empty"
    
    if len(project_id) < 3:
        return False, "Project ID must be at least 3 characters long"
    
    if len(project_id) > 50:
        return False, "Project ID cannot exceed 50 characters"
    
    # Allow alphanumeric, hyphens, and underscores
    if not re.match(r'^[a-zA-Z0-9_-]+#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, project_id):
        return False, "Project ID can only contain letters, numbers, hyphens, and underscores"
    
    return True, None

def validate_coordinates(latitude: float, longitude: float) -> Tuple[bool, Optional[str]]:
    """
    Validate GPS coordinates
    Returns (is_valid, error_message)
    """
    if not (-90 <= latitude <= 90):
        return False, "Latitude must be between -90 and 90 degrees"
    
    if not (-180 <= longitude <= 180):
        return False, "Longitude must be between -180 and 180 degrees"
    
    return True, None

def validate_file_extension(filename: str, allowed_extensions: List[str]) -> Tuple[bool, Optional[str]]:
    """
    Validate file extension
    Returns (is_valid, error_message)
    """
    if not filename:
        return False, "Filename cannot be empty"
    
    extension = filename.lower().split('.')[-1] if '.' in filename else ''
    
    if extension not in [ext.lower() for ext in allowed_extensions]:
        return False, f"File extension '{extension}' not allowed. Allowed: {', '.join(allowed_extensions)}"
    
    return True, None

def sanitize_filename(filename: str) -> str:
    """
    Sanitize filename for safe storage
    """
    # Remove or replace unsafe characters
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # Remove leading/trailing spaces and dots
    filename = filename.strip(' .')
    
    # Ensure filename is not empty
    if not filename:
        filename = "unnamed_file"
    
    return filename

def validate_amount(amount: Any, min_value: float = 0, max_value: Optional[float] = None) -> Tuple[bool, Optional[str]]:
    """
    Validate numeric amount
    Returns (is_valid, error_message)
    """
    try:
        amount = float(amount)
    except (TypeError, ValueError):
        return False, "Amount must be a valid number"
    
    if amount < min_value:
        return False, f"Amount must be at least {min_value}"
    
    if max_value is not None and amount > max_value:
        return False, f"Amount cannot exceed {max_value}"
    
    return True, None
'''

    def _get_serialization_utils(self) -> str:
        return '''"""
Serialization utilities
"""

import json
from datetime import datetime, date
from decimal import Decimal
from typing import Any, Dict
from uuid import UUID

class CustomJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder to handle additional types"""
    
    def default(self, obj: Any) -> Any:
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, date):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, UUID):
            return str(obj)
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)

def serialize_to_json(data: Any) -> str:
    """
    Serialize data to JSON string
    """
    return json.dumps(data, cls=CustomJSONEncoder, ensure_ascii=False)

def deserialize_from_json(json_str: str) -> Any:
    """
    Deserialize JSON string to Python object
    """
    return json.loads(json_str)

def dict_to_model(data: Dict[str, Any], model_class):
    """
    Convert dictionary to Pydantic model instance
    """
    return model_class(**data)

def model_to_dict(model_instance) -> Dict[str, Any]:
    """
    Convert Pydantic model instance to dictionary
    """
    if hasattr(model_instance, 'dict'):
        return model_instance.dict()
    elif hasattr(model_instance, '__dict__'):
        return model_instance.__dict__
    else:
        raise ValueError("Object cannot be converted to dictionary")

def camel_to_snake(name: str) -> str:
    """
    Convert camelCase to snake_case
    """
    import re
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

def snake_to_camel(name: str) -> str:
    """
    Convert snake_case to camelCase
    """
    components = name.split('_')
    return components[0] + ''.join(word.capitalize() for word in components[1:])
'''

    def _get_helper_utils(self) -> str:
        return '''"""
General helper utilities
"""

import hashlib
import secrets
import string
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import uuid

def generate_uuid() -> str:
    """Generate a new UUID string"""
    return str(uuid.uuid4())

def generate_random_string(length: int = 32, use_letters: bool = True, use_digits: bool = True) -> str:
    """
    Generate a random string of specified length
    """
    characters = ""
    if use_letters:
        characters += string.ascii_letters
    if use_digits:
        characters += string.digits
    
    if not characters:
        raise ValueError("Must include at least letters or digits")
    
    return ''.join(secrets.choice(characters) for _ in range(length))

def generate_api_key() -> str:
    """Generate a secure API key"""
    return f"pk_{''.join(secrets.choice(string.ascii_letters + string.digits) for _ in range(32))}"

def hash_string(input_string: str, salt: str = "") -> str:
    """
    Generate SHA-256 hash of a string
    """
    return hashlib.sha256((input_string + salt).encode()).hexdigest()

def verify_hash(input_string: str, hash_value: str, salt: str = "") -> bool:
    """
    Verify if input string matches the hash
    """
    return hash_string(input_string, salt) == hash_value

def truncate_string(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Truncate string to specified length with suffix
    """
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_date_string(date_str: str) -> Optional[datetime]:
    """
    Parse date string in various formats
    """
    formats = [
        "%Y-%m-%d",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S.%fZ",
        "%d/%m/%Y",
        "%m/%d/%Y",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    return None

def format_file_size(size_bytes: int) -> str:
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def clean_dict(data: Dict[str, Any], remove_none: bool = True, remove_empty: bool = False) -> Dict[str, Any]:
    """
    Clean dictionary by removing None or empty values
    """
    cleaned = {}
    
    for key, value in data.items():
        if remove_none and value is None:
            continue
        
        if remove_empty and (value == "" or value == [] or value == {}):
            continue
        
        cleaned[key] = value
    
    return cleaned

def merge_dicts(*dicts: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge multiple dictionaries
    """
    result = {}
    for d in dicts:
        if d:
            result.update(d)
    return result

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """
    Split list into chunks of specified size
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, re.IGNORECASE)
    return url_pattern.match(url) is not None
'''

    def _get_hedera_utils(self) -> str:
        return '''"""
Hedera Hashgraph utility functions
"""

import hashlib
import json
from typing import Dict, Any, Optional

def generate_token_id(project_id: str, batch_number: int = 1) -> int:
    """
    Generate a deterministic token ID from project ID and batch number
    """
    # Create a hash of project_id + batch_number
    hash_input = f"{project_id}_{batch_number}"
    hash_bytes = hashlib.sha256(hash_input.encode()).digest()
    
    # Convert first 8 bytes to integer (to fit in uint256)
    return int.from_bytes(hash_bytes[:8], byteorder='big')

def format_hedera_amount(amount: int) -> str:
    """
    Format amount for Hedera transactions (in tinybars)
    """
    return str(amount * 100000000)  # Convert to tinybars

def validate_hedera_account_id(account_id: str) -> bool:
    """
    Validate Hedera account ID format (0.0.xxxxx)
    """
    import re
    pattern = r'^0\.0\.\d+
        return '''"""
Validation utilities and helpers
"""

import re
from typing import Any, Dict, List, Optional, Tuple
from email_validator import validate_email, EmailNotValidError

def validate_email_address(email: str) -> Tuple[bool, Optional[str]]:
    """
    Validate email address
    Returns (is_valid, error_message)
    """
    try:
        valid = validate_email(email)
        return True, None
    except EmailNotValidError as e:
        return False, str(e)

def validate_phone_number(phone: str) -> Tuple[bool, Optional[str]]:
    """
    Validate phone number (basic validation)
    Returns (is_valid, error_message)
    """
    # Remove all non-digit characters
    digits_only = re.sub(r'\D', '', phone)
    
    if len(digits_only) < 10:
        return False, "Phone number must have at least 10 digits"
    
    if len(digits_only) > 15:
        return False, "Phone number cannot exceed 15 digits"
    
    return True, None

def validate_password_strength(password: str) -> Tuple[bool, List[str]]:
    """
    Validate password strength
    Returns (is_valid, list_of_issues)
    """
    issues = []
    
    if len(password) < 8:
        issues.append("Password must be at least 8 characters long")
    
    if not re.search(r'[A-Z]', password):
        issues.append("Password must contain at least one uppercase letter")
    
    if not re.search(r'[a-z]', password):
        issues.append("Password must contain at least one lowercase letter")
    
    if not re.search(r'\d', password):
        issues.append("Password must contain at least one digit")
    
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        issues.append("Password must contain at least one special character")
    
    return len(issues) == 0, issues

def validate_project_id(project_id: str) -> Tuple[bool, Optional[str]]:
    """
    Validate project ID format
    Returns (is_valid, error_message)
    """
    if not project_id:
        return False, "Project ID cannot be empty"
    
    if len(project_id) < 3:
        return False, "Project ID must be at least 3 characters long"
    
    if len(project_id) > 50:
        return False, "Project ID cannot exceed 50 characters"
    
    # Allow alphanumeric, hyphens, and underscores
    if not re.match(r'^[a-zA-Z0-9_-]+#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, project_id):
        return False, "Project ID can only contain letters, numbers, hyphens, and underscores"
    
    return True, None

def validate_coordinates(latitude: float, longitude: float) -> Tuple[bool, Optional[str]]:
    """
    Validate GPS coordinates
    Returns (is_valid, error_message)
    """
    if not (-90 <= latitude <= 90):
        return False, "Latitude must be between -90 and 90 degrees"
    
    if not (-180 <= longitude <= 180):
        return False, "Longitude must be between -180 and 180 degrees"
    
    return True, None

def validate_file_extension(filename: str, allowed_extensions: List[str]) -> Tuple[bool, Optional[str]]:
    """
    Validate file extension
    Returns (is_valid, error_message)
    """
    if not filename:
        return False, "Filename cannot be empty"
    
    extension = filename.lower().split('.')[-1] if '.' in filename else ''
    
    if extension not in [ext.lower() for ext in allowed_extensions]:
        return False, f"File extension '{extension}' not allowed. Allowed: {', '.join(allowed_extensions)}"
    
    return True, None

def sanitize_filename(filename: str) -> str:
    """
    Sanitize filename for safe storage
    """
    # Remove or replace unsafe characters
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # Remove leading/trailing spaces and dots
    filename = filename.strip(' .')
    
    # Ensure filename is not empty
    if not filename:
        filename = "unnamed_file"
    
    return filename

def validate_amount(amount: Any, min_value: float = 0, max_value: Optional[float] = None) -> Tuple[bool, Optional[str]]:
    """
    Validate numeric amount
    Returns (is_valid, error_message)
    """
    try:
        amount = float(amount)
    except (TypeError, ValueError):
        return False, "Amount must be a valid number"
    
    if amount < min_value:
        return False, f"Amount must be at least {min_value}"
    
    if max_value is not None and amount > max_value:
        return False, f"Amount cannot exceed {max_value}"
    
    return True, None
'''

    def _get_serialization_utils(self) -> str:
        return '''"""
Serialization utilities
"""

import json
from datetime import datetime, date
from decimal import Decimal
from typing import Any, Dict
from uuid import UUID

class CustomJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder to handle additional types"""
    
    def default(self, obj: Any) -> Any:
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, date):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, UUID):
            return str(obj)
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)

def serialize_to_json(data: Any) -> str:
    """
    Serialize data to JSON string
    """
    return json.dumps(data, cls=CustomJSONEncoder, ensure_ascii=False)

def deserialize_from_json(json_str: str) -> Any:
    """
    Deserialize JSON string to Python object
    """
    return json.loads(json_str)

def dict_to_model(data: Dict[str, Any], model_class):
    """
    Convert dictionary to Pydantic model instance
    """
    return model_class(**data)

def model_to_dict(model_instance) -> Dict[str, Any]:
    """
    Convert Pydantic model instance to dictionary
    """
    if hasattr(model_instance, 'dict'):
        return model_instance.dict()
    elif hasattr(model_instance, '__dict__'):
        return model_instance.__dict__
    else:
        raise ValueError("Object cannot be converted to dictionary")

def camel_to_snake(name: str) -> str:
    """
    Convert camelCase to snake_case
    """
    import re
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

def snake_to_camel(name: str) -> str:
    """
    Convert snake_case to camelCase
    """
    components = name.split('_')
    return components[0] + ''.join(word.capitalize() for word in components[1:])
'''

    def _get_helper_utils(self) -> str:
        return '''"""
General helper utilities
"""

import hashlib
import secrets
import string
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import uuid

def generate_uuid() -> str:
    """Generate a new UUID string"""
    return str(uuid.uuid4())

def generate_random_string(length: int = 32, use_letters: bool = True, use_digits: bool = True) -> str:
    """
    Generate a random string of specified length
    """
    characters = ""
    if use_letters:
        characters += string.ascii_letters
    if use_digits:
        characters += string.digits
    
    if not characters:
        raise ValueError("Must include at least letters or digits")
    
    return ''.join(secrets.choice(characters) for _ in range(length))

def generate_api_key() -> str:
    """Generate a secure API key"""
    return f"pk_{''.join(secrets.choice(string.ascii_letters + string.digits) for _ in range(32))}"

def hash_string(input_string: str, salt: str = "") -> str:
    """
    Generate SHA-256 hash of a string
    """
    return hashlib.sha256((input_string + salt).encode()).hexdigest()

def verify_hash(input_string: str, hash_value: str, salt: str = "") -> bool:
    """
    Verify if input string matches the hash
    """
    return hash_string(input_string, salt) == hash_value

def truncate_string(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Truncate string to specified length with suffix
    """
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_date_string(date_str: str) -> Optional[datetime]:
    """
    Parse date string in various formats
    """
    formats = [
        "%Y-%m-%d",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S.%fZ",
        "%d/%m/%Y",
        "%m/%d/%Y",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    return None

def format_file_size(size_bytes: int) -> str:
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def clean_dict(data: Dict[str, Any], remove_none: bool = True, remove_empty: bool = False) -> Dict[str, Any]:
    """
    Clean dictionary by removing None or empty values
    """
    cleaned = {}
    
    for key, value in data.items():
        if remove_none and value is None:
            continue
        
        if remove_empty and (value == "" or value == [] or value == {}):
            continue
        
        cleaned[key] = value
    
    return cleaned

def merge_dicts(*dicts: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge multiple dictionaries
    """
    result = {}
    for d in dicts:
        if d:
            result.update(d)
    return result

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """
    Split list into chunks of specified size
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()

    return bool(re.match(pattern, account_id))

def create_metadata_json(project_data: Dict[str, Any]) -> str:
    """
    Create standardized metadata JSON for carbon tokens
    """
    metadata = {
        "name": project_data.get("name"),
        "description": project_data.get("description"),
        "image": project_data.get("image_url"),
        "attributes": [
            {
                "trait_type": "Project Type",
                "value": project_data.get("project_type")
            },
            {
                "trait_type": "Country",
                "value": project_data.get("country")
            },
            {
                "trait_type": "Methodology",
                "value": project_data.get("methodology")
            },
            {
                "trait_type": "Vintage Year",
                "value": project_data.get("vintage_year")
            }
        ],
        "external_url": project_data.get("external_url"),
        "carbon_credit_info": {
            "vintage_year": project_data.get("vintage_year"),
            "verification_standard": project_data.get("standard"),
            "additional_certifications": project_data.get("certifications", [])
        }
    }
    
    return json.dumps(metadata, ensure_ascii=False)
'''

    def _get_registry_interface(self) -> str:
        return '''"""
Registry interface for blockchain operations
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional

class IRegistryService(ABC):
    """Interface for registry service operations"""
    
    @abstractmethod
    async def register_project(self, project_id: str, metadata: Dict[str, Any]) -> str:
        """Register a new project and mint NFT"""
        pass
    
    @abstractmethod
    async def issue_credits(
        self, 
        project_id: str, 
        amount: int, 
        to_address: str,
        metadata: Dict[str, Any]
    ) -> str:
        """Issue carbon credits for a project"""
        pass
    
    @abstractmethod
    async def transfer_credits(
        self,
        from_address: str,
        to_address: str,
        token_id: int,
        amount: int
    ) -> str:
        """Transfer credits between addresses"""
        pass
    
    @abstractmethod
    async def retire_credits(
        self,
        owner_address: str,
        token_id: int,
        amount: int,
        retirement_reason: str
    ) -> str:
        """Retire (burn) carbon credits"""
        pass
    
    @abstractmethod
    async def get_credit_balance(self, address: str, token_id: int) -> int:
        """Get credit balance for an address"""
        pass
    
    @abstractmethod
    async def get_project_info(self, project_id: str) -> Optional[Dict[str, Any]]:
        """Get project information from blockchain"""
        pass
    
    @abstractmethod
    async def get_transaction_history(self, token_id: int) -> List[Dict[str, Any]]:
        """Get transaction history for a token"""
        pass

class IBlockchainClient(ABC):
    """Interface for blockchain client operations"""
    
    @abstractmethod
    async def deploy_contract(self, contract_code: str, constructor_args: List[Any]) -> str:
        """Deploy a smart contract"""
        pass
    
    @abstractmethod
    async def call_contract_function(
        self,
        contract_address: str,
        function_name: str,
        args: List[Any],
        sender_private_key: str
    ) -> str:
        """Call a contract function"""
        pass
    
    @abstractmethod
    async def get_transaction_receipt(self, tx_hash: str) -> Dict[str, Any]:
        """Get transaction receipt"""
        pass
    
    @abstractmethod
    async def get_block_number(self) -> int:
        """Get current block number"""
        pass
'''

    def _get_project_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/project.py": '''"""Project domain entity"""

from dataclasses import dataclass
from typing import Optional, List
from datetime import datetime
from packages.common.models.enums import ProjectType, ProjectStatus

@dataclass
class ProjectEntity:
    id: str
    project_id: str
    name: str
    description: Optional[str]
    project_type: ProjectType
    methodology: Optional[str]
    country: str
    region: Optional[str]
    area_hectares: Optional[float]
    estimated_annual_reduction: Optional[int]
    total_estimated_reduction: Optional[int]
    crediting_period_start: Optional[str]
    crediting_period_end: Optional[str]
    status: ProjectStatus
    owner_id: str
    validator_id: Optional[str]
    created_at: datetime
    updated_at: datetime
    
    def can_edit(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_submit(self) -> bool:
        return self.status == ProjectStatus.DRAFT
    
    def can_validate(self) -> bool:
        return self.status == ProjectStatus.SUBMITTED
''',
            "app/domain/entities/document.py": '''"""Document domain entity"""

from dataclasses import dataclass
from typing import Optional
from datetime import datetime
from packages.common.models.enums import DocumentType

@dataclass
class DocumentEntity:
    id: str
    project_id: str
    title: str
    document_type: DocumentType
    file_path: str
    file_size: int
    file_extension: str
    uploaded_by: str
    is_public: bool
    created_at: datetime
    
    @property
    def file_size_mb(self) -> float:
        return round(self.file_size / (1024 * 1024), 2)
    
    @property
    def is_image(self) -> bool:
        return self.file_extension.lower() in ['jpg', 'jpeg', 'png', 'gif']
''',
            "app/domain/services/project_service.py": '''"""Project domain service"""

from typing import List, Optional
from ..entities.project import ProjectEntity
from ..repositories.project_repository import IProjectRepository
from packages.common.exceptions.business import ProjectNotFoundError, InvalidProjectStatusError
from packages.common.models.enums import ProjectStatus

class ProjectService:
    def __init__(self, project_repository: IProjectRepository):
        self.project_repository = project_repository
    
    async def create_project(self, project_data: dict, owner_id: str) -> ProjectEntity:
        """Create a new project"""
        project_data['owner_id'] = owner_id
        project_data['status'] = ProjectStatus.DRAFT
        return await self.project_repository.create(project_data)
    
    async def get_project_by_id(self, project_id: str) -> Optional[ProjectEntity]:
        """Get project by ID"""
        return await self.project_repository.get_by_id(project_id)
    
    async def get_projects_by_owner(self, owner_id: str) -> List[ProjectEntity]:
        """Get all projects owned by a user"""
        return await self.project_repository.get_by_owner_id(owner_id)
    
    async def update_project(self, project_id: str, updates: dict) -> ProjectEntity:
        """Update project"""
        project = await self.project_repository.get_by_id(project_id)
        if not project:
            raise ProjectNotFoundError(project_id)
        
        if not project.can_edit():
            raise InvalidProjectStatusError(project.status.value, "edited")
        
        return await self.project_repository.update(project_id, updates)
    
    async def submit_for_validation(self, project_id: str) -> ProjectEntity:
        """Submit project for validation"""
        project = await self.project_repository.get_by_id(project_id)
        if not project:
            raise ProjectNotFoundError(project_id)
        
        if not project.can_submit():
            raise InvalidProjectStatusError(project.status.value, ProjectStatus.SUBMITTED.value)
        
        return await self.project_repository.update(
            project_id, 
            {"status": ProjectStatus.SUBMITTED}
        )
''',
        }

    def _get_api_gateway_files(self) -> Dict[str, str]:
        return {
            "app/main.py": '''"""
API Gateway Main Application
"""

from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import httpx
import os
from .middleware.auth import AuthMiddleware
from .middleware.rate_limit import RateLimitMiddleware
from .routing.router import setup_routes

app = FastAPI(
    title="PRISM API Gateway",
    description="API Gateway for PRISM Carbon Registry Platform",
    version="1.0.0",
)

# Add middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(AuthMiddleware)
app.add_middleware(RateLimitMiddleware)

# Setup routes
setup_routes(app)

# Service URLs
SERVICES = {
    "user": os.getenv("USER_SERVICE_URL", "http://user-service:8000"),
    "project": os.getenv("PROJECT_SERVICE_URL", "http://project-service:8000"),
    "validation": os.getenv("VALIDATION_SERVICE_URL", "http://validation-service:8000"),
    "registry": os.getenv("REGISTRY_SERVICE_URL", "http://registry-service:8000"),
    "exchange": os.getenv("EXCHANGE_SERVICE_URL", "http://exchange-service:8000"),
}

@app.get("/")
async def root():
    return {"message": "PRISM API Gateway", "version": "1.0.0"}

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    service_health = {}
    
    async with httpx.AsyncClient() as client:
        for service_name, service_url in SERVICES.items():
            try:
                response = await client.get(f"{service_url}/health", timeout=5.0)
                service_health[service_name] = {
                    "status": "healthy" if response.status_code == 200 else "unhealthy",
                    "response_time": response.elapsed.total_seconds()
                }
            except Exception as e:
                service_health[service_name] = {
                    "status": "unhealthy",
                    "error": str(e)
                }
    
    overall_status = "healthy" if all(
        s["status"] == "healthy" for s in service_health.values()
    ) else "degraded"
    
    return {
        "status": overall_status,
        "services": service_health
    }
''',
            "app/routing/router.py": '''"""
API Gateway routing setup
"""

from fastapi import FastAPI, Request, HTTPException
import httpx
from typing import Dict, Any

SERVICES = {
    "user": "http://user-service:8000",
    "project": "http://project-service:8000",
    "validation": "http://validation-service:8000",
    "registry": "http://registry-service:8000",
    "exchange": "http://exchange-service:8000",
}

def setup_routes(app: FastAPI):
    """Setup proxy routes for all services"""
    
    @app.api_route("/api/v1/users/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    @app.api_route("/api/v1/auth/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_user_service(request: Request, path: str):
        return await proxy_request(request, "user", f"/api/v1/{path}")
    
    @app.api_route("/api/v1/projects/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_project_service(request: Request, path: str):
        return await proxy_request(request, "project", f"/api/v1/{path}")
    
    @app.api_route("/api/v1/validation/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_validation_service(request: Request, path: str):
        return await proxy_request(request, "validation", f"/api/v1/{path}")
    
    @app.api_route("/api/v1/registry/{path:path}", methods=["GET", "POST", "PUT", "DELETE"])
    async def proxy_registry_service(request: Request, path: str):
        return await proxy_request(request, "registry", f"/api/v1/{path}")

async def proxy_request(request: Request, service: str, path: str):
    """Proxy request to appropriate service"""
    
    service_url = SERVICES.get(service)
    if not service_url:
        raise HTTPException(status_code=404, detail="Service not found")
    
    url = f"{service_url}{path}"
    
    # Get request data
    headers = dict(request.headers)
    headers.pop("host", None)  # Remove host header
    
    body = await request.body()
    params = dict(request.query_params)
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.request(
                method=request.method,
                url=url,
                headers=headers,
                content=body,
                params=params,
                timeout=30.0
            )
            
            return JSONResponse(
                content=response.json() if response.content else None,
                status_code=response.status_code,
                headers=dict(response.headers)
            )
    
    except httpx.TimeoutException:
        raise HTTPException(status_code=504, detail="Service timeout")
    except Exception as e:
        raise HTTPException(status_code=502, detail=f"Service error: {str(e)}")
''',
        }

    def _get_test_conftest(self) -> str:
        return '''"""
Test configuration and fixtures
"""

import pytest
import asyncio
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from fastapi.testclient import TestClient
from packages.common.database.base import Base
from app.main import app

# Test database URL
TEST_DATABASE_URL = "postgresql://test:test@localhost:5432/test_db"

@pytest.fixture(scope="session")
def event_loop():
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def test_db():
    """Create test database"""
    engine = create_engine(TEST_DATABASE_URL)
    Base.metadata.create_all(bind=engine)
    
    TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    
    yield TestingSessionLocal
    
    Base.metadata.drop_all(bind=engine)

@pytest.fixture
def client(test_db):
    """Create test client"""
    with TestClient(app) as test_client:
        yield test_client

@pytest.fixture
def sample_user_data():
    """Sample user data for testing"""
    return {
        "email": "test@example.com",
        "password": "TestPassword123!",
        "full_name": "Test User",
        "organization": "Test Organization",
        "country": "US"
    }

@pytest.fixture
def sample_project_data():
    """Sample project data for testing"""
    return {
        "name": "Test Carbon Project",
        "description": "A test carbon reduction project",
        "project_type": "forestry",
        "country": "Brazil",
        "area_hectares": 1000.0,
        "estimated_annual_reduction": 5000,
        "methodology": "VCS-001"
    }
'''

    def _get_frontend_index_tsx(self) -> str:
        return '''"""
Validation utilities and helpers
"""

import re
from typing import Any, Dict, List, Optional, Tuple
from email_validator import validate_email, EmailNotValidError

def validate_email_address(email: str) -> Tuple[bool, Optional[str]]:
    """
    Validate email address
    Returns (is_valid, error_message)
    """
    try:
        valid = validate_email(email)
        return True, None
    except EmailNotValidError as e:
        return False, str(e)

def validate_phone_number(phone: str) -> Tuple[bool, Optional[str]]:
    """
    Validate phone number (basic validation)
    Returns (is_valid, error_message)
    """
    # Remove all non-digit characters
    digits_only = re.sub(r'\D', '', phone)
    
    if len(digits_only) < 10:
        return False, "Phone number must have at least 10 digits"
    
    if len(digits_only) > 15:
        return False, "Phone number cannot exceed 15 digits"
    
    return True, None

def validate_password_strength(password: str) -> Tuple[bool, List[str]]:
    """
    Validate password strength
    Returns (is_valid, list_of_issues)
    """
    issues = []
    
    if len(password) < 8:
        issues.append("Password must be at least 8 characters long")
    
    if not re.search(r'[A-Z]', password):
        issues.append("Password must contain at least one uppercase letter")
    
    if not re.search(r'[a-z]', password):
        issues.append("Password must contain at least one lowercase letter")
    
    if not re.search(r'\d', password):
        issues.append("Password must contain at least one digit")
    
    if not re.search(r'[!@#$%^&*(),.?":{}|<>]', password):
        issues.append("Password must contain at least one special character")
    
    return len(issues) == 0, issues

def validate_project_id(project_id: str) -> Tuple[bool, Optional[str]]:
    """
    Validate project ID format
    Returns (is_valid, error_message)
    """
    if not project_id:
        return False, "Project ID cannot be empty"
    
    if len(project_id) < 3:
        return False, "Project ID must be at least 3 characters long"
    
    if len(project_id) > 50:
        return False, "Project ID cannot exceed 50 characters"
    
    # Allow alphanumeric, hyphens, and underscores
    if not re.match(r'^[a-zA-Z0-9_-]+#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
, project_id):
        return False, "Project ID can only contain letters, numbers, hyphens, and underscores"
    
    return True, None

def validate_coordinates(latitude: float, longitude: float) -> Tuple[bool, Optional[str]]:
    """
    Validate GPS coordinates
    Returns (is_valid, error_message)
    """
    if not (-90 <= latitude <= 90):
        return False, "Latitude must be between -90 and 90 degrees"
    
    if not (-180 <= longitude <= 180):
        return False, "Longitude must be between -180 and 180 degrees"
    
    return True, None

def validate_file_extension(filename: str, allowed_extensions: List[str]) -> Tuple[bool, Optional[str]]:
    """
    Validate file extension
    Returns (is_valid, error_message)
    """
    if not filename:
        return False, "Filename cannot be empty"
    
    extension = filename.lower().split('.')[-1] if '.' in filename else ''
    
    if extension not in [ext.lower() for ext in allowed_extensions]:
        return False, f"File extension '{extension}' not allowed. Allowed: {', '.join(allowed_extensions)}"
    
    return True, None

def sanitize_filename(filename: str) -> str:
    """
    Sanitize filename for safe storage
    """
    # Remove or replace unsafe characters
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    
    # Remove leading/trailing spaces and dots
    filename = filename.strip(' .')
    
    # Ensure filename is not empty
    if not filename:
        filename = "unnamed_file"
    
    return filename

def validate_amount(amount: Any, min_value: float = 0, max_value: Optional[float] = None) -> Tuple[bool, Optional[str]]:
    """
    Validate numeric amount
    Returns (is_valid, error_message)
    """
    try:
        amount = float(amount)
    except (TypeError, ValueError):
        return False, "Amount must be a valid number"
    
    if amount < min_value:
        return False, f"Amount must be at least {min_value}"
    
    if max_value is not None and amount > max_value:
        return False, f"Amount cannot exceed {max_value}"
    
    return True, None
'''

    def _get_serialization_utils(self) -> str:
        return '''"""
Serialization utilities
"""

import json
from datetime import datetime, date
from decimal import Decimal
from typing import Any, Dict
from uuid import UUID

class CustomJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder to handle additional types"""
    
    def default(self, obj: Any) -> Any:
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, date):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        elif isinstance(obj, UUID):
            return str(obj)
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)

def serialize_to_json(data: Any) -> str:
    """
    Serialize data to JSON string
    """
    return json.dumps(data, cls=CustomJSONEncoder, ensure_ascii=False)

def deserialize_from_json(json_str: str) -> Any:
    """
    Deserialize JSON string to Python object
    """
    return json.loads(json_str)

def dict_to_model(data: Dict[str, Any], model_class):
    """
    Convert dictionary to Pydantic model instance
    """
    return model_class(**data)

def model_to_dict(model_instance) -> Dict[str, Any]:
    """
    Convert Pydantic model instance to dictionary
    """
    if hasattr(model_instance, 'dict'):
        return model_instance.dict()
    elif hasattr(model_instance, '__dict__'):
        return model_instance.__dict__
    else:
        raise ValueError("Object cannot be converted to dictionary")

def camel_to_snake(name: str) -> str:
    """
    Convert camelCase to snake_case
    """
    import re
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

def snake_to_camel(name: str) -> str:
    """
    Convert snake_case to camelCase
    """
    components = name.split('_')
    return components[0] + ''.join(word.capitalize() for word in components[1:])
'''

    def _get_helper_utils(self) -> str:
        return '''"""
General helper utilities
"""

import hashlib
import secrets
import string
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
import uuid

def generate_uuid() -> str:
    """Generate a new UUID string"""
    return str(uuid.uuid4())

def generate_random_string(length: int = 32, use_letters: bool = True, use_digits: bool = True) -> str:
    """
    Generate a random string of specified length
    """
    characters = ""
    if use_letters:
        characters += string.ascii_letters
    if use_digits:
        characters += string.digits
    
    if not characters:
        raise ValueError("Must include at least letters or digits")
    
    return ''.join(secrets.choice(characters) for _ in range(length))

def generate_api_key() -> str:
    """Generate a secure API key"""
    return f"pk_{''.join(secrets.choice(string.ascii_letters + string.digits) for _ in range(32))}"

def hash_string(input_string: str, salt: str = "") -> str:
    """
    Generate SHA-256 hash of a string
    """
    return hashlib.sha256((input_string + salt).encode()).hexdigest()

def verify_hash(input_string: str, hash_value: str, salt: str = "") -> bool:
    """
    Verify if input string matches the hash
    """
    return hash_string(input_string, salt) == hash_value

def truncate_string(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Truncate string to specified length with suffix
    """
    if len(text) <= max_length:
        return text
    return text[:max_length - len(suffix)] + suffix

def parse_date_string(date_str: str) -> Optional[datetime]:
    """
    Parse date string in various formats
    """
    formats = [
        "%Y-%m-%d",
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%dT%H:%M:%SZ",
        "%Y-%m-%dT%H:%M:%S.%fZ",
        "%d/%m/%Y",
        "%m/%d/%Y",
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    
    return None

def format_file_size(size_bytes: int) -> str:
    """
    Format file size in human readable format
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def clean_dict(data: Dict[str, Any], remove_none: bool = True, remove_empty: bool = False) -> Dict[str, Any]:
    """
    Clean dictionary by removing None or empty values
    """
    cleaned = {}
    
    for key, value in data.items():
        if remove_none and value is None:
            continue
        
        if remove_empty and (value == "" or value == [] or value == {}):
            continue
        
        cleaned[key] = value
    
    return cleaned

def merge_dicts(*dicts: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge multiple dictionaries
    """
    result = {}
    for d in dicts:
        if d:
            result.update(d)
    return result

def chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:
    """
    Split list into chunks of specified size
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]

def flatten_list(nested_list: List[List[Any]]) -> List[Any]:
    """
    Flatten nested list
    """
    return [item#!/usr/bin/env python3
"""
PRISM Carbon Registry Platform - Structure Generator Script
This script creates the complete modular file structure with basic implementations.

Usage: python generate_structure.py [project_name]
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List, Any

class StructureGenerator:
    def __init__(self, project_name: str = "prism-carbon-registry"):
        self.project_name = project_name
        self.base_path = Path(project_name)
        
    def create_structure(self):
        """Create the complete project structure"""
        print(f"Creating PRISM Carbon Registry structure: {self.project_name}")
        
        # Create all directories
        self._create_directories()
        
        # Create all files
        self._create_root_files()
        self._create_shared_packages()
        self._create_services()
        self._create_frontend()
        self._create_infrastructure()
        self._create_tools()
        self._create_documentation()
        self._create_tests()
        self._create_github_workflows()
        
        print(f"\n‚úÖ Structure created successfully!")
        print(f"üìÅ Project location: {self.base_path.absolute()}")
        print(f"\nNext steps:")
        print(f"1. cd {self.project_name}")
        print(f"2. docker-compose up -d")
        print(f"3. ./tools/scripts/setup.sh")
        
    def _create_directories(self):
        """Create all necessary directories"""
        directories = [
            # Root level
            "",
            
            # Shared packages
            "packages/common/database",
            "packages/common/models", 
            "packages/common/auth",
            "packages/common/messaging",
            "packages/common/config",
            "packages/common/exceptions",
            "packages/common/logging",
            "packages/common/utils",
            "packages/blockchain/hedera",
            "packages/blockchain/contracts",
            "packages/blockchain/interfaces",
            
            # Services
            "services/api-gateway/app/middleware",
            "services/api-gateway/app/routing",
            "services/api-gateway/app/auth",
            "services/api-gateway/config",
            
            # User service
            "services/user-service/app/domain/entities",
            "services/user-service/app/domain/services", 
            "services/user-service/app/domain/repositories",
            "services/user-service/app/domain/exceptions",
            "services/user-service/app/infrastructure/database/repositories",
            "services/user-service/app/infrastructure/database/migrations",
            "services/user-service/app/infrastructure/external",
            "services/user-service/app/infrastructure/messaging",
            "services/user-service/app/application/commands",
            "services/user-service/app/application/queries",
            "services/user-service/app/application/dto",
            "services/user-service/app/application/events",
            "services/user-service/app/presentation/api/v1/routes",
            "services/user-service/app/presentation/api/v1/schemas",
            "services/user-service/app/presentation/api/middleware",
            "services/user-service/app/presentation/events",
            "services/user-service/tests/unit",
            "services/user-service/tests/integration",
            "services/user-service/alembic",
            
            # Project service
            "services/project-service/app/domain/entities",
            "services/project-service/app/domain/services",
            "services/project-service/app/domain/repositories", 
            "services/project-service/app/infrastructure/database",
            "services/project-service/app/infrastructure/file_storage",
            "services/project-service/app/infrastructure/ai",
            "services/project-service/app/application/commands",
            "services/project-service/app/application/queries",
            "services/project-service/app/application/dto",
            "services/project-service/app/presentation/api/v1/routes",
            "services/project-service/app/presentation/api/v1/schemas",
            "services/project-service/tests",
            
            # Validation service
            "services/validation-service/app/domain/entities",
            "services/validation-service/app/domain/services",
            "services/validation-service/app/domain/repositories",
            "services/validation-service/app/infrastructure/ai",
            "services/validation-service/app/infrastructure/blockchain",
            "services/validation-service/app/application",
            "services/validation-service/app/presentation",
            "services/validation-service/tests",
            
            # Registry service
            "services/registry-service/app/domain/entities",
            "services/registry-service/app/domain/services", 
            "services/registry-service/app/domain/repositories",
            "services/registry-service/app/infrastructure/blockchain",
            "services/registry-service/app/infrastructure/ipfs",
            "services/registry-service/app/application",
            "services/registry-service/app/presentation",
            "services/registry-service/tests",
            
            # Exchange service
            "services/exchange-service/app/domain/entities",
            "services/exchange-service/app/domain/services",
            "services/exchange-service/app/domain/repositories",
            "services/exchange-service/app/infrastructure/matching",
            "services/exchange-service/app/infrastructure/websockets",
            "services/exchange-service/app/application",
            "services/exchange-service/app/presentation",
            "services/exchange-service/tests",
            
            # dMRV service
            "services/dmrv-service/app/domain/entities",
            "services/dmrv-service/app/domain/services",
            "services/dmrv-service/app/domain/repositories",
            "services/dmrv-service/app/infrastructure/satellite",
            "services/dmrv-service/app/infrastructure/iot",
            "services/dmrv-service/app/infrastructure/gis",
            "services/dmrv-service/app/infrastructure/ml",
            "services/dmrv-service/app/application",
            "services/dmrv-service/app/presentation",
            "services/dmrv-service/tests",
            
            # Governance service
            "services/governance-service/app/domain/entities",
            "services/governance-service/app/domain/services",
            "services/governance-service/app/domain/repositories",
            "services/governance-service/app/infrastructure",
            "services/governance-service/app/application",
            "services/governance-service/app/presentation",
            "services/governance-service/tests",
            
            # Notification service
            "services/notification-service/app/domain",
            "services/notification-service/app/infrastructure/email",
            "services/notification-service/app/infrastructure/sms",
            "services/notification-service/app/infrastructure/push",
            "services/notification-service/app/application",
            "services/notification-service/app/presentation",
            "services/notification-service/tests",
            
            # File service
            "services/file-service/app/domain/entities",
            "services/file-service/app/domain/services",
            "services/file-service/app/domain/repositories",
            "services/file-service/app/infrastructure/storage",
            "services/file-service/app/infrastructure/processing",
            "services/file-service/app/infrastructure/security",
            "services/file-service/app/application",
            "services/file-service/app/presentation",
            "services/file-service/tests",
            
            # Frontend
            "frontend/web-app/public",
            "frontend/web-app/src/components/common",
            "frontend/web-app/src/components/forms",
            "frontend/web-app/src/components/charts",
            "frontend/web-app/src/components/tables",
            "frontend/web-app/src/pages/public",
            "frontend/web-app/src/pages/dashboard",
            "frontend/web-app/src/pages/projects",
            "frontend/web-app/src/pages/validation",
            "frontend/web-app/src/pages/registry",
            "frontend/web-app/src/pages/exchange",
            "frontend/web-app/src/pages/admin",
            "frontend/web-app/src/services/api",
            "frontend/web-app/src/services/auth",
            "frontend/web-app/src/services/websockets",
            "frontend/web-app/src/hooks",
            "frontend/web-app/src/context",
            "frontend/web-app/src/utils",
            "frontend/web-app/src/types",
            "frontend/web-app/src/constants",
            "frontend/web-app/src/assets",
            "frontend/web-app/tests",
            "frontend/web-app/build",
            
            "frontend/mobile-app/android",
            "frontend/mobile-app/ios", 
            "frontend/mobile-app/src",
            "frontend/mobile-app/tests",
            
            "frontend/admin-panel/src",
            "frontend/admin-panel/tests",
            
            # Infrastructure
            "infrastructure/kubernetes/base",
            "infrastructure/kubernetes/overlays/development",
            "infrastructure/kubernetes/overlays/staging", 
            "infrastructure/kubernetes/overlays/production",
            "infrastructure/kubernetes/charts",
            "infrastructure/terraform/modules",
            "infrastructure/terraform/environments",
            "infrastructure/docker/base",
            "infrastructure/docker/production",
            "infrastructure/monitoring/prometheus",
            "infrastructure/monitoring/grafana",
            "infrastructure/monitoring/alertmanager",
            
            # Tools
            "tools/scripts",
            "tools/generators",
            "tools/linting",
            "tools/testing",
            
            # Documentation
            "docs/api",
            "docs/architecture", 
            "docs/deployment",
            "docs/user-guides",
            "docs/development",
            
            # Tests
            "tests/integration",
            "tests/e2e",
            "tests/performance",
            "tests/fixtures",
            
            # GitHub
            ".github/workflows",
        ]
        
        for directory in directories:
            path = self.base_path / directory
            path.mkdir(parents=True, exist_ok=True)
            
        print(f"üìÅ Created {len(directories)} directories")
        
    def _create_root_files(self):
        """Create root level files"""
        files = {
            "README.md": self._get_main_readme(),
            ".gitignore": self._get_gitignore(),
            ".env.example": self._get_env_example(),
            "docker-compose.yml": self._get_docker_compose(),
            "docker-compose.prod.yml": self._get_docker_compose_prod(),
            "Makefile": self._get_makefile(),
            "requirements.txt": "# Root level requirements for development tools\npytest>=7.0.0\nblack>=22.0.0\nflake8>=4.0.0\nmypy>=0.910\npre-commit>=2.15.0",
        }
        
        for filename, content in files.items():
            self._write_file("", filename, content)
            
    def _create_shared_packages(self):
        """Create shared packages"""
        
        # Common package files
        common_files = {
            "packages/common/__init__.py": "",
            "packages/common/database/__init__.py": "",
            "packages/common/database/base.py": self._get_database_base(),
            "packages/common/database/session.py": self._get_database_session(),
            "packages/common/database/utils.py": self._get_database_utils(),
            "packages/common/models/__init__.py": "",
            "packages/common/models/base.py": self._get_models_base(),
            "packages/common/models/user.py": self._get_user_model(),
            "packages/common/models/project.py": self._get_project_model(),
            "packages/common/models/enums.py": self._get_enums(),
            "packages/common/auth/__init__.py": "",
            "packages/common/auth/jwt_handler.py": self._get_jwt_handler(),
            "packages/common/auth/middleware.py": self._get_auth_middleware(),
            "packages/common/auth/decorators.py": self._get_auth_decorators(),
            "packages/common/messaging/__init__.py": "",
            "packages/common/messaging/event_bus.py": self._get_event_bus(),
            "packages/common/messaging/message_types.py": self._get_message_types(),
            "packages/common/messaging/publishers.py": self._get_publishers(),
            "packages/common/config/__init__.py": "",
            "packages/common/config/settings.py": self._get_settings(),
            "packages/common/config/environment.py": self._get_environment(),
            "packages/common/exceptions/__init__.py": "",
            "packages/common/exceptions/base.py": self._get_exceptions_base(),
            "packages/common/exceptions/business.py": self._get_business_exceptions(),
            "packages/common/exceptions/handlers.py": self._get_exception_handlers(),
            "packages/common/logging/__init__.py": "",
            "packages/common/logging/setup.py": self._get_logging_setup(),
            "packages/common/logging/formatters.py": self._get_logging_formatters(),
            "packages/common/logging/middleware.py": self._get_logging_middleware(),
            "packages/common/utils/__init__.py": "",
            "packages/common/utils/validation.py": self._get_validation_utils(),
            "packages/common/utils/serialization.py": self._get_serialization_utils(),
            "packages/common/utils/helpers.py": self._get_helper_utils(),
        }
        
        # Blockchain package files
        blockchain_files = {
            "packages/blockchain/__init__.py": "",
            "packages/blockchain/hedera/__init__.py": "",
            "packages/blockchain/hedera/client.py": self._get_hedera_client(),
            "packages/blockchain/hedera/contracts.py": self._get_hedera_contracts(),
            "packages/blockchain/hedera/utils.py": self._get_hedera_utils(),
            "packages/blockchain/contracts/CarbonAssetToken.sol": self._get_carbon_token_contract(),
            "packages/blockchain/interfaces/__init__.py": "",
            "packages/blockchain/interfaces/registry.py": self._get_registry_interface(),
        }
        
        all_files = {**common_files, **blockchain_files}
        
        for filepath, content in all_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_services(self):
        """Create all microservices"""
        services = [
            "api-gateway", "user-service", "project-service", 
            "validation-service", "registry-service", "exchange-service",
            "dmrv-service", "governance-service", "notification-service", "file-service"
        ]
        
        for service in services:
            self._create_service(service)
            
    def _create_service(self, service_name: str):
        """Create a single service with all necessary files"""
        service_path = f"services/{service_name}"
        
        # Basic service files
        files = {
            "Dockerfile": self._get_service_dockerfile(service_name),
            "requirements.txt": self._get_service_requirements(service_name),
            "app/__init__.py": "",
            "app/main.py": self._get_service_main(service_name),
            "tests/__init__.py": "",
            "tests/conftest.py": self._get_test_conftest(),
            "tests/unit/__init__.py": "",
            "tests/integration/__init__.py": "",
        }
        
        # Add service-specific files based on service type
        if service_name == "user-service":
            files.update(self._get_user_service_files())
        elif service_name == "project-service":
            files.update(self._get_project_service_files())
        elif service_name == "api-gateway":
            files.update(self._get_api_gateway_files())
        
        for filepath, content in files.items():
            path_parts = filepath.split("/")
            directory = "/".join([service_path] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_frontend(self):
        """Create frontend applications"""
        
        # Web app files
        web_files = {
            "package.json": self._get_frontend_package_json(),
            "Dockerfile": self._get_frontend_dockerfile(),
            "public/index.html": self._get_frontend_index_html(),
            "src/index.tsx": self._get_frontend_index_tsx(),
            "src/App.tsx": self._get_frontend_app_tsx(),
            "src/components/common/Button.tsx": self._get_button_component(),
            "src/components/common/Modal.tsx": self._get_modal_component(),
            "src/pages/public/HomePage.tsx": self._get_home_page(),
            "src/pages/dashboard/DashboardPage.tsx": self._get_dashboard_page(),
            "src/services/api/client.ts": self._get_api_client(),
            "src/services/auth/authService.ts": self._get_auth_service(),
            "src/hooks/useAuth.ts": self._get_use_auth_hook(),
            "src/context/AuthContext.tsx": self._get_auth_context(),
            "src/types/index.ts": self._get_frontend_types(),
            "src/constants/index.ts": self._get_frontend_constants(),
            "tests/setup.ts": self._get_frontend_test_setup(),
        }
        
        for filepath, content in web_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["frontend/web-app"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_infrastructure(self):
        """Create infrastructure files"""
        
        infra_files = {
            # Kubernetes
            "kubernetes/base/namespace.yaml": self._get_k8s_namespace(),
            "kubernetes/base/configmap.yaml": self._get_k8s_configmap(),
            "kubernetes/overlays/development/kustomization.yaml": self._get_k8s_kustomization_dev(),
            
            # Terraform
            "terraform/main.tf": self._get_terraform_main(),
            "terraform/variables.tf": self._get_terraform_variables(),
            "terraform/outputs.tf": self._get_terraform_outputs(),
            
            # Monitoring
            "monitoring/prometheus/prometheus.yml": self._get_prometheus_config(),
            "monitoring/grafana/dashboard.json": self._get_grafana_dashboard(),
        }
        
        for filepath, content in infra_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["infrastructure"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tools(self):
        """Create development tools"""
        
        tools_files = {
            "scripts/setup.sh": self._get_setup_script(),
            "scripts/build.sh": self._get_build_script(),
            "scripts/deploy.sh": self._get_deploy_script(),
            "scripts/test.sh": self._get_test_script(),
            "scripts/migrate.sh": self._get_migrate_script(),
            "linting/pyproject.toml": self._get_pyproject_toml(),
            "linting/.flake8": self._get_flake8_config(),
            "testing/pytest.ini": self._get_pytest_config(),
        }
        
        for filepath, content in tools_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tools"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_documentation(self):
        """Create documentation files"""
        
        docs_files = {
            "README.md": self._get_docs_readme(),
            "architecture/overview.md": self._get_architecture_overview(),
            "architecture/services.md": self._get_services_architecture(),
            "deployment/local.md": self._get_local_deployment(),
            "deployment/production.md": self._get_production_deployment(),
            "development/getting-started.md": self._get_getting_started(),
            "development/contributing.md": self._get_contributing_guide(),
            "api/openapi.yml": self._get_openapi_spec(),
        }
        
        for filepath, content in docs_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["docs"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_tests(self):
        """Create test files"""
        
        test_files = {
            "integration/test_user_flow.py": self._get_integration_test(),
            "e2e/test_project_creation.py": self._get_e2e_test(),
            "performance/test_load.py": self._get_performance_test(),
            "fixtures/sample_data.json": self._get_test_fixtures(),
        }
        
        for filepath, content in test_files.items():
            path_parts = filepath.split("/")
            directory = "/".join(["tests"] + path_parts[:-1])
            filename = path_parts[-1]
            self._write_file(directory, filename, content)
            
    def _create_github_workflows(self):
        """Create GitHub Actions workflows"""
        
        workflow_files = {
            "ci.yml": self._get_ci_workflow(),
            "cd.yml": self._get_cd_workflow(),
            "security.yml": self._get_security_workflow(),
            "release.yml": self._get_release_workflow(),
        }
        
        for filename, content in workflow_files.items():
            self._write_file(".github/workflows", filename, content)
            
        # Additional GitHub files
        self._write_file(".github", "PULL_REQUEST_TEMPLATE.md", self._get_pr_template())
        
    def _write_file(self, directory: str, filename: str, content: str):
        """Write content to a file"""
        if directory:
            file_path = self.base_path / directory / filename
        else:
            file_path = self.base_path / filename
            
        # Create directory if it doesn't exist
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    # Content generation methods
    def _get_main_readme(self) -> str:
        return '''# PRISM Carbon Registry Platform

A comprehensive, modular system for end-to-end carbon credit management with AI-powered validation, blockchain-based registry, and automated monitoring.

## Architecture

This platform follows a microservices architecture with the following key principles:
- **Domain-Driven Design (DDD)** for clear business boundaries
- **Clean Architecture** for maintainable, testable code
- **Event-Driven Architecture** for loose coupling
- **CQRS** for optimized read/write operations

## Services

- **API Gateway**: Request routing, authentication, rate limiting
- **User Service**: User management and authentication
- **Project Service**: Carbon project management and documentation
- **Validation Service**: AI-powered project validation and verification
- **Registry Service**: Blockchain-based carbon credit registry
- **Exchange Service**: Carbon credit trading platform
- **dMRV Service**: Digital monitoring, reporting, and verification
- **Governance Service**: Compliance and policy management
- **Notification Service**: Multi-channel notifications
- **File Service**: Secure file storage and processing

## Quick Start

1. **Clone and setup**:
   ```bash
   git clone <repository-url>
   cd prism-carbon-registry
   cp .env.example .env
   ```

2. **Start infrastructure**:
   ```bash
   docker-compose up -d
   ```

3. **Initialize services**:
   ```bash
   ./tools/scripts/setup.sh
   ```

4. **Run migrations**:
   ```bash
   ./tools/scripts/migrate.sh
   ```

5. **Access the platform**:
   - Web App: http://localhost:3000
   - API Gateway: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

## Development

See [Development Guide](docs/development/getting-started.md) for detailed setup instructions.

## Documentation

- [Architecture Overview](docs/architecture/overview.md)
- [Services Documentation](docs/architecture/services.md)
- [API Documentation](docs/api/)
- [Deployment Guides](docs/deployment/)

## Contributing

Please read our [Contributing Guide](docs/development/contributing.md) before submitting pull requests.

## License

[Your License Here]
'''

    def _get_gitignore(self) -> str:
        return '''# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# React
/build
/coverage

# Environment files
.env.local
.env.development.local
.env.test.local
.env.production.local

# Docker
docker-compose.override.yml

# Kubernetes secrets
*-secret.yaml

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Test coverage
.coverage
htmlcov/
.pytest_cache/

# Blockchain
contracts/build/
.openzeppelin/

# IDE
*.code-workspace
'''

    def _get_env_example(self) -> str:
        return '''# Database Configuration
DATABASE_URL=postgresql://prism:prism_password@localhost:5432/prism_core
MONGO_URL=mongodb://localhost:27017/prism

# Redis
REDIS_URL=redis://localhost:6379

# JWT Configuration
JWT_SECRET=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Hedera Configuration
HEDERA_ACCOUNT_ID=0.0.123456
HEDERA_PRIVATE_KEY=your-hedera-private-key
HEDERA_NETWORK=testnet

# API Keys
OPENAI_API_KEY=your-openai-api-key
SATELLITE_API_KEY=your-satellite-data-api-key

# Email Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# File Storage
FILE_STORAGE_TYPE=local  # local, s3, gcs
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_BUCKET_NAME=your-s3-bucket

# External Services
VERRA_API_URL=https://registry.verra.org/api
GOLD_STANDARD_API_URL=https://registry.goldstandard.org/api

# Monitoring
SENTRY_DSN=your-sentry-dsn
PROMETHEUS_PORT=9090

# Development
DEBUG=true
LOG_LEVEL=DEBUG
'''

    def _get_docker_compose(self) -> str:
        return '''version: "3.9"

services:
  # Databases
  postgres:
    image: postgis/postgis:15-3.3-alpine
    container_name: prism_postgres
    environment:
      POSTGRES_USER: prism
      POSTGRES_PASSWORD: prism_password
      POSTGRES_DB: prism_core
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - prism_network

  mongodb:
    image: mongo:6.0
    container_name: prism_mongodb
    environment:
      MONGO_INITDB_DATABASE: prism
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    networks:
      - prism_network

  redis:
    image: redis:7-alpine
    container_name: prism_redis
    ports:
      - "6379:6379"
    networks:
      - prism_network

  # Services
  api-gateway:
    build: ./services/api-gateway
    container_name: prism_api_gateway
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  user-service:
    build: ./services/user-service
    container_name: prism_user_service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    networks:
      - prism_network

  project-service:
    build: ./services/project-service
    container_name: prism_project_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://prism:prism_password@postgres:5432/prism_core
      - MONGO_URL=mongodb://mongodb:27017/prism
    depends_on:
      - postgres
      - mongodb
    networks:
      - prism_network

  # Frontend
  web-app:
    build: ./frontend/web-app
    container_name: prism_web_app
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - api-gateway
    networks:
      - prism_network

  # Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prism_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - prism_network

  grafana:
    image: grafana/grafana:latest
    container_name: prism_grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - prism_network

networks:
  prism_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  grafana_data:
'''

    def _get_docker_compose_prod(self) -> str:
        return '''version: "3.9"

services:
  # Production configuration with health checks, resource limits, etc.
  postgres:
    image: postgis/postgis:15-3.3-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - prism_network

  # Add other production services...

networks:
  prism_network:
    external: true

volumes:
  postgres_data:
    external: true
'''

    def _get_makefile(self) -> str:
        return '''# PRISM Carbon Registry Platform Makefile

.PHONY: help setup build test lint clean deploy

help: ## Show this help message
	@echo "Available commands:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $1, $2}'

setup: ## Setup development environment
	@echo "Setting up development environment..."
	./tools/scripts/setup.sh

build: ## Build all services
	@echo "Building all services..."
	./tools/scripts/build.sh

test: ## Run all tests
	@echo "Running tests..."
	./tools/scripts/test.sh

lint: ## Run linting
	@echo "Running linters..."
	black --check .
	flake8 .
	mypy .

format: ## Format code
	@echo "Formatting code..."
	black .
	isort .

clean: ## Clean up containers and volumes
	@echo "Cleaning up..."
	docker-compose down -v
	docker system prune -f

migrate: ## Run database migrations
	@echo "Running migrations..."
	./tools/scripts/migrate.sh

deploy-dev: ## Deploy to development
	@echo "Deploying to development..."
	./tools/scripts/deploy.sh dev

deploy-prod: ## Deploy to production
	@echo "Deploying to production..."
	./tools/scripts/deploy.sh prod

logs: ## Show logs
	docker-compose logs -f

up: ## Start all services
	docker-compose up -d

down: ## Stop all services
	docker-compose down

restart: ## Restart all services
	docker-compose restart
'''

    def _get_database_base(self) -> str:
        return '''"""
Base database configuration and utilities
"""

from sqlalchemy import create_engine, MetaData
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from typing import Optional

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://prism:prism_password@localhost:5432/prism_core")

# SQLAlchemy engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=os.getenv("DB_ECHO", "false").lower() == "true"
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()

# Metadata
metadata = MetaData()

def get_db():
    """
    Dependency to get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_tables():
    """
    Create all tables
    """
    Base.metadata.create_all(bind=engine)

def drop_tables():
    """
    Drop all tables
    """
    Base.metadata.drop_all(bind=engine)
'''

    def _get_database_session(self) -> str:
        return '''"""
Database session management
"""

from contextlib import contextmanager
from sqlalchemy.orm import Session
from .base import SessionLocal
import logging

logger = logging.getLogger(__name__)

@contextmanager
def get_db_session():
    """
    Context manager for database sessions
    """
    session: Session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        logger.error(f"Database session error: {e}")
        raise
    finally:
        session.close()

class DatabaseSession:
    """
    Database session wrapper
    """
    
    def __init__(self):
        self.session: Session = SessionLocal()
    
    def __enter__(self):
        return self.session
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.session.rollback()
        else:
            self.session.commit()
        self.session.close()
'''

    def _get_database_utils(self) -> str:
        return '''"""
Database utility functions
"""

from sqlalchemy import text
from sqlalchemy.orm import Session
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)

def execute_raw_sql(session: Session, query: str, params: Dict[str, Any] = None) -> List[Dict]:
    """
    Execute raw SQL query
    """
    try:
        result = session.execute(text(query), params or {})
        return [dict(row) for row in result]
    except Exception as e:
        logger.error(f"Error executing raw SQL: {e}")
        raise

def check_table_exists(session: Session, table_name: str) -> bool:
    """
    Check if table exists
    """
    query = """
    SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_name = :table_name
    );
    """
    result = session.execute(text(query), {"table_name": table_name})
    return result.scalar()

def get_table_row_count(session: Session, table_name: str) -> int:
    """
    Get row count for a table
    """
    query = f"SELECT COUNT(*) FROM {table_name}"
    result = session.execute(text(query))
    return result.scalar()
'''

    def _get_models_base(self) -> str:
        return '''"""
Base models and mixins
"""

from sqlalchemy import Column, Integer, DateTime, String, Boolean
from sqlalchemy.sql import func
from packages.common.database.base import Base
import uuid

class TimestampMixin:
    """
    Mixin for created_at and updated_at timestamps
    """
    created_at = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now(), nullable=False)

class UUIDMixin:
    """
    Mixin for UUID primary key
    """
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))

class BaseModel(Base, TimestampMixin, UUIDMixin):
    """
    Base model with common fields
    """
    __abstract__ = True
    
    is_active = Column(Boolean, default=True, nullable=False)
    
    def to_dict(self):
        """
        Convert model to dictionary
        """
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
    
    def __repr__(self):
        return f"<{self.__class__.__name__}(id={self.id})>"
'''

    def _get_user_model(self) -> str:
        return '''"""
User model
"""

from sqlalchemy import Column, String, Boolean, Enum as SQLEnum
from packages.common.models.base import BaseModel
from packages.common.models.enums import UserRole, UserStatus
import enum

class User(BaseModel):
    """
    User model
    """
    __tablename__ = "users"
    
    email = Column(String(255), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=False)
    organization = Column(String(255))
    phone = Column(String(50))
    country = Column(String(100))
    role = Column(SQLEnum(UserRole), default=UserRole.PROJECT_DEVELOPER, nullable=False)
    status = Column(SQLEnum(UserStatus), default=UserStatus.ACTIVE, nullable=False)
    is_verified = Column(Boolean, default=False, nullable=False)
    last_login = Column(String)  # Store as ISO string
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
    
    def can_validate_projects(self) -> bool:
        return self.role in [UserRole.VALIDATOR, UserRole.ADMIN]
    
    def can_issue_credits(self) -> bool:
        return self.role in [UserRole.REGISTRY_ADMIN, UserRole.ADMIN]
'''

    def _get_project_model(self) -> str:
        return '''"""
Project model
"""

from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from packages.common.models.base import BaseModel
from packages.common.models.enums import ProjectType, ProjectStatus

class Project(BaseModel):
    """
    Carbon project model
    """
    __tablename__ = "projects"
    
    project_id = Column(String(100), unique=True, nullable=False, index=True)
    name = Column(String(255), nullable=False)
    description = Column(Text)
    project_type = Column(SQLEnum(ProjectType), nullable=False)
    methodology = Column(String(100))
    country = Column(String(100), nullable=False)
    region = Column(String(100))
    area_hectares = Column(Float)
    estimated_annual_reduction = Column(Integer)  # tCO2e per year
    total_estimated_reduction = Column(Integer)  # Total tCO2e over project lifetime
    crediting_period_start = Column(String)  # ISO date string
    crediting_period_end = Column(String)    # ISO date string
    status = Column(SQLEnum(ProjectStatus), default=ProjectStatus.DRAFT, nullable=False)
    
    # Foreign keys
    owner_id = Column(String, ForeignKey("users.id"), nullable=False)
    validator_id = Column(String, ForeignKey("users.id"))
    
    # Issued credits tracking
    issued_credits = Column(Integer, default=0)
    available_credits = Column(Integer, default=0)
    retired_credits = Column(Integer, default=0)
    
    # Relationships
    owner = relationship("User", foreign_keys=[owner_id])
    validator = relationship("User", foreign_keys=[validator_id])
    
    def get_status_display(self) -> str:
        return self.status.value.replace("_", " ").title()
    
    def is_editable(self) -> bool:
        return self.status in [ProjectStatus.DRAFT, ProjectStatus.REJECTED]
    
    def can_issue_credits(self) -> bool:
        return self.status == ProjectStatus.REGISTERED
'''

    def _get_enums(self) -> str:
        return '''"""
Common enums used across the platform
"""

from enum import Enum

class UserRole(str, Enum):
    """User roles"""
    ADMIN = "admin"
    PROJECT_DEVELOPER = "project_developer"
    VALIDATOR = "validator"
    AUDITOR = "auditor"
    REGISTRY_ADMIN = "registry_admin"
    TRADER = "trader"
    BUYER = "buyer"

class UserStatus(str, Enum):
    """User status"""
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    PENDING = "pending"

class ProjectType(str, Enum):
    """Carbon project types"""
    FORESTRY = "forestry"
    RENEWABLE_ENERGY = "renewable_energy"
    ENERGY_EFFICIENCY = "energy_efficiency"
    METHANE_CAPTURE = "methane_capture"
    INDUSTRIAL = "industrial"
    AGRICULTURE = "agriculture"
    WASTE_MANAGEMENT = "waste_management"
    TRANSPORT = "transport"
    BLUE_CARBON = "blue_carbon"
    DIRECT_AIR_CAPTURE = "direct_air_capture"

class ProjectStatus(str, Enum):
    """Project status"""
    DRAFT = "draft"
    SUBMITTED = "submitted"
    UNDER_VALIDATION = "under_validation"
    VALIDATED = "validated"
    REJECTED = "rejected"
    REGISTERED = "registered"
    ACTIVE = "active"
    SUSPENDED = "suspended"
    COMPLETED = "completed"

class DocumentType(str, Enum):
    """Document types"""
    PDD = "pdd"
    MONITORING_REPORT = "monitoring_report"
    VALIDATION_REPORT = "validation_report"
    VERIFICATION_REPORT = "verification_report"
    PROJECT_PHOTO = "project_photo"
    SATELLITE_IMAGE = "satellite_image"
    LEGAL_DOCUMENT = "legal_document"
    CERTIFICATE = "certificate"
    OTHER = "other"

class CreditStatus(str, Enum):
    """Carbon credit status"""
    ISSUED = "issued"
    AVAILABLE = "available"
    RESERVED = "reserved"
    TRANSFERRED = "transferred"
    RETIRED = "retired"
    CANCELLED = "cancelled"

class TransactionType(str, Enum):
    """Transaction types"""
    ISSUANCE = "issuance"
    TRANSFER = "transfer"
    RETIREMENT = "retirement"
    CANCELLATION = "cancellation"
'''

    def _get_auth_middleware(self) -> str:
        return '''"""
Authentication middleware for FastAPI
"""

from fastapi import Request, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from typing import Optional
import logging
from .jwt_handler import verify_token

logger = logging.getLogger(__name__)
security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Get current user from JWT token
    """
    try:
        payload = verify_token(credentials.credentials)
        if payload is None:
            raise HTTPException(status_code=401, detail="Invalid or expired token")
        
        return payload
    except Exception as e:
        logger.error(f"Authentication error: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

async def get_current_user_optional(request: Request) -> Optional[dict]:
    """
    Get current user optionally (doesn't raise error if no token)
    """
    try:
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None
        
        token = auth_header.split(" ")[1]
        payload = verify_token(token)
        return payload
    except Exception:
        return None

def require_role(required_role: str):
    """
    Decorator to require specific user role
    """
    def role_checker(current_user: dict = Depends(get_current_user)):
        user_role = current_user.get("role")
        if user_role != required_role:
            raise HTTPException(
                status_code=403, 
                detail=f"Access denied. Required role: {required_role}"
            )
        return current_user
    return role_checker
'''

    def _get_auth_decorators(self) -> str:
        return '''"""
Authentication decorators and utilities
"""

from functools import wraps
from typing import Callable, List, Optional
from fastapi import HTTPException, Depends
from .middleware import get_current_user
import logging

logger = logging.getLogger(__name__)

def authenticated(func: Callable) -> Callable:
    """
    Decorator to require authentication
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        # This decorator is used with FastAPI Depends in route definitions
        current_user = kwargs.get('current_user')
        if not current_user:
            raise HTTPException(status_code=401, detail="Authentication required")
        return await func(*args, **kwargs)
    return wrapper

def require_roles(allowed_roles: List[str]):
    """
    Decorator factory to require specific roles
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_role = current_user.get('role')
            if user_role not in allowed_roles:
                raise HTTPException(
                    status_code=403, 
                    detail=f"Access denied. Required roles: {', '.join(allowed_roles)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator

def require_permissions(required_permissions: List[str]):
    """
    Decorator factory to require specific permissions
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="Authentication required")
            
            user_permissions = current_user.get('permissions', [])
            missing_permissions = set(required_permissions) - set(user_permissions)
            
            if missing_permissions:
                raise HTTPException(
                    status_code=403,
                    detail=f"Missing permissions: {', '.join(missing_permissions)}"
                )
            return await func(*args, **kwargs)
        return wrapper
    return decorator
'''

    def _get_jwt_handler(self) -> str:
        return '''"""
JWT token handling utilities
"""

import jwt
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)

JWT_SECRET = os.getenv("JWT_SECRET", "your-secret-key")
JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
JWT_EXPIRATION_HOURS = int(os.getenv("JWT_EXPIRATION_HOURS", "24"))

def create_access_token(data: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> str:
    """
    Create JWT access token
    """
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(hours=JWT_EXPIRATION_HOURS)
    
    to_encode.update({"exp": expire, "iat": datetime.utcnow()})
    
    try:
        encoded_jwt = jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALGORITHM)
        return encoded_jwt
    except Exception as e:
        logger.error(f"Error creating JWT token: {e}")
        raise

def verify_token(token: str) -> Optional[Dict[str, Any]]:
    """
    Verify and decode JWT token
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload
    except jwt.ExpiredSignatureError:
        logger.warning("JWT token has expired")
        return None
    except jwt.JWTError as e:
        logger.error(f"JWT verification error: {e}")
        return None

def refresh_token(token: str) -> Optional[str]:
    """
    Refresh JWT token if valid
    """
    payload = verify_token(token)
    if payload:
        # Remove exp and iat from payload
        payload.pop("exp", None)
        payload.pop("iat", None)
        return create_access_token(payload)
    return None
'''

    def _get_message_types(self) -> str:
        return '''"""
Message types for event bus communication
"""

from dataclasses import dataclass
from typing import Any, Dict, Optional
from datetime import datetime
from packages.common.models.enums import ProjectStatus, UserRole

@dataclass
class UserCreatedEvent:
    """Event fired when a new user is created"""
    user_id: str
    email: str
    full_name: str
    role: UserRole
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectCreatedEvent:
    """Event fired when a new project is created"""
    project_id: str
    owner_id: str
    project_name: str
    project_type: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ProjectStatusChangedEvent:
    """Event fired when project status changes"""
    project_id: str
    old_status: ProjectStatus
    new_status: ProjectStatus
    changed_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class DocumentUploadedEvent:
    """Event fired when a document is uploaded"""
    project_id: str
    document_id: str
    document_type: str
    uploaded_by: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class ValidationCompletedEvent:
    """Event fired when project validation is completed"""
    project_id: str
    validator_id: str
    validation_result: str  # "approved" or "rejected"
    feedback: Optional[str] = None
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsIssuedEvent:
    """Event fired when carbon credits are issued"""
    project_id: str
    credit_batch_id: str
    amount: int
    issued_to: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsTransferredEvent:
    """Event fired when credits are transferred"""
    from_address: str
    to_address: str
    credit_batch_id: str
    amount: int
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()

@dataclass
class CreditsRetiredEvent:
    """Event fired when credits are retired"""
    retired_by: str
    credit_batch_id: str
    amount: int
    retirement_reason: str
    blockchain_tx_hash: str
    timestamp: str = datetime.utcnow().isoformat()
'''

    def _get_publishers(self) -> str:
        return '''"""
Event publishers for different services
"""

import asyncio
import logging
from typing import Any, Dict
from .event_bus import event_bus, Event
from .message_types import *

logger = logging.getLogger(__name__)

class EventPublisher:
    """Base event publisher"""
    
    def __init__(self, service_name: str):
        self.service_name = service_name
    
    async def publish_event(self, event_type: str, data: Dict[str, Any], correlation_id: str = None):
        """Publish a generic event"""
        event = Event(
            event_type=event_type,
            data=data,
            timestamp=datetime.utcnow().isoformat(),
            source_service=self.service_name,
            correlation_id=correlation_id
        )
        await event_bus.publish(event)

class UserEventPublisher(EventPublisher):
    """Publisher for user-related events"""
    
    def __init__(self):
        super().__init__("user-service")
    
    async def publish_user_created(self, user_data: UserCreatedEvent):
        """Publish user created event"""
        await self.publish_event("user.created", user_data.__dict__)

class ProjectEventPublisher(EventPublisher):
    """Publisher for project-related events"""
    
    def __init__(self):
        super().__init__("project-service")
    
    async def publish_project_created(self, project_data: ProjectCreatedEvent):
        """Publish project created event"""
        await self.publish_event("project.created", project_data.__dict__)
    
    async def publish_project_status_changed(self, status_data: ProjectStatusChangedEvent):
        """Publish project status changed event"""
        await self.publish_event("project.status_changed", status_data.__dict__)
    
    async def publish_document_uploaded(self, document_data: DocumentUploadedEvent):
        """Publish document uploaded event"""
        await self.publish_event("document.uploaded", document_data.__dict__)

class RegistryEventPublisher(EventPublisher):
    """Publisher for registry-related events"""
    
    def __init__(self):
        super().__init__("registry-service")
    
    async def publish_credits_issued(self, credits_data: CreditsIssuedEvent):
        """Publish credits issued event"""
        await self.publish_event("credits.issued", credits_data.__dict__)
    
    async def publish_credits_transferred(self, transfer_data: CreditsTransferredEvent):
        """Publish credits transferred event"""
        await self.publish_event("credits.transferred", transfer_data.__dict__)
    
    async def publish_credits_retired(self, retirement_data: CreditsRetiredEvent):
        """Publish credits retired event"""
        await self.publish_event("credits.retired", retirement_data.__dict__)

class ValidationEventPublisher(EventPublisher):
    """Publisher for validation-related events"""
    
    def __init__(self):
        super().__init__("validation-service")
    
    async def publish_validation_completed(self, validation_data: ValidationCompletedEvent):
        """Publish validation completed event"""
        await self.publish_event("validation.completed", validation_data.__dict__)
'''

    def _get_environment(self) -> str:
        return '''"""
Environment configuration utilities
"""

import os
from enum import Enum
from typing import Optional

class Environment(str, Enum):
    """Environment types"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"

def get_environment() -> Environment:
    """Get current environment"""
    env_name = os.getenv("ENVIRONMENT", "development").lower()
    
    try:
        return Environment(env_name)
    except ValueError:
        return Environment.DEVELOPMENT

def is_development() -> bool:
    """Check if running in development"""
    return get_environment() == Environment.DEVELOPMENT

def is_production() -> bool:
    """Check if running in production"""
    return get_environment() == Environment.PRODUCTION

def is_testing() -> bool:
    """Check if running in testing"""
    return get_environment() == Environment.TESTING

def get_log_level() -> str:
    """Get appropriate log level for environment"""
    env = get_environment()
    
    if env == Environment.PRODUCTION:
        return "WARNING"
    elif env == Environment.TESTING:
        return "ERROR"
    else:
        return "DEBUG"

def get_database_echo() -> bool:
    """Get database echo setting for environment"""
    return is_development() and os.getenv("DB_ECHO", "false").lower() == "true"
'''

    def _get_business_exceptions(self) -> str:
        return '''"""
Business-specific exceptions
"""

from .base import BaseException, ErrorCode

# User-related exceptions
class UserNotFoundError(BaseException):
    """User not found error"""
    
    def __init__(self, user_id: str):
        super().__init__(
            message=f"User with ID {user_id} not found",
            error_code=ErrorCode.USER_NOT_FOUND,
            status_code=404
        )

class UserAlreadyExistsError(BaseException):
    """User already exists error"""
    
    def __init__(self, email: str):
        super().__init__(
            message=f"User with email {email} already exists",
            error_code=ErrorCode.USER_ALREADY_EXISTS,
            status_code=409
        )

class InvalidCredentialsError(BaseException):
    """Invalid credentials error"""
    
    def __init__(self):
        super().__init__(
            message="Invalid email or password",
            error_code=ErrorCode.INVALID_CREDENTIALS,
            status_code=401
        )

# Project-related exceptions
class ProjectNotFoundError(BaseException):
    """Project not found error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} not found",
            error_code=ErrorCode.PROJECT_NOT_FOUND,
            status_code=404
        )

class ProjectAlreadyExistsError(BaseException):
    """Project already exists error"""
    
    def __init__(self, project_id: str):
        super().__init__(
            message=f"Project with ID {project_id} already exists",
            error_code=ErrorCode.PROJECT_ALREADY_EXISTS,
            status_code=409
        )

class InvalidProjectStatusError(BaseException):
    """Invalid project status transition error"""
    
    def __init__(self, current_status: str, new_status: str):
        super().__init__(
            message=f"Cannot change project status from {current_status} to {new_status}",
            error_code=ErrorCode.INVALID_PROJECT_STATUS,
            status_code=400
        )

# File-related exceptions
class FileNotFoundError(BaseException):
    """File not found error"""
    
    def __init__(self, file_id: str):
        super().__init__(
            message=f"File with ID {file_id} not found",
            error_code=ErrorCode.FILE_NOT_FOUND,
            status_code=404
        )

class FileTooLargeError(BaseException):
    """File too large error"""
    
    def __init__(self, max_size: int):
        super().__init__(
            message=f"File size exceeds maximum allowed size of {max_size} bytes",
            error_code=ErrorCode.FILE_TOO_LARGE,
            status_code=413
        )

class InvalidFileTypeError(BaseException):
    """Invalid file type error"""
    
    def __init__(self, file_type: str, allowed_types: list):
        super().__init__(
            message=f"File type {file_type} not allowed. Allowed types: {', '.join(allowed_types)}",
            error_code=ErrorCode.INVALID_FILE_TYPE,
            status_code=400
        )

# Blockchain-related exceptions
class BlockchainError(BaseException):
    """General blockchain error"""
    
    def __init__(self, message: str = "Blockchain operation failed"):
        super().__init__(
            message=message,
            error_code=ErrorCode.BLOCKCHAIN_ERROR,
            status_code=500
        )

class InsufficientBalanceError(BaseException):
    """Insufficient balance error"""
    
    def __init__(self, required: int, available: int):
        super().__init__(
            message=f"Insufficient balance. Required: {required}, Available: {available}",
            error_code=ErrorCode.INSUFFICIENT_BALANCE,
            status_code=400
        )

class TransactionFailedError(BaseException):
    """Transaction failed error"""
    
    def __init__(self, tx_hash: str, reason: str = "Unknown"):
        super().__init__(
            message=f"Transaction {tx_hash} failed: {reason}",
            error_code=ErrorCode.TRANSACTION_FAILED,
            status_code=500
        )
'''

    def _get_exception_handlers(self) -> str:
        return '''"""
Exception handlers for FastAPI applications
"""

from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from typing import Union
from .base import BaseException

logger = logging.getLogger(__name__)

async def base_exception_handler(request: Request, exc: BaseException):
    """Handle custom base exceptions"""
    
    logger.error(
        f"Business exception: {exc.error_code.value}",
        extra={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": exc.error_code.value,
            "message": exc.message,
            "details": exc.details,
        }
    )

async def validation_exception_handler(request: Request, exc: RequestValidationError):
    """Handle FastAPI validation errors"""
    
    logger.warning(
        f"Validation error on {request.method} {request.url.path}",
        extra={"validation_errors": exc.errors()}
    )
    
    return JSONResponse(
        status_code=422,
        content={
            "error_code": "VALIDATION_ERROR",
            "message": "Validation failed",
            "details": {
                "validation_errors": exc.errors()
            }
        }
    )

async def http_exception_handler(request: Request, exc: Union[HTTPException, StarletteHTTPException]):
    """Handle HTTP exceptions"""
    
    logger.warning(
        f"HTTP exception: {exc.status_code}",
        extra={
            "status_code": exc.status_code,
            "detail": str(exc.detail),
            "path": request.url.path,
            "method": request.method,
        }
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error_code": f"HTTP_{exc.status_code}",
            "message": str(exc.detail),
            "details": {}
        }
    )

async def general_exception_handler(request: Request, exc: Exception):
    """Handle unexpected exceptions"""
    
    logger.error(
        f"Unexpected exception: {type(exc).__name__}",
        extra={
            "exception_type": type(exc).__name__,
            "exception_message": str(exc),
            "path": request.url.path,
            "method": request.method,
        },
        exc_info=True
    )
    
    return JSONResponse(
        status_code=500,
        content={
            "error_code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred",
            "details": {}
        }
    )

def setup_exception_handlers(app):
    """Setup exception handlers for a FastAPI app"""
    
    app.add_exception_handler(BaseException, base_exception_handler)
    app.add_exception_handler(RequestValidationError, validation_exception_handler)
    app.add_exception_handler(HTTPException, http_exception_handler)
    app.add_exception_handler(StarletteHTTPException, http_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)
'''

    def _get_validation_utils(self) -> str:
        return '''"""
Event bus for inter-service communication
"""

import asyncio
import json
import logging
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

@dataclass
class Event:
    """Base event class"""
    event_type: str
    data: Dict[str, Any]
    timestamp: str
    source_service: str
    correlation_id: Optional[str] = None

class EventHandler(ABC):
    """Abstract event handler"""
    
    @abstractmethod
    async def handle(self, event: Event) -> None:
        pass

class EventBus:
    """
    Simple in-memory event bus
    In production, this would be replaced with Redis, RabbitMQ, or Kafka
    """
    
    def __init__(self):
        self._handlers: Dict[str, List[EventHandler]] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """Subscribe to an event type"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """Publish an event"""
        logger.info(f"Publishing event: {event.event_type}")
        
        # Call all subscribers
        if event.event_type in self._subscribers:
            for handler in self._subscribers[event.event_type]:
                try:
                    await handler(event)
                except Exception as e:
                    logger.error(f"Error in event handler: {e}")
    
    def register_handler(self, event_type: str, handler: EventHandler):
        """Register an event handler"""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

# Global event bus instance
event_bus = EventBus()
'''

    def _get_service_main(self, service_name: str) -> str:
        return f'''"""
{service_name.replace("-", " ").title()} Service Main Application
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from packages.common.logging.setup import setup_logging
from packages.common.config.settings import get_settings
import logging

# Setup logging
setup_logging()
logger = logging.getLogger(__name__)

# Get settings
settings = get_settings()

# Create FastAPI app
app = FastAPI(
    title="{service_name.replace("-", " ").title()} Service",
    description="PRISM Carbon Registry - {service_name.replace("-", " ").title()} Service",
    version="1.0.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {{"message": "{service_name.replace("-", " ").title()} Service is running"}}

@app.get("/health")
async def health_check():
    return {{"status": "healthy", "service": "{service_name}"}}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
'''

    def _get_service_dockerfile(self, service_name: str) -> str:
        return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
'''

    def _get_service_requirements(self, service_name: str) -> str:
        base_requirements = '''fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0
sqlalchemy>=2.0.0
alembic>=1.12.0
psycopg2-binary>=2.9.0
redis>=5.0.0
celery>=5.3.0
python-multipart>=0.0.6
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-dotenv>=1.0.0
requests>=2.31.0
'''
        
        service_specific = {
            'user-service': 'bcrypt>=4.0.0\nemail-validator>=2.0.0\n',
            'project-service': 'PyPDF2>=3.0.0\nPillow>=10.0.0\nopenai>=1.0.0\n',
            'validation-service': 'scikit-learn>=1.3.0\nnumpy>=1.24.0\n',
            'registry-service': 'web3>=6.0.0\nipfshttpclient>=0.8.0\n',
            'exchange-service': 'websockets>=11.0.0\n',
            'dmrv-service': 'gdal>=3.7.0\nrasterio>=1.3.0\n',
        }
        
        return base_requirements + service_specific.get(service_name, '')

    def _get_user_service_files(self) -> Dict[str, str]:
        return {
            "app/domain/entities/user.py": '''"""User domain entity"""

from dataclasses import dataclass
from typing import Optional
from packages.common.models.enums import UserRole, UserStatus

@dataclass
class UserEntity:
    id: str
    email: str
    full_name: str
    organization: Optional[str]
    role: UserRole
    status: UserStatus
    is_verified: bool
    
    def is_admin(self) -> bool:
        return self.role == UserRole.ADMIN
''',
            "app/domain/services/user_service.py": '''"""User domain service"""

from typing import Optional
from packages.common.exceptions.business import UserNotFoundError
from ..entities.user import UserEntity
from ..repositories.user_repository import UserRepository

class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository
    
    async def create_user(self, user_data: dict) -> UserEntity:
        """Create a new user"""
        return await self.user_repository.create(user_data)
    
    async def get_user_by_email(self, email: str) -> Optional[UserEntity]:
        """Get user by email"""
        return await self.user_repository.get_by_email(email)
    
    async def verify_user(self, user_id: str) -> bool:
        """Verify user account"""
        user = await self.user_repository.get_by_id(user_id)
        if not user:
            raise UserNotFoundError(f"User {user_id} not found")
        
        return await self.user_repository.update(user_id, {"is_verified": True})
''',
            "app/presentation/api/v1/routes/users.py": '''"""User API routes"""

from fastapi import APIRouter, Depends, HTTPException
from typing import List
from ..schemas.user import UserCreate, UserResponse
from ....domain.services.user_service import UserService

router = APIRouter(prefix="/users", tags=["users"])

@router.post("/", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    user_service: UserService = Depends()
):
    """Create a new user"""
    return await user_service.create_user(user_data.dict())

@router.get("/{user_id}", response_model=UserResponse)
async def get_user(
    user_id: str,
    user_service: UserService = Depends()
):
    """Get user by ID"""
    user = await user_service.get_user_by_id(user_id)
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    return user
''',
        }

    def _get_frontend_package_json(self) -> str:
        return '''{
  "name": "prism-web-app",
  "version": "1.0.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.11",
    "@types/react": "^18.0.26",
    "@types/react-dom": "^18.0.10",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.8.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.4",
    "web-vitals": "^2.1.4",
    "axios": "^1.2.2",
    "react-query": "^3.39.3",
    "@mui/material": "^5.11.2",
    "@mui/icons-material": "^5.11.0",
    "@emotion/react": "^11.10.5",
    "@emotion/styled": "^11.10.5",
    "recharts": "^2.4.3"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@types/react-router-dom": "^5.3.3"
  }
}'''

    def _get_setup_script(self) -> str:
        return '''#!/bin/bash

# PRISM Carbon Registry Platform Setup Script

set -e

echo "üöÄ Setting up PRISM Carbon Registry Platform..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker is not installed. Please install Docker first."
    exit 1
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose is not installed. Please install Docker Compose first."
    exit 1
fi

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo "üìù Creating .env file from .env.example..."
    cp .env.example .env
    echo "‚ö†Ô∏è  Please update the .env file with your actual configuration values"
fi

# Build and start services
echo "üèóÔ∏è  Building and starting services..."
docker-compose up -d --build

# Wait for services to be ready
echo "‚è≥ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "üìä Running database migrations..."
./tools/scripts/migrate.sh

# Install frontend dependencies
echo "üì¶ Installing frontend dependencies..."
cd frontend/web-app
npm install
cd ../..

echo "‚úÖ Setup complete!"
echo ""
echo "üåê Access the platform:"
echo "   - Web App: http://localhost:3000"
echo "   - API Gateway: http://localhost:8000"
echo "   - API Docs: http://localhost:8000/docs"
echo "   - Grafana: http://localhost:3001 (admin/admin)"
echo ""
echo "üîß Useful commands:"
echo "   - View logs: make logs"
echo "   - Run tests: make test"
echo "   - Stop services: make down"
'''

    def _get_ci_workflow(self) -> str:
        return '''name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run linting
      run: |
        black --check .
        flake8 .
        mypy .
    
    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  build:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push images
      run: |
        docker-compose build
        docker-compose push
'''

    def _get_carbon_token_contract(self) -> str:
        return '''// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/Pausable.sol";

/**
 * @title CarbonAssetToken
 * @dev ERC1155 token for carbon credits and project NFTs
 */
contract CarbonAssetToken is ERC1155, Ownable, Pausable {
    
    // Token types
    uint256 public constant PROJECT_NFT = 1;
    uint256 public constant CARBON_CREDIT = 2;
    
    // Mapping from token ID to project metadata URI
    mapping(uint256 => string) private _tokenURIs;
    
    // Mapping from token ID to total supply
    mapping(uint256 => uint256) public totalSupply;
    
    // Events
    event CreditIssued(uint256 indexed tokenId, address indexed to, uint256 amount);
    event CreditRetired(uint256 indexed tokenId, address indexed from, uint256 amount);
    
    constructor(string memory uri) ERC1155(uri) {}
    
    /**
     * @dev Issue carbon credits
     */
    function issueCredits(
        address to,
        uint256 tokenId,
        uint256 amount,
        string memory tokenURI,
        bytes memory data
    ) public onlyOwner {
        _mint(to, tokenId, amount, data);
        totalSupply[tokenId] += amount;
        
        if (bytes(tokenURI).length > 0) {
            _setTokenURI(tokenId, tokenURI);
        }
        
        emit CreditIssued(tokenId, to, amount);
    }
    
    /**
     * @dev Retire carbon credits (burn)
     */
    function retireCredits(uint256 tokenId, uint256 amount) public {
        _burn(msg.sender, tokenId, amount);
        totalSupply[tokenId] -= amount;
        
        emit CreditRetired(tokenId, msg.sender, amount);
    }
    
    /**
     * @dev Set token URI
     */
    function _setTokenURI(uint256 tokenId, string memory tokenURI) internal {
        _tokenURIs[tokenId] = tokenURI;
    }
    
    /**
     * @dev Get token URI
     */
    function uri(uint256 tokenId) public view override returns (string memory) {
        string memory tokenURI = _tokenURIs[tokenId];
        return bytes(tokenURI).length > 0 ? tokenURI : super.uri(tokenId);
    }
    
    /**
     * @dev Pause contract
     */
    function pause() public onlyOwner {
        _pause();
    }
    
    /**
     * @dev Unpause contract
     */
    function unpause() public onlyOwner {
        _unpause();
    }
    
    /**
     * @dev Override required by Solidity
     */
    function _beforeTokenTransfer(
        address operator,
        address from,
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        bytes memory data
    ) internal override whenNotPaused {
        super._beforeTokenTransfer(operator, from, to, ids, amounts, data);
    }
}
'''

    def _get_hedera_client(self) -> str:
        return '''"""
Hedera Hashgraph client for blockchain interactions
"""

import os
import json
import logging
from typing import Optional, Dict, Any
from web3 import Web3
from eth_account import Account

logger = logging.getLogger(__name__)

class HederaClient:
    """
    Client for interacting with Hedera Hashgraph
    """
    
    def __init__(self):
        self.network = os.getenv("HEDERA_NETWORK", "testnet")
        self.account_id = os.getenv("HEDERA_ACCOUNT_ID")
        self.private_key = os.getenv("HEDERA_PRIVATE_KEY")
        
        # Web3 connection for EVM operations
        if self.network == "mainnet":
            self.web3_url = "https://mainnet.hashio.io/api"
        else:
            self.web3_url = "https://testnet.hashio.io/api"
            
        self.web3 = Web3(Web3.HTTPProvider(self.web3_url))
        
        # Contract addresses (deploy and update these)
        self.carbon_token_address = os.getenv("CARBON_TOKEN_ADDRESS")
        
    def deploy_carbon_token_contract(self, contract_bytecode: str, abi: list) -> str:
        """
        Deploy the carbon token contract
        """
        try:
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Create contract
            contract = self.web3.eth.contract(abi=abi, bytecode=contract_bytecode)
            
            # Build transaction
            transaction = contract.constructor("ipfs://").buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 2000000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            # Wait for receipt
            receipt = self.web3.eth.wait_for_transaction_receipt(tx_hash)
            
            logger.info(f"Carbon token contract deployed at: {receipt.contractAddress}")
            return receipt.contractAddress
            
        except Exception as e:
            logger.error(f"Error deploying contract: {e}")
            raise
    
    def issue_carbon_credits(
        self, 
        to_address: str, 
        token_id: int, 
        amount: int, 
        metadata_uri: str
    ) -> str:
        """
        Issue carbon credits to an address
        """
        try:
            if not self.carbon_token_address:
                raise ValueError("Carbon token contract not deployed")
            
            # Load contract ABI (this should be loaded from a file)
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Create account from private key
            account = Account.from_key(self.private_key)
            
            # Build transaction
            transaction = contract.functions.issueCredits(
                to_address,
                token_id,
                amount,
                metadata_uri,
                b''
            ).buildTransaction({
                'from': account.address,
                'nonce': self.web3.eth.get_transaction_count(account.address),
                'gas': 500000,
                'gasPrice': self.web3.toWei('20', 'gwei'),
            })
            
            # Sign and send transaction
            signed_txn = self.web3.eth.account.sign_transaction(transaction, self.private_key)
            tx_hash = self.web3.eth.send_raw_transaction(signed_txn.rawTransaction)
            
            logger.info(f"Carbon credits issued. Transaction: {tx_hash.hex()}")
            return tx_hash.hex()
            
        except Exception as e:
            logger.error(f"Error issuing carbon credits: {e}")
            raise
    
    def retire_carbon_credits(self, owner_address: str, token_id: int, amount: int) -> str:
        """
        Retire (burn) carbon credits
        """
        try:
            # Similar implementation to issue_carbon_credits
            # but calling retireCredits function
            pass
            
        except Exception as e:
            logger.error(f"Error retiring carbon credits: {e}")
            raise
    
    def get_credit_balance(self, address: str, token_id: int) -> int:
        """
        Get carbon credit balance for an address
        """
        try:
            if not self.carbon_token_address:
                return 0
            
            # Load contract ABI
            with open("packages/blockchain/contracts/CarbonAssetToken.json", "r") as f:
                contract_data = json.load(f)
                abi = contract_data["abi"]
            
            # Create contract instance
            contract = self.web3.eth.contract(
                address=self.carbon_token_address,
                abi=abi
            )
            
            # Call balanceOf function
            balance = contract.functions.balanceOf(address, token_id).call()
            return balance
            
        except Exception as e:
            logger.error(f"Error getting credit balance: {e}")
            return 0

# Global client instance
hedera_client = HederaClient()
'''

    def _get_settings(self) -> str:
        return '''"""
Application settings and configuration
"""

from pydantic import BaseSettings, validator
from typing import Optional, List
import os

class DatabaseSettings(BaseSettings):
    """Database configuration"""
    url: str = "postgresql://prism:prism_password@localhost:5432/prism_core"
    echo: bool = False
    pool_size: int = 10
    max_overflow: int = 20
    
    class Config:
        env_prefix = "DB_"

class RedisSettings(BaseSettings):
    """Redis configuration"""
    url: str = "redis://localhost:6379"
    
    class Config:
        env_prefix = "REDIS_"

class JWTSettings(BaseSettings):
    """JWT configuration"""
    secret: str = "your-secret-key"
    algorithm: str = "HS256"
    expiration_hours: int = 24
    
    class Config:
        env_prefix = "JWT_"

class HederaSettings(BaseSettings):
    """Hedera blockchain configuration"""
    account_id: Optional[str] = None
    private_key: Optional[str] = None
    network: str = "testnet"
    
    class Config:
        env_prefix = "HEDERA_"

class EmailSettings(BaseSettings):
    """Email configuration"""
    smtp_host: str = "smtp.gmail.com"
    smtp_port: int = 587
    username: Optional[str] = None
    password: Optional[str] = None
    
    class Config:
        env_prefix = "SMTP_"

class Settings(BaseSettings):
    """Main application settings"""
    
    # Basic settings
    app_name: str = "PRISM Carbon Registry"
    version: str = "1.0.0"
    debug: bool = False
    log_level: str = "INFO"
    
    # Service URLs
    user_service_url: str = "http://localhost:8001"
    project_service_url: str = "http://localhost:8002"
    validation_service_url: str = "http://localhost:8003"
    registry_service_url: str = "http://localhost:8004"
    
    # CORS settings
    cors_origins: List[str] = ["http://localhost:3000", "http://localhost:3001"]
    
    # Component settings
    database: DatabaseSettings = DatabaseSettings()
    redis: RedisSettings = RedisSettings()
    jwt: JWTSettings = JWTSettings()
    hedera: HederaSettings = HederaSettings()
    email: EmailSettings = EmailSettings()
    
    @validator("cors_origins", pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(",")]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = False

def get_settings() -> Settings:
    """Get application settings"""
    return Settings()
'''

    def _get_exceptions_base(self) -> str:
        return '''"""
Base exception classes and error handling
"""

from enum import Enum
from typing import Optional, Dict, Any, List
import logging

logger = logging.getLogger(__name__)

class ErrorCode(str, Enum):
    """Standard error codes"""
    
    # Generic errors
    INTERNAL_ERROR = "INTERNAL_ERROR"
    VALIDATION_ERROR = "VALIDATION_ERROR"
    NOT_FOUND = "NOT_FOUND"
    UNAUTHORIZED = "UNAUTHORIZED"
    FORBIDDEN = "FORBIDDEN"
    
    # User errors
    USER_NOT_FOUND = "USER_NOT_FOUND"
    USER_ALREADY_EXISTS = "USER_ALREADY_EXISTS"
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    
    # Project errors
    PROJECT_NOT_FOUND = "PROJECT_NOT_FOUND"
    PROJECT_ALREADY_EXISTS = "PROJECT_ALREADY_EXISTS"
    INVALID_PROJECT_STATUS = "INVALID_PROJECT_STATUS"
    
    # File errors
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    
    # Blockchain errors
    BLOCKCHAIN_ERROR = "BLOCKCHAIN_ERROR"
    INSUFFICIENT_BALANCE = "INSUFFICIENT_BALANCE"
    TRANSACTION_FAILED = "TRANSACTION_FAILED"

class BaseException(Exception):
    """Base exception class"""
    
    def __init__(
        self,
        message: str,
        error_code: ErrorCode,
        details: Optional[Dict[str, Any]] = None,
        status_code: int = 500
    ):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.status_code = status_code
        super().__init__(message)
        
        # Log the exception
        logger.error(
            f"Exception: {error_code.value} - {message}",
            extra={"error_code": error_code.value, "details": details}
        )

class ValidationError(BaseException):
    """Validation error"""
    
    def __init__(
        self,
        message: str = "Validation failed",
        field_errors: Optional[List[Dict[str, str]]] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.field_errors = field_errors or []
        error_details = {"field_errors": self.field_errors}
        if details:
            error_details.update(details)
            
        super().__init__(
            message=message,
            error_code=ErrorCode.VALIDATION_ERROR,
            details=error_details,
            status_code=400
        )

class NotFoundError(BaseException):
    """Resource not found error"""
    
    def __init__(
        self,
        resource_type: str,
        resource_id: str,
        details: Optional[Dict[str, Any]] = None
    ):
        message = f"{resource_type} with ID {resource_id} not found"
        super().__init__(
            message=message,
            error_code=ErrorCode.NOT_FOUND,
            details=details,
            status_code=404
        )

class UnauthorizedError(BaseException):
    """Unauthorized access error"""
    
    def __init__(
        self,
        message: str = "Unauthorized access",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.UNAUTHORIZED,
            details=details,
            status_code=401
        )

class ForbiddenError(BaseException):
    """Forbidden access error"""
    
    def __init__(
        self,
        message: str = "Access forbidden",
        details: Optional[Dict[str, Any]] = None
    ):
        super().__init__(
            message=message,
            error_code=ErrorCode.FORBIDDEN,
            details=details,
            status_code=403
        )
'''

    def _get_logging_setup(self) -> str:
        return '''"""
Logging configuration and setup
"""

import logging
import logging.config
import os
import sys
from typing import Dict, Any

def get_logging_config() -> Dict[str, Any]:
    """Get logging configuration"""
    
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    
    config = {
        "version": 1,
        "disable_existing_loggers": False,
        "formatters": {
            "standard": {
                "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
            },
            "json": {
                "()": "packages.common.logging.formatters.JSONFormatter",
            },
        },
        "handlers": {
            "console": {
                "level": log_level,
                "class": "logging.StreamHandler",
                "formatter": "json" if os.getenv("LOG_FORMAT") == "json" else "standard",
                "stream": sys.stdout,
            },
            "file": {
                "level": log_level,
                "class": "logging.handlers.RotatingFileHandler",
                "formatter": "json",
                "filename": "logs/application.log",
                "maxBytes": 10485760,  # 10MB
                "backupCount": 5,
            },
        },
        "loggers": {
            "": {  # root logger
                "handlers": ["console"],
                "level": log_level,
                "propagate": False,
            },
            "uvicorn": {
                "handlers": ["console"],
                "level": "INFO",
                "propagate": False,
            },
            "sqlalchemy.engine": {
                "handlers": ["console"],
                "level": "WARNING",
                "propagate": False,
            },
        },
    }
    
    # Add file handler in production
    if os.getenv("ENVIRONMENT") == "production":
        config["loggers"][""]["handlers"].append("file")
    
    return config

def setup_logging():
    """Setup logging configuration"""
    
    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)
    
    # Apply logging configuration
    logging.config.dictConfig(get_logging_config())
    
    # Log startup message
    logger = logging.getLogger(__name__)
    logger.info("Logging configured successfully")
'''

    def _get_logging_formatters(self) -> str:
        return '''"""
Custom logging formatters
"""

import json
import logging
import traceback
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """JSON log formatter"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as JSON"""
        
        log_data: Dict[str, Any] = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # Add process and thread info
        log_data["process"] = record.process
        log_data["thread"] = record.thread
        
        # Add extra fields
        if hasattr(record, "user_id"):
            log_data["user_id"] = record.user_id
        
        if hasattr(record, "request_id"):
            log_data["request_id"] = record.request_id
            
        if hasattr(record, "trace_id"):
            log_data["trace_id"] = record.trace_id
        
        # Add exception info
        if record.exc_info:
            log_data["exception"] = {
                "type": record.exc_info[0].__name__ if record.exc_info[0] else None,
                "message": str(record.exc_info[1]) if record.exc_info[1] else None,
                "traceback": traceback.format_exception(*record.exc_info),
            }
        
        # Add any extra attributes
        for key, value in record.__dict__.items():
            if key not in log_data and not key.startswith("_"):
                try:
                    json.dumps(value)  # Test if value is JSON serializable
                    log_data[key] = value
                except (TypeError, ValueError):
                    log_data[key] = str(value)
        
        return json.dumps(log_data, ensure_ascii=False)

class StructuredFormatter(logging.Formatter):
    """Structured text formatter for development"""
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with structure"""
        
        # Base format
        formatted = super().format(record)
        
        # Add extra context if available
        extras = []
        if hasattr(record, "user_id"):
            extras.append(f"user_id={record.user_id}")
        
        if hasattr(record, "request_id"):
            extras.append(f"request_id={record.request_id}")
        
        if extras:
            formatted += f" [{', '.join(extras)}]"
        
        return formatted
'''

    def _get_frontend_app_tsx(self) -> str:
        return '''import React from 'react';
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ThemeProvider, createTheme } from '@mui/material/styles';
import CssBaseline from '@mui/material/CssBaseline';

import { AuthProvider } from './context/AuthContext';
import HomePage from './pages/public/HomePage';
import DashboardPage from './pages/dashboard/DashboardPage';
import ProjectsPage from './pages/projects/ProjectsPage';
import RegistryPage from './pages/registry/RegistryPage';

const theme = createTheme({
  palette: {
    primary: {
      main: '#2e7d32', // Green theme for carbon/environmental focus
    },
    secondary: {
      main: '#1976d2',
    },
  },
});

const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 3,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

function App() {
  return (
    <QueryClientProvider client={queryClient}>
      <ThemeProvider theme={theme}>
        <CssBaseline />
        <AuthProvider>
          <Router>
            <Routes>
              <Route path="/" element={<HomePage />} />
              <Route path="/dashboard" element={<DashboardPage />} />
              <Route path="/projects" element={<ProjectsPage />} />
              <Route path="/registry" element={<RegistryPage />} />
            </Routes>
          </Router>
        </AuthProvider>
      </ThemeProvider>
    </QueryClientProvider>
  );
}

export default App;
'''

    def _get_api_client(self) -> str:
        return '''import axios, { AxiosInstance, AxiosResponse } from 'axios';

const API_BASE_URL = process.env.REACT_APP_API_URL || 'http://localhost:8000';

class ApiClient {
  private client: AxiosInstance;

  constructor() {
    this.client = axios.create({
      baseURL: API_BASE_URL,
      timeout: 10000,
    });

    // Request interceptor to add auth token
    this.client.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // Response interceptor for error handling
    this.client.interceptors.response.use(
      (response) => response,
      (error) => {
        if (error.response?.status === 401) {
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  // User endpoints
  async getProfile() {
    const response = await this.client.get('/api/v1/users/me');
    return response.data;
  }

  async updateProfile(data: any) {
    const response = await this.client.put('/api/v1/users/me', data);
    return response.data;
  }

  // Project endpoints
  async getProjects(params?: any) {
    const response = await this.client.get('/api/v1/projects', { params });
    return response.data;
  }

  async getProject(id: string) {
    const response = await this.client.get(`/api/v1/projects/${id}`);
    return response.data;
  }

  async createProject(data: any) {
    const response = await this.client.post('/api/v1/projects', data);
    return response.data;
  }

  async updateProject(id: string, data: any) {
    const response = await this.client.put(`/api/v1/projects/${id}`, data);
    return response.data;
  }

  async uploadDocument(projectId: string, file: File, documentType: string) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('document_type', documentType);

    const response = await this.client.post(
      `/api/v1/projects/${projectId}/documents`,
      formData,
      {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      }
    );
    return response.data;
  }

  // Authentication endpoints
  async login(email: string, password: string) {
    const response = await this.client.post('/api/v1/auth/login', {
      email,
      password,
    });
    return response.data;
  }

  async register(userData: any) {
    const response = await this.client.post('/api/v1/auth/register', userData);
    return response.data;
  }

  async refreshToken() {
    const response = await this.client.post('/api/v1/auth/refresh');
    return response.data;
  }
}

export default new ApiClient();
'''

    def _get_k8s_namespace(self) -> str:
        return '''apiVersion: v1
kind: Namespace
metadata:
  name: prism-carbon-registry
  labels:
    name: prism-carbon-registry
    environment: development
'''

    def _get_terraform_main(self) -> str:
        return '''terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    kubernetes = {
      source  = "hashicorp/kubernetes"
      version = "~> 2.23"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

# EKS Cluster
module "eks" {
  source = "./modules/eks"
  
  cluster_name    = var.cluster_name
  cluster_version = var.cluster_version
  
  vpc_id          = module.vpc.vpc_id
  subnet_ids      = module.vpc.private_subnets
  
  node_groups = var.node_groups
  
  tags = var.tags
}

# VPC
module "vpc" {
  source = "./modules/vpc"
  
  name = "${var.cluster_name}-vpc"
  cidr = var.vpc_cidr
  
  availability_zones = var.availability_zones
  
  tags = var.tags
}

# RDS Database
module "rds" {
  source = "./modules/rds"
  
  identifier = "${var.cluster_name}-postgres"
  engine     = "postgres"
  
  allocated_storage = var.db_allocated_storage
  instance_class    = var.db_instance_class
  
  db_name  = var.db_name
  username = var.db_username
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.database_subnets
  
  tags = var.tags
}

# ElastiCache Redis
module "redis" {
  source = "./modules/redis"
  
  cluster_id = "${var.cluster_name}-redis"
  
  node_type = var.redis_node_type
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  tags = var.tags
}
'''

    def _get_prometheus_config(self) -> str:
        return '''global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'user-service'
    static_configs:
      - targets: ['user-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'project-service'
    static_configs:
      - targets: ['project-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'registry-service'
    static_configs:
      - targets: ['registry-service:8000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: /metrics

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    metrics_path: /metrics
'''

    # Add the main execution and run function
    def run(self):
        """Run the structure generator"""
        try:
            self.create_structure()
        except Exception as e:
            print(f"‚ùå Error creating structure: {e}")
            sys.exit(1)

def main():
    """Main entry point"""
    project_name = sys.argv[1] if len(sys.argv) > 1 else "prism-carbon-registry"
    
    generator = StructureGenerator(project_name)
    generator.run()

if __name__ == "__main__":
    main()
